% !TeX root = ../main.tex

\chapter{Stand der Technik}
\label{chapter:stand-der-technik}

% \begin{otherlanguage}{american}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % Reference ML in scenario-based validation of autonomous systems
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The current state of machine learning for scenario-based validation of autonomous systems relies heavily on data-based models to predict complex parameterized situations, for example in traffic. The engineering surrogate model is intended to assess risks and check the plausibility of scenarios, for example when a control system should predict a situation. For this purpose, the RQ is discussed in the following state-of-the-art research.

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % R1
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% R1 Which machine-learning-based surrogate models are suitable for uncertainty quantification?

% \begin{table}[!htpb]
%   \centering
%   \footnotesize
%   \begin{tabularx}{\textwidth}{|l|X|}
%     \hline
%     \textbf{Surrogate Model} & \textbf{Reason for Suitability} \\
%     \hline
%     \begin{itemize}[topsep=0em, itemsep=0.25em, leftmargin=0em, labelsep=0.25em]
%       \item 1. Gaussian Process Regression
%     \end{itemize} &  
%     \begin{itemize}[topsep=0em, itemsep=0em, leftmargin=0em, labelsep=0.25em]
%       \item 1.1. Intrinsic probabilistic output
%       \item 1.2. Exact variance estimation for small datasets
%       \item 1.3. Kernel-based uncertainty characterization
%     \end{itemize} \\ 
%     \hline
%     \begin{itemize}[topsep=0em, itemsep=0em, leftmargin=0em, labelsep=0.25em]
%       \item 2. Deep Ensembles
%     \end{itemize} & 
%     \begin{itemize}[topsep=0em, itemsep=0em, leftmargin=0em, labelsep=0.25em]
%       \item 2.1. Redundant modeling reduces overconfidence
%       \item 2.2. Easy integration into existing architectures
%       \item 2.3. Robust against out-of-distribution data
%     \end{itemize} \\
%     \hline
%     \begin{itemize}[topsep=0em, itemsep=0em, leftmargin=0em, labelsep=0.25em]
%       \item 3. Hybrid Methods
%     \end{itemize} & 
%     \begin{itemize}[topsep=0em, itemsep=0em, leftmargin=0em, labelsep=0.25em]
%       \item 3.1. Combines strengths of black-box models and GPR
%       \item 3.2. Can be retrofitted onto existing models
%       \item 3.3. Computationally efficient uncertainty propagation
%     \end{itemize} \\
%     \hline
%     \begin{itemize}[topsep=0em, itemsep=0em, leftmargin=0em, labelsep=0.25em]
%       \item 4. Bayesian Neural Networks
%     \end{itemize} & 
%     \begin{itemize}[topsep=0em, itemsep=0em, leftmargin=0em, labelsep=0.25em]
%       \item 4.1. Systematic integration of priors
%       \item 4.2. Theoretically grounded parameter uncertainty
%       \item 4.3. Natural regularization through Bayesian inference
%     \end{itemize} \\
%     \hline
%   \end{tabularx}
%   \caption{R1 Comparison of uncertainty quantification methods in ML}
%   \label{tab:chapter6r1}
% \end{table}

% \footnote{%
% \begin{minipage}[t]{\textwidth}
% \scriptsize
% \textbf{Sources for Tab. \ref{tab:chapter6r1}:}\\
% 1. \parencite[Ch.~2]{rasmussen2006gaussian}, 
% 1.1. \parencite[p.~16–17]{rasmussen2006gaussian}, 
% 1.2. \parencite[Ch.~2.2]{rasmussen2006gaussian},
% 1.3. \parencite[Ch.~4]{rasmussen2006gaussian}\\[0.3em]
% 2. \parencite{lakshminarayanan2017simple},
% 2.1. \parencite[p.~3]{lakshminarayanan2017simple},
% 2.2. \parencite[p.~5]{lakshminarayanan2017simple},
% 2.3. \parencite{ovadia2019can}\\[0.3em]
% 3. \parencite{perdikaris2017nonlinear}, 
% 3.1. \parencite[p.~5–6]{perdikaris2017nonlinear},
% 3.2. \parencite[p.~6]{perdikaris2017nonlinear},
% 3.3. \parencite{liu2020multifidelity}\\[0.3em]
% 4. \parencite{gal2016uncertainty}, 
% 4.1. \parencite[Ch.~2.3]{gal2016uncertainty}, 
% 4.2. \parencite[p.~40–41]{gal2016uncertainty}, 
% 4.3. \parencite[p.~41–42]{gal2016uncertainty}
% \end{minipage}%
% }

% % (Overview from MC25)

% \newpage


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % R2
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% R2 Which general and model-specific factors influence uncertainty learning in ML models?

% \newline
% R2.1 General Factors

% \begin{table}[!htpb]
%   \centering
%   \footnotesize
%   \begin{tabularx}{\textwidth}{|l|X|}
%     \hline
%     \textbf{Uncertainty Dimensions} & \textbf{Possible Values} \\
%     \hline
%     1. Localization in the system & Environment, modeling, functions, objectives, available resources \\
%     \hline
%     2. Nature & Epistemic, Aleatoric \\
%     \hline
%     3. Degree of uncertainty & No uncertainty, lack of knowledge, lack of awareness, lack of capability to gain awareness \\
%     \hline
%     4. Time of emergence & Requirements definition, development time, runtime \\
%     \hline
%   \end{tabularx}
%   \caption{R2 General factors for classifying uncertainty in AI systems, based on A. Kreutz~\nocite{AndreasKreutz2022}~\nocite{AndreasKreutz2022b}}
%   \label{tab:chapter6r21}
% \end{table}

% \newline
% R2.2 Model-specific Factors

% \begin{table}[!htpb]
%   \centering
%   \footnotesize
%   \begin{tabularx}{\textwidth}{|l|X|}
%     \hline
%     \textbf{Bayesian Neural Networks} & \textbf{Model-specific Factors} \\
%     \hline
%     1. Prior distributions & The choice of priors affects uncertainty and prediction accuracy. \\
%     \hline
%     2. Likelihood function & Determines how uncertainty in observations is modeled (e.g. Gaussian). \\
%     \hline
%     3. Posterior approximation & MCMC or variational inference estimates the posterior and uncertainty. \\
%     \hline
%     4. Regularization & Helps avoid overfitting and control uncertainty. \\
%     \hline
%     5. Bayesian optimization & Optimizes hyperparameters considering uncertainty. \\
%     \hline
%     6. Data quality & Poor data quality increases uncertainty, good quality reduces it. \\
%     \hline
%     7. Model scale & The scale of the model influences uncertainty quantification. \\
%     \hline
%   \end{tabularx}
%   \caption{R2.2 Model-specific factors for uncertainty classification in Bayesian Neural Networks}
%   \label{tab:chapter6r22}
% \end{table}

% \begin{table}[!htpb]
%   \centering
%   \footnotesize
%   \begin{tabularx}{\textwidth}{|l|X|}
%     \hline
%     \textbf{Evidential Neural Networks} & \textbf{Model-specific Factors} \\
%     \hline
%     1. Prior function & Influences how uncertainty is modeled over data and parameters. \\
%     \hline
%     2. Evidence function & Models uncertainty via evidence parameters such as \( \alpha \), \( \beta \), and \( v \). \\
%     \hline
%     3. Posterior approximation & Approximation of the posterior distribution to determine uncertainty. \\
%     \hline
%     4. Evidence optimization & Optimization of evidence parameters during training. \\
%     \hline
%     5. Evidence-based regularization & Regularizes evidence parameters to prevent overfitting. \\
%     \hline
%     6. Multimodality & Simultaneous modeling of multiple competing uncertainty predictions. \\
%     \hline
%     7. Data-inherent uncertainty & Uncertainty that directly arises from the data itself. \\
%     \hline
%     8. Data quality & Poor data quality increases uncertainty in the model. \\
%     \hline
%     9. Network depth & The depth affects the capability to capture uncertainty. \\
%     \hline
%   \end{tabularx}
%   \caption{R2.2 Model-specific factors for uncertainty classification in Evidential Neural Networks}
%   \label{tab:chapter6r23}
% \end{table}

% \footnote{%
% \begin{minipage}[t]{\textwidth}
% \scriptsize
% \textbf{Sources for Tab. \ref{tab:chapter6r21}, Tab. \ref{tab:chapter6r22}, Tab. \ref{tab:chapter6r23}:}\\[0.125em]
% \textbf{R2.1 General Factors:} 
% 1. \parencite[p.~47–52]{AndreasKreutz2022},
% 2. \parencite[p.~54]{AndreasKreutz2022},
% 3. \parencite[p.~56–58]{AndreasKreutz2022},
% 4. \parencite[p.~60]{AndreasKreutz2022}\\[0.125em]

% \textbf{R2.2.1 Bayesian Neural Networks:} 
% 1. \parencite[Ch.~2.3]{gal2016uncertainty},
% 2. \parencite[Ch.~3]{blundell2015weight},
% 3. \parencite[p.~40–41]{gal2016uncertainty},
% 4. \parencite[p.~41–42]{gal2016uncertainty},
% 5. \parencite[Ch.~7.4]{rasmussen2006gaussian},
% 6. \parencite[p.~16]{bishop2006pattern},
% 7. \parencite[p.~29–31]{gal2016uncertainty}\\[0.125em]

% \textbf{R2.2.2 Evidential Neural Networks:} 
% 1. \parencite{sensoy2018evidential},
% 2. \parencite[p.~2–3]{sensoy2018evidential},
% 3. \parencite[p.~4]{sensoy2018evidential},
% 4. \parencite[p.~5]{sensoy2018evidential},
% 5. \parencite[p.~6]{sensoy2018evidential},
% 6. \parencite[p.~6–7]{sensoy2018evidential},
% 7. \parencite{kendall2017uncertainties},
% 8. \parencite{kendall2017uncertainties},
% 9. \parencite[p.~6]{sensoy2018evidential}
% \end{minipage}%
% }

% \newpage


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % R3
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% R3 How can these influencing factors be mitigated to improve uncertainty estimation?

% \newline
% How to mitigate general factors?

% \begin{table}[!htpb]
%   \centering
%   \footnotesize
%   \begin{tabularx}{\textwidth}{|l|X|}
%     \hline
%     \textbf{Uncertainty Dimensions} & \textbf{Possible Mitigation} \\
%     \hline
%     1. Localization in the system & Improve model accuracy and resource utilization through targeted data collection and model adaptation. \\
%     \hline
%     2. Nature & Use of hybrid models capable of modeling both epistemic and aleatoric uncertainty. \\
%     \hline
%     3. Degree of uncertainty & Increase model specification, e.g., through ensemble modeling and explicit uncertainty quantification. \\
%     \hline
%     4. Time of occurrence & Integrate uncertainty modeling early in requirements definition and development phases. \\
%     \hline
%   \end{tabularx}
%   \caption{R3 Mitigation of general factors in AI systems}
%   \label{tab:chapter6r31}
% \end{table}

% \newline
% How to mitigate model-specific factors?

% \begin{table}[!htpb]
%   \centering
%   \footnotesize
%   \begin{tabularx}{\textwidth}{|l|X|}
%     \hline
%     \textbf{Model-specific factors} & \textbf{Mitigation of uncertainty estimation} \\
%     \hline
%     1. Prior distributions & Choose more robust priors and adapt priors to the data to avoid excessive uncertainty. \\
%     \hline
%     2. Likelihood function & Optimize likelihood models, e.g., by using multidimensional likelihoods for uncertainty modeling. \\
%     \hline
%     3. Posterior approximation & Employ efficient approximation techniques such as Variational Inference for improved uncertainty estimation. \\
%     \hline
%     4. Regularization & Apply stronger regularization techniques to avoid overfitting and explicitly reduce uncertainty. \\
%     \hline
%     5. Bayesian optimization & Optimize hyperparameters under uncertainty to specifically reduce uncertainty in the model. \\
%     \hline
%     6. Data quality & Improve data quality through data cleansing and compilation of training sets that reduce uncertainty. \\
%     \hline
%     7. Scale & Use scaling models to reduce uncertainty by training models on larger data sets. \\
%     \hline
%   \end{tabularx}
%   \caption{R3.1 Mitigation of model-specific factors for uncertainty estimation in \textbf{\gls{Bayesian Neural Networks}}}
%   \label{tab:chapter6r32}
% \end{table}

% \begin{table}[!htpb]
%   \centering
%   \footnotesize
%   \begin{tabularx}{\textwidth}{|l|X|}
%     \hline
%     \textbf{Model-specific factors} & \textbf{Mitigation of uncertainty estimation} \\
%     \hline
%     1. Prior function & Use flexible prior functions tailored to the specific level of data uncertainty. \\
%     \hline
%     2. Evidence function & Improve evidence parameters, e.g., by using multimodal evidence functions to better model uncertainty. \\
%     \hline
%     3. Posterior approximation & Apply precise MCMC methods or improved approximation methods for more accurate posterior estimation. \\
%     \hline
%     4. Evidence optimization & Optimize evidence parameters to avoid highly uncertain parameter regions and thus reduce uncertainty. \\
%     \hline
%     5. Evidence-based regularization & Apply stronger regularization of evidence parameters to avoid excessive uncertainty in modeling. \\
%     \hline
%     6. Multimodality & Integrate multimodal uncertainty models to capture multiple sources of uncertainty simultaneously. \\
%     \hline
%     7. Data-inherent uncertainty & Reduce data noise and improve preprocessing to minimize uncertainty inherent in the data. \\
%     \hline
%     8. Data quality & Improve data quality by using better datasets and data augmentation. \\
%     \hline
%     9. Network depth & Optimize network depth with regard to model complexity to avoid unnecessary uncertainties. \\
%     \hline
%   \end{tabularx}
%   \caption{R3.2 Mitigation of model-specific factors for uncertainty estimation in \textbf{\gls{Evidential Neural Networks}}}
%   \label{tab:chapter6r33}
% \end{table}

% \footnote{%
% \begin{minipage}[t]{\textwidth}
% \scriptsize
% \textbf{Sources for Tab. \ref{tab:chapter6r31}, Tab. \ref{tab:chapter6r32}, Tab. \ref{tab:chapter6r33}:}\\[0.125em]
% \textbf{R3 General factors}\\
% 1. \parencite[pp.~47–52]{AndreasKreutz2022},
% 2. \parencite[pp.~6–9]{perdikaris2017nonlinear},
% 3. \parencite[p.~3]{ovadia2019can},
% 4. \parencite[p.~60]{AndreasKreutz2022} \\[0.125em]

% \textbf{R3.1 Bayesian Neural Networks}\\
% 1. \parencite[Chap.~2.3]{gal2016uncertainty},
% 2. \parencite[Chap.~3]{blundell2015weight},
% 3. \parencite[pp.~40–41]{gal2016uncertainty},
% 4. \parencite[pp.~41–42]{gal2016uncertainty},
% 5. \parencite[Chap.~7.4]{rasmussen2006gaussian},
% 6. \parencite[p.~16]{bishop2006pattern},
% 7. \parencite[pp.~29–31]{gal2016uncertainty} \\[0.125em]

% \textbf{R3.2 Evidential Neural Networks}\\
% 1. \parencite{sensoy2018evidential},
% 2. \parencite[pp.~3–4]{sensoy2018evidential},
% 3. \parencite[p.~4]{sensoy2018evidential},
% 4. \parencite[p.~5]{sensoy2018evidential},
% 5. \parencite[p.~6]{sensoy2018evidential},
% 6. \parencite[pp.~6–7]{sensoy2018evidential},
% 7. \parencite{kendall2017uncertainties},
% 8. \parencite{kendall2017uncertainties},
% 9. \parencite[p.~6]{sensoy2018evidential}
% \end{minipage}%
% }

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % R4
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% R4 To what extent can ML-based uncertainty quantification reliably reflect the uncertainties observed in real-world application scenarios?
% % Evidence from theoretical derivation of how correspondence can be achieved.
% \newline
% % UQ-Pred-UQ-Data-EQ-Ensure-Framework
% Lanini et al. provide a framework for assessing R4 \parencite{Lanini2024}, aimed at optimization within an application domain. Their research further differentiates between data-based and model-based uncertainty metrics to address this question.
% \newline
% Manchingal et al. distance themselves from the optimization toward application domains. They describe epistemic artificial intelligence as a paradigm shift. At its core, the goal is to train not only on knowledge in the form of data, but also explicitly on the absence of knowledge. \parencite{manchingal2025}


% \pagebreak


% \textbf{Modeling Evidential Knowledge}

% \begin{figure}[!ht]
%   \centering
%   \includegraphics[width=\textwidth]{../figures/x3.png}
%   \caption{R4.1}
% \end{figure}

% \begin{figure}[!ht]
%   \centering
%   \includegraphics[width=\textwidth]{../figures/x2.png}
%   \caption{R4.2}
% \end{figure}


% \textbf{Modeling Evidential Ignorance}

% One approach to training \gls{evidential neural networks} on ignorance is to condition the model such that it produces low evidence values for unknown inputs. This is achieved by including out-of-distribution (OOD) examples during training and augmenting the loss function with a term that pushes the evidence distribution toward a uniform distribution:

% \[
% \text{Loss}_{\text{total}} = \text{Loss}_{\text{in}} + \lambda \cdot \text{KL}\bigl(\text{Dir}(\boldsymbol{\alpha}) \,\|\, \text{Uniform}\bigr).
% \]

% This prevents excessively high evidence values for unknown inputs. In regression tasks, variance can similarly be intentionally increased by setting $\alpha$ and $\beta$ to low values. Thus, the ENN learns to explicitly express ignorance through low evidence and high uncertainty (cf. Manchingal et al. (MC25)).


% \pagebreak


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % R5
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% R5 Conducting a comprehensive literature review on UQ techniques in ML-based surrogate modeling.

% The contribution to a comprehensive literature review on UQ techniques in ML-based surrogate modeling is focused on \gls{evidential neural networks}. Within \gls{evidential neural networks}, a distinction is made between inclusion and exclusion criteria.

% \begin{table}[htbp]
% \centering
% \footnotesize
% \begin{tabularx}{\textwidth}{|l|X|}
% \hline
% \textbf{Criterion} & \textbf{Description} \\ \hline

% \textbf{Inclusion Criteria} & 
% Evidential Deep Learning or evidential uncertainty modeling \newline
% Peer-reviewed or relevant arXiv preprints \newline
% Including experiments or applications \newline
% Publications from 2016–2025 \newline
% English language \\ \hline

% \textbf{Exclusion Criteria} &
% No implementation or purely theoretical without EDL reference \newline
% Only Bayesian NNs/ensembles without evidential approaches \newline
% Purely technical papers without relevance to uncertainty \newline
% Non-English publications \newline
% Only posters or abstracts without full text \\ \hline

% \end{tabularx}
% \caption{R5 Selection criteria for the literature review on Evidential Deep Learning}
% \label{tab:auswahlkriterien}
% \end{table}

% % Catalog of questions covered by the scopes. 

% % How is Evidential Deep Learning used for uncertainty quantification in neural networks?

% % Which methods, benchmarks, and applications exist for EDL?

% % What is the optimal loss function for EDL?

% % What are the mathematical foundations underlying Evidential Deep Learning?

% % What is the connection between EDL and Subjective Logic?

% % How do Evidential Deep Learning and Bayesian Deep Learning differ?

% % Which architectures are suitable for Evidential Learning?

% % What modifications are necessary for classical CNNs, RNNs, Transformers for EDL?

% % How are evidential layers integrated into existing architectures?

% % What are the differences between evidential loss and standard loss functions like cross entropy?

% % What role does KL regularization play in the context of EDL?

% % How does EDL handle erroneous or uncertain labels?

% % How do epistemic and aleatoric uncertainties differ in EDL?

% % How can evidential parameters be interpreted?

% % Which benchmarks are typically used for EDL (e.g., MNIST, CIFAR-10, OOD tests)?

% % How does EDL perform compared to Bayesian Neural Networks and Deep Ensembles?

% % What are the application areas for EDL, especially in fields like autonomous driving or Industry 4.0?

% % What challenges currently exist in training and deploying Evidential Deep Learning?

% % What overconfidence problems can occur in EDL?

% % How scalable is Evidential Deep Learning to large models and datasets?

% % How does EDL compare to deterministic methods with post-hoc calibration?

% A catalog of questions has been generated for the literature review, which has resulted in the following scopes:

% \begin{table}[htbp]
% \centering
% \footnotesize
% \begin{tabularx}{\textwidth}{|l|X|}
% \hline
% \textbf{Scope} & \textbf{Description} \\ \hline

% 1. Theoretical Foundations &
% 1.1. Mathematical formulation of EDL \newline
% 1.2. Connection to Subjective Logic \newline
% 1.3. Differences from Bayesian Deep Learning \\ \hline

% 2. Architectures &
% 2.1. Network architectures for evidential learning \newline
% 2.2. Modifications to classical CNNs, RNNs, Transformers \newline
% 2.3. Integration of evidential layers \\ \hline

% 3. Loss Functions &
% 3.1. Evidential Loss vs. standard cross entropy \newline
% 3.2. KL regularization \newline
% 3.3. Handling noisy labels \\ \hline

% 4. Uncertainty Types &
% 4.1. Epistemic vs. aleatoric uncertainty \newline
% 4.2. Interpretation of evidential parameters \\ \hline

% 5. Benchmarks &
% 5.1. Typical datasets (MNIST, CIFAR-10, OOD tests) \newline
% 5.2. Comparison to Bayesian NNs and ensembles \\ \hline

% 6. Application Domains &
% 6.1. Autonomous driving \newline
% 6.2. Industry 4.0 \\ \hline

% 7. Comparison to Other Methods &
% 7.1. Bayesian Neural Networks \newline
% 7.2. Deep Ensembles \newline
% 7.3. Deterministic methods with calibration \\ \hline

% 8. Challenges &
% 8.1. Training stability \newline
% 8.2. Overconfidence problems \newline
% 8.3. Scalability to large models \\ \hline

% \end{tabularx}
% \caption{R5 Scopes of the questions for the literature review on Evidential Deep Learning}
% \label{tab:edl_scopes}
% \end{table}

% \pagebreak

% Based on the R5 scopes of the questions in the literature review on Evidential Deep Learning, the following R5 scopes of answers for the literature review on Evidential Deep Learning with corresponding sources have been defined:

% \begin{table}[htbp]
% \centering
% \footnotesize
% \begin{tabularx}{\textwidth}{|l|X|}
% \hline
% \textbf{Scope} & \textbf{Description / Sources} \\ \hline

% 1.1. & Sensoy et al. (2018): Evidential Deep Learning to Quantify Classification Uncertainty \cite{sensoy2018evidential} \newline
%          Sensoy et al. (2023): Evidential Deep Learning: Theory and Practice \cite{sensoy2023tutorial} \\ 
% 1.2. & Jøsang (2016): Subjective Logic \cite{josang2016subjective} \\ 
% 1.3. & Kendall \& Gal (2017): What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision? \cite{kendall2017uncertainties} \newline
%          Peters et al. (2023): On the Mathematical Consistency of Evidential Learning \cite{peters2023consistency} \\ \hline

% 2.1. & Amini et al. (2020): Deep Evidential Regression \cite{amini2020deep} \newline
%          Tian et al. (2024): Evidential Graph Neural Networks \cite{tian2024egnn} \\ 
% 2.2. & Sensoy et al. (2020): Uncertainty-Aware Deep Classification \cite{sensoy2020uncertainty} \newline
%          Dordevic et al. (2024): Evidential Transformers for Improved Image Retrieval \cite{dordevic2024evidential} \\ 
% 2.3. & Zhou et al. (2022): Evidential Transformer Networks \cite{zhou2022evidential} \newline
%          Dordevic et al. (2024): Evidential Transformers for Improved Image Retrieval \cite{dordevic2024evidential} \\ \hline

% 3.1. & Sensoy et al. (2018): Evidential Loss Function (Evidential Deep Learning) \cite{sensoy2018evidential} \\ 
% 3.2. & Sensoy et al. (2020): KL Regularization in Evidential Networks \cite{sensoy2020uncertainty} \newline
%          Amini et al. (2023): Improved KL Regularization for Evidential Regression \cite{amini2023kl} \\ 
% 3.3. & Dhamija et al. (2018): Reducing Model Confidence for Out-of-Distribution Detection \cite{dhamija2018reducing} \\ \hline

% 4.1. & Kendall \& Gal (2017): Aleatoric and Epistemic Uncertainty \cite{kendall2017uncertainties} \newline
%          Tran et al. (2023): Separating Aleatoric and Epistemic Uncertainty in Evidential Models \cite{tran2023separating} \\ 
% 4.2. & Amini et al. (2020): Interpreting evidential parameters in regression tasks \cite{amini2020deep} \\ \hline

% 5.1. & Amini et al. (2020): Evaluation on MNIST, CIFAR-10, OOD \cite{amini2020deep} \newline
%          Bohlke et al. (2023): Evaluation on CIFAR-100C, ImageNet-O \cite{dordevic2024evidential} \\ 
% 5.2. & Lakshminarayanan et al. (2017): Deep Ensembles as Baseline for Uncertainty \cite{lakshminarayanan2017simple} \newline
%          Tran et al. (2023): Comparative Benchmarks \cite{tran2023separating} \\ \hline

% 6.1. & Feng et al. (2022): Evidential Uncertainty in Autonomous Driving \cite{feng2022review} \\ 
% 6.2. & Wang et al. (2022): Uncertainty Modeling in Industrial AI \cite{wang2022uncertainty} \newline
%          Gupta et al. (2023): Evidential Learning for Industrial Predictive Maintenance \cite{gupta2023industrialedl} \newline
%          Chen et al. (2024): Uncertainty Estimation in Vision-Language Models \cite{chen2024vlm} \\ \hline

% 7.1. & Gal \& Ghahramani (2016): Dropout as Bayesian Approximation \cite{gal2016dropout} \\ 
% 7.2. & Lakshminarayanan et al. (2017): Deep Ensembles \cite{lakshminarayanan2017simple} \\ 
% 7.3. & Guo et al. (2017): On Calibration of Modern Neural Networks \cite{guo2017calibration} \newline
%          Tran et al. (2023): Comparison of calibration in evidential vs. deterministic methods \cite{tran2023separating} \\ \hline

% 8.1. & Sensoy et al. (2020): Training stability in evidential networks \cite{sensoy2020uncertainty} \newline
%          Peters et al. (2023): Loss function degeneracies \cite{peters2023consistency} \\ 
% 8.2. & Dhamija et al. (2018): Overconfidence in neural networks \cite{dhamija2018reducing} \newline
%          Chen et al. (2024): Overconfidence in multimodal evidential learning \cite{chen2024vlm} \\ 
% 8.3. & Zhou et al. (2022): Scalability of evidential transformers \cite{zhou2022evidential} \newline
%          Bohlke et al. (2023): Scalability challenges in large Vision Transformers \cite{dordevic2024evidential} \\ \hline

% \end{tabularx}
% \caption{R5 Scopes of the answers in the literature review on Evidential Deep Learning with current sources (2016–2025)}
% \label{tab:edl_scopes_sources_updated}
% \end{table}
% \newline
% High-quality, central surveys include \parencite{Ulmer2023}, \parencite{Gawlikowski2023}.
% \newline
% The relationship between model-based evidential uncertainty and that observed in real-world data is elaborated in Appendix \ref{sec:enn_gum_derivation}.

% \pagebreak



% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % R6
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% R6 Identification and analysis of suitable uncertainty metrics for surrogate models, distinguishing between aleatoric and epistemic uncertainty.

% \begin{table}[htpb]
%   \centering
%   \begin{tabularx}{\textwidth}{|l|l|X|}
%     \hline
%     & \textbf{Data-based Metrics} & \textbf{Model-based Metrics} \\
%     \hline
%     \textbf{AC} & 
%     \begin{tabular}[c]{@{}l@{}} 
%       \( \sigma = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2} \) \\ 
%       Standard deviation (noise) \\[1ex]
%       \( \text{Var} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 \) \\ 
%       Variance of residuals
%     \end{tabular}
%     & 
%     \begin{tabular}[c]{@{}l@{}} 
%       \( p(\theta \mid \mathcal{D}) \) \\ 
%       Bayesian uncertainty (posterior) \\[1ex]
%       Cross-validation (train/test splits)
%     \end{tabular} \\
%     \hline
%     \textbf{EC} & 
%     \begin{tabular}[c]{@{}l@{}} 
%       \( \text{Error} = \sum_{i=1}^{n} |y_i - \hat{y}_i| \) \\ 
%       Error analysis on test data
%     \end{tabular}
%     & 
%     \begin{tabular}[c]{@{}l@{}} 
%       \( \hat{y} \pm z \cdot \sigma \) \\ 
%       Confidence interval \\[1ex]
%       \( H(p) = - \sum_{i} p(x_i) \log(p(x_i)) \) \\ 
%       Entropy of the posterior distribution
%     \end{tabular} \\
%     \hline
%   \end{tabularx}
%   \caption{R6 Uncertainty metrics for surrogate models}
%   \label{tab:chapter6r61}
% \end{table}

% \footnote{%
% \begin{minipage}[t]{\textwidth}
% \scriptsize
% \textbf{Sources for Table \ref{tab:chapter6r61}:}\\[0.125em]
% \textbf{AC (Aleatoric Uncertainty)}\\
% \quad Data-based metrics: \parencite[pp.~28–30]{bishop2006pattern}, 
% \quad Model-based metrics: \parencite[Ch.~2]{rasmussen2006gaussian}; \parencite{blundell2015weight}\\ [0.125em]

% \textbf{EC (Epistemic Uncertainty)}\\
% \quad Data-based metrics: \parencite[pp.~30–32]{bishop2006pattern}, 
% \quad Model-based metrics: \parencite[pp.~40–42]{gal2016uncertainty}; \parencite{sensoy2018evidential},
% \end{minipage}%
% }

% \pagebreak



% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % R7
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% R7 Comparison of model-specific and application-specific evaluation metrics for uncertainty quantification.

% % Example application domain: [Example Domain]
% For the comparison, applications in engineering are proposed:

% \begin{table}[!htbp]
% \centering
% \scriptsize
% \begin{tabularx}{\textwidth}{|l|X|}
% \hline
% \textbf{Domain} & \textbf{Typical Applications} \\
% \hline
% Structural Mechanics & Stress analysis, fatigue life prediction \\
% \hline
% Aerodynamics & CFD simulations, drag/lift coefficients \\
% \hline
% Automotive Engineering & Crash simulations, acoustics (NVH), thermal management \\
% \hline
% Acoustics & Modal analysis, sound propagation \\
% \hline
% Materials Science & Material properties, materials design \\
% \hline
% Geophysics & Earthquake simulation, soil mechanics \\
% \hline
% Process Simulation & Chemical reactors, process optimization \\
% \hline
% Energy & Battery management, grid stability \\
% \hline
% \end{tabularx}
% \caption{Engineering application domains for ML surrogate models}
% \label{tab:ingenieurwesen-domains-small}
% \end{table}

% % Application specification:
% As an example domain for comparing model-specific and application-specific uncertainty metrics for surrogate models in autonomous driving, the field of automotive engineering is chosen.

% \begin{table}[!htpb]
%   \centering
%   \scriptsize
%   \begin{tabularx}{\textwidth}{|l|X|X|}
%     \hline
%     & \textbf{Model-specific Metrics} & \textbf{Application-specific Metrics (Autonomous Driving)} \\
%     \hline
%     \textbf{AC} & 
%     RMSE: Deviation between predicted and actual sensor data (e.g., object positions) \newline
%     MAE: Mean absolute error in object detection or trajectory prediction \newline
%     KL(P‖Q): Divergence between predicted and ground truth probability distributions & 
%     Accuracy: Correctness of object detection (e.g., pedestrian detected/not detected) \newline
%     F1-Score: Balance between precision and recall in object detection \newline
%     AUC: Discriminative power in classifying safe vs. unsafe scenarios \\
%     \hline
%     \textbf{EC} & 
%     \( \mathcal{L}(\theta) \): Loss function including uncertainty terms (e.g., evidential loss) \newline
%     BMA: Bayesian Model Averaging of multiple posteriors for more robust uncertainties \newline
%     CI: Confidence intervals for critical quantities (e.g., time-to-collision) & 
%     Error: Deviation between predicted and actual safety distances \newline
%     H(p): Entropy of classification output as a measure of epistemic uncertainty \newline
%     AUC-PR: Performance for rare, critical classes (e.g., rare hazardous situations) \\
%     \hline
%   \end{tabularx}
%   \caption{Comparison of model-specific and application-specific uncertainty metrics for surrogate models in autonomous driving}
%   \label{tab:chapter6r71}
% \end{table}

% \footnote{%

% \begin{minipage}[t]{\textwidth}
% \scriptsize
% \textbf{Sources for Table \ref{tab:ingenieurwesen-domains-small}:}\\[0.5em]
% The listed application domains are compiled from \parencite{Gawlikowski2023} and \parencite{Ulmer2023}. Both works discuss typical use cases for ML-based surrogate models in engineering.
% \end{minipage}%
% \vspace{0.125em}
% \begin{minipage}[t]{\textwidth}
% \scriptsize
% \textbf{Sources for Table \ref{tab:chapter6r71}:}\\[0.5em]
% \textbf{AC (Aleatoric Uncertainty)}\\
% \quad Model-specific metrics: \parencite[pp.~224–226]{bishop2006pattern}; \parencite[Ch.~2]{rasmussen2006gaussian} \\
% \quad Application-specific metrics: \parencite[pp.~40–42]{bishop2006pattern} \\[0.5em]

% \textbf{EC (Epistemic Uncertainty)}\\
% \quad Model-specific metrics: \parencite[pp.~40–42]{gal2016uncertainty}; \parencite{blundell2015weight}; \parencite{sensoy2018evidential} \\
% \quad Application-specific metrics: \parencite[pp.~233–235]{bishop2006pattern}; \parencite{ovadia2019can}
% \end{minipage}%
% }

% \pagebreak



% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %  R8 /assets/repos/BA__U-i-mlb-Sm-f-d-s-V-a-S__tex/prototypes/prototype_s8-02-07-25/prototype_s8-02-07-25.py
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% % R8 Comparison

% \begin{table}[!htpb]
%   \centering
%   \begin{tabularx}{\textwidth}{|l|l|X|}
%     \hline
%       & \textbf{Bayesian Neural Networks} & \textbf{Conformal Prediction} \\
%     \hline
%     \textbf{Aleatoric Uncertainty} & 
%     \begin{tabular}[c]{@{}l@{}} 
%       Posterior distribution \( p(\theta \mid \mathcal{D}) \) \\ 
%       UQ via model parameters based on training \\[1ex]
%       MC Dropout \\ 
%     \end{tabular} &
%     \begin{tabular}[c]{@{}l@{}} 
%       CI \( \hat{y} \pm z \cdot \sigma \) \\ 
%       UQ through confidence intervals \\[1ex]
%       Ensemble \\ 
%     \end{tabular} \\
%     \hline
%     \textbf{Epistemic Uncertainty} & 
%     \begin{tabular}[c]{@{}l@{}} 
%       Bayesian uncertainty \( p(\theta \mid \mathcal{D}) \) \\ 
%       UQ via model parameters through Bayesian inference \\[1ex]
%       VI: Posterior approximation
%     \end{tabular} &
%     \begin{tabular}[c]{@{}l@{}} 
%       Confidence regions \\ 
%       Predictive UQ through confidence intervals \\[1ex]
%       GPR: kernel-based UQ approach, training
%     \end{tabular} \\
%     \hline
%   \end{tabularx}
%   \caption{R8 Comparison of UQ approaches for Bayesian Neural Networks and Conformal Prediction}
%   \label{tab:chapter6r81}
% \end{table}


% \paragraph{Comparison Score}

% The comparison score is computed as:
% {
%   \[\footnotesize
%   \text{Score} = w_\text{err} \cdot \frac{\text{RMSE}}{\text{Norm}_\text{RMSE}}
%   + w_\text{ECE} \cdot \frac{\text{ECE}}{\text{Norm}_\text{ECE}}
%   + w_\text{width} \cdot \frac{\text{IntervalWidth}}{\text{Norm}_\text{Width}}
%   + w_\text{runtime} \cdot \frac{\text{Runtime}}{\text{Norm}_\text{Runtime}}
%   \]
% }


% \begin{table}[htbp]
% \centering
% \footnotesize
% \begin{tabularx}{\textwidth}{|l|X|X|X|X|X|X|}
% \hline
% \textbf{Method} & \textbf{RMSE} & \textbf{MAE} & \textbf{Coverage} & \textbf{ECE} & \textbf{Mean Interval Width} & \textbf{Score} \\
% \hline
% BNN HMC & 6.845 & 5.697 & 0.010 & 0.990 & 2.404 & 1.3988 \\
% \hline
% BNN SVI & 1367.638 & 1046.232 & 0.020 & 0.980 & 70.001 & 69.8022 \\
% \hline
% CP      & 0.096 & 0.075 & 0.870 & 0.130 & 0.267 & 0.0493 \\
% \hline
% \end{tabularx}
% \caption{Comparison of BNN (HMC, SVI) and CP models in terms of performance and uncertainty quantification.}
% \label{tab:r8_results}
% \end{table}


% \paragraph{Interpretation of Results}

% 1. \textbf{BNN HMC}: Delivers moderate error (RMSE ≈ 6.8), low epistemic uncertainty, but extremely low coverage. The uncertainty intervals barely capture the true values, indicating an overconfidence problem.\\
% 2. \textbf{BNN SVI}: Clearly fails. Very high RMSE (≈ 1367) and large epistemic variance indicate instability or convergence issues.\\
% 3. \textbf{Conformal Prediction (CP)}: Achieves very low error (RMSE ≈ 0.096), good coverage (approx. 87%), and the best score. This method is recommended for this dataset.


% \footnote{%
% \begin{minipage}[t]{\textwidth}
% \scriptsize
% \textbf{Sources for Table \ref{tab:chapter6r81}:}\\[0.5em]
% \textbf{Bayesian Neural Networks (BNNs)}\\
% Aleatoric Uncertainty: \parencite[Ch.~3]{blundell2015weight}; \parencite[pp.~40–42]{gal2016uncertainty} \\
% Epistemic Uncertainty: \parencite[pp.~40–42]{gal2016uncertainty}; \parencite{mackay1992practical} \\[0.5em]

% \textbf{Conformal Prediction (CP)}\\
% Aleatoric Uncertainty: \parencite[pp.~4–5]{vovk2005algorithmic}; \parencite{angelopoulos2021gentle} \\
% Epistemic Uncertainty: \parencite{angelopoulos2021gentle}; \parencite[pp.~63–65]{shafer2008tutorial}; \parencite{rasmussen2006gaussian}
% \end{minipage}%
% }

% \pagebreak



% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % R9
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% R9 Investigation of the theoretical influence of various factors on the uncertainty estimates of selected models.

% R9 is to be executed using a minimal sensitivity analysis example on \gls{Evidential Neural Networks} (ENN) in order to quantify the theoretical influence of model parameters on uncertainty estimation. The evidence parameter $\nu$ and training data size are varied to keep the analysis effort low.

% % Investigation - Most Minimal Sensitivity Analysis:
% % S1: Model Definition
% % S2: Parameter Range
% % S3: Execution of the Analysis

% % Comparison of selected models

% \textit{A - Model Definition}, \textit{B - Parameter Range}, \textit{C - Execution}

% \begin{table}[!htpb]
%   \centering
%   \footnotesize
%   \begin{tabularx}{\textwidth}{|l|X|X|X|}
%     \hline
%     & \textbf{BNN} & \textbf{CP} & \textbf{ENN} \\
%     \hline
%     \textbf{A} & 
%     \begin{tabular}[c]{@{}l@{}} 
%       Posterior \( p(\theta \mid \mathcal{D}) \) \\ 
%       UQ via model parameters \\ 
%       MC Dropout
%     \end{tabular} &
%     \begin{tabular}[c]{@{}l@{}} 
%       CI \( \hat{y} \pm z \cdot \sigma \) \\ 
%       UQ via confidence intervals \\ 
%       Ensemble
%     \end{tabular} &
%     \begin{tabular}[c]{@{}l@{}} 
%       Predictive distribution \( p(y \mid \mu, \alpha, \beta, \nu) \) \\ 
%       Evidence parameters
%     \end{tabular} \\
%     \hline
%     \textbf{B} & 
%     \begin{tabular}[c]{@{}l@{}} 
%       Model parameters: weights \( w_i \) \\ 
%       Influence of priors \\ 
%       Hyperparameter sensitivity
%     \end{tabular} &
%     \begin{tabular}[c]{@{}l@{}} 
%       Uncertainty estimation via CI \\ 
%       Influence of confidence regions
%     \end{tabular} &
%     \begin{tabular}[c]{@{}l@{}} 
%       Evidence parameters \(\nu\), \(\alpha\), \(\beta\) \\ 
%       control uncertainty components.
%     \end{tabular} \\
%     \hline
%     \textbf{C} & 
%     \begin{tabular}[c]{@{}l@{}} 
%       Bayesian inference for UQ \\ 
%       MC simulation with dropout
%     \end{tabular} &
%     \begin{tabular}[c]{@{}l@{}} 
%       Ensemble for UQ \\ 
%       Confidence region and CI analysis
%     \end{tabular} &
%     \begin{tabular}[c]{@{}l@{}} 
%       No sampling approximation needed \\ 
%       KL regularization controls evidence
%     \end{tabular} \\
%     \hline
%   \end{tabularx}
%   \caption{R9 Overview of UQ methods for \gls{Bayesian Neural Networks}, \gls{Conformal Prediction} and \gls{Evidential Neural Networks} without sensitivity annotations}
%   \label{tab:chapter6r91_clean}
% \end{table}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % R9 **/assets/repos/BA__U-i-mlb-Sm-f-d-s-V-a-S__tex/prototypes/prototype_s9-02-07-25/*.py
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% % S4: Evaluation
% \newline 
% \texttt{min\_sensitivity\_analysis\_enn.py} yields:

% \begin{table}[!htbp]
% \centering
% \footnotesize
% \begin{tabular}{|c|c|c|c|c|c|}
% \hline
% $\nu$ 
% & mean total var 
% & mean aleatoric 
% & mean epistemic 
% & RMSE 
% & RUI \\
% \hline
% 1  & $1.6191 \pm 0.1344$ & $0.8095 \pm 0.0672$ & $0.8095 \pm 0.0672$ & $155.7554$ & $0.0082$ \\
% \hline
% 5  & $1.0007 \pm 0.1152$ & $0.8339 \pm 0.0960$ & $0.1668 \pm 0.0192$ & $155.8031$ & $0.0064$ \\
% \hline
% 10 & $0.8591 \pm 0.0482$ & $0.7810 \pm 0.0439$ & $0.0781 \pm 0.0044$ & $155.0450$ & $0.0060$ \\
% \hline
% 20 & $0.8376 \pm 0.0804$ & $0.7978 \pm 0.0766$ & $0.0399 \pm 0.0038$ & $156.6731$ & $0.0058$ \\
% \hline
% \end{tabular}
% \caption{R9 Minimal sensitivity analysis \gls{Evidential Neural Networks} with $\pm 2\sigma$}
% \label{tab:enn_results}
% \end{table}

% The parameter $\nu$ in \gls{Evidential Neural Networks} controls the balance between \gls{Epistemic Uncertainty} and \gls{Aleatoric Uncertainty}. Low $\nu$ values emphasize epistemic uncertainty, while higher $\nu$ values shift the uncertainty decomposition more strongly toward the aleatoric component.

% \newline
% \texttt{min\_sensitivity\_analysis\_bnn.py} yields:

% \begin{table}[!htbp]
% \centering
% \footnotesize
% \begin{tabular}{|c|c|c|c|c|c|}
% \hline
% Dropout 
% & mean total var 
% & mean aleatoric 
% & mean epistemic 
% & RMSE 
% & RUI \\
% \hline
% 0.05 & $0.0079 \pm 0.0162$ & $0.0051 \pm 0.0108$ & $0.0028 \pm 0.0059$ & $6.8592$ & $0.0129$ \\
% \hline
% 0.10 & $0.0164 \pm 0.0382$ & $0.0099 \pm 0.0219$ & $0.0065 \pm 0.0167$ & $6.5767$ & $0.0195$ \\
% \hline
% 0.20 & $0.0347 \pm 0.0859$ & $0.0198 \pm 0.0460$ & $0.0150 \pm 0.0409$ & $7.2445$ & $0.0257$ \\
% \hline
% 0.50 & $0.1482 \pm 0.3429$ & $0.0783 \pm 0.1419$ & $0.0699 \pm 0.2080$ & $8.9771$ & $0.0429$ \\
% \hline
% \end{tabular}
% \caption{R9 Minimal sensitivity analysis \gls{Bayesian Neural Networks} with $\pm 2\sigma$}
% \label{tab:bnn_results}
% \end{table} 

% The dropout rate in \gls{Bayesian Neural Networks} directly influences \gls{Epistemic Uncertainty}, as higher dropout rates allow greater model variability and thus produce higher epistemic uncertainty in predictions.

% \newline
% \texttt{min\_sensitivity\_analysis\_cp.py} yields:

% \begin{table}[!htbp]
% \centering
% \footnotesize
% \begin{tabular}{|c|c|c|c|c|c|c|}
% \hline
% $\alpha$ 
% & Coverage 
% & Mean CI-Width 
% & mean aleatoric 
% & mean epistemic 
% & mean total var 
% & RUI \\
% \hline
% 0.20 & 0.820 & 1.0022 & $0.2088 \pm 0.9139$ & $0.3612 \pm 0.4821$ & $0.5700 \pm 0.4821$ & $1.8978$ \\
% \hline
% 0.10 & 0.913 & 1.3215 & $0.2088 \pm 0.9139$ & $0.3612 \pm 0.4821$ & $0.5700 \pm 0.4821$ & $1.8978$ \\
% \hline
% 0.05 & 0.953 & 1.7910 & $0.2088 \pm 0.9139$ & $0.3612 \pm 0.4821$ & $0.5700 \pm 0.4821$ & $1.8978$ \\
% \hline
% 0.01 & 1.000 & 3.0993 & $0.2088 \pm 0.9139$ & $0.3612 \pm 0.4821$ & $0.5700 \pm 0.4821$ & $1.8978$ \\
% \hline
% \end{tabular}
% \caption{R9 Minimal sensitivity analysis \gls{Conformal Prediction} with $\pm 2\sigma$}
% \label{tab:cp_results}
% \end{table}

% The significance level $\alpha$ in \gls{Conformal Prediction} determines the width of the prediction intervals. Smaller $\alpha$ values result in higher confidence levels and thus wider, more conservative uncertainty intervals.

% \paragraph{Comparative Evaluation of Models \gls{Bayesian Neural Networks}, \gls{Conformal Prediction}, \gls{Evidential Neural Networks}}

% The three tables show the sensitivity analyses for \gls{Evidential Neural Networks}, \gls{Bayesian Neural Networks}, and \gls{Conformal Prediction} under variation of their respective control parameters (\(\nu\), dropout rate, \(\alpha\)). The key metrics evaluated were the mean total variance \(\overline{u(y)^2}\), mean aleatoric variance \(\overline{u_{\text{aleatoric}}^2}\), mean epistemic variance \(\overline{u_{\text{epistemic}}^2}\), RMSE, and the \emph{Relative Uncertainty Index} (RUI).

% In direct comparison, \gls{Evidential Neural Networks} exhibit the highest variances, e.g., up to \(\overline{u(y)^2} \approx 1.6\), while RMSE remains relatively stable around 155. The uncertainty decomposition in ENNs shows roughly equal contributions from \(\overline{u_{\text{aleatoric}}^2}\) and \(\overline{u_{\text{epistemic}}^2}\) at low \(\nu\). As \(\nu\) increases, \(\overline{u_{\text{epistemic}}^2}\) decreases significantly, shifting the uncertainty share more toward the aleatoric component. This highlights that very low \(\nu\) values can prevent overconfidence because the model allows for greater epistemic uncertainty.

% \gls{Bayesian Neural Networks} yield much lower variances, often below \(\overline{u(y)^2} < 0.02\), with significantly lower RMSE between 6 and 9. However, higher dropout rates lead to increasing values for both \(\overline{u_{\text{epistemic}}^2}\) and \(\overline{u_{\text{aleatoric}}^2}\), indicating greater spread in uncertainty. Too low dropout rates, however, may foster overconfidence because epistemic uncertainty remains underrepresented.

% \gls{Conformal Prediction} produces consistent mean variance values across all \(\alpha\) levels because the underlying Random Forest fit remains unchanged. Here, \(\overline{u(y)^2} \approx 0.57\), comprised of moderate epistemic variance \(\overline{u_{\text{epistemic}}^2} \approx 0.36\) and lower aleatoric component \(\overline{u_{\text{aleatoric}}^2} \approx 0.21\). The RUI values for \gls{Conformal Prediction} are noticeably higher at around 1.9, reflecting relatively broad uncertainty widths compared to the low RMSE (< 0.4). Due to direct interval calculation, \gls{Conformal Prediction} inherently guards against overconfidence but remains more conservative.

% Overall, the models show different profiles: \gls{Evidential Neural Networks} have the highest uncertainty levels but stable RMSE around 155. \gls{Bayesian Neural Networks} achieve lower errors and lower uncertainties but are sensitive to dropout rates. \gls{Conformal Prediction} yields stable but wider intervals, providing robust calibration. The metrics \(\overline{u(y)^2}\), \(\overline{u_{\text{aleatoric}}^2}\), \(\overline{u_{\text{epistemic}}^2}\), RMSE, and RUI enable a cross-method assessment of uncertainty and help detect overconfidence early.


% \begin{table}[!htbp]
% \centering
% \footnotesize
% \begin{tabularx}{\textwidth}{|l|X|}
% \hline
% \textbf{Method} & \textbf{Sensitivity Aspects} \\
% \hline
% \textbf{BNN} &
% Broader posterior with weak priors; stronger epistemic uncertainty. Higher dropout rate → increases epistemic uncertainty. \\
% \hline
% \textbf{CP} &
% CI width increases with higher confidence level; smaller calibration sets lead to unstable CIs. Coverage decreases with too narrow regions; interval width grows with higher \(\alpha\). Heteroscedastic data cause highly varying CI widths. \\
% \hline
% \textbf{ENN} &
% High epistemic uncertainty at low \(\nu\). Low \(\nu\) → more epistemic variance. Larger datasets reduce uncertainty. Excessive KL regularization may reduce model confidence excessively. \\
% \hline
% \end{tabularx}
% \caption{R9 Summary of sensitivity aspects of UQ methods \gls{Bayesian Neural Networks}, \gls{Conformal Prediction}, \gls{Evidential Neural Networks}}
% \label{tab:sensitivity_r9_transposed}
% \end{table}


% \footnote{%
% \begin{minipage}[t]{\textwidth}
% \scriptsize
% \textbf{Sources for Table \ref{tab:chapter6r91}:}\\[0.5em]
% \textbf{BNN (Bayesian Neural Networks)}\\
% A (Model Definition): \parencite[Ch.~3]{blundell2015weight}; \parencite[pp.~40–42]{gal2016uncertainty} \\
% B (Parameter Range): \parencite[pp.~448–450]{mackay1992practical}; \parencite[Ch.~5]{rasmussen2006gaussian} \\
% C (Execution): \parencite[pp.~41–42]{gal2016uncertainty}; \parencite{blundell2015weight} \\[0.5em]

% \textbf{CP (Conformal Prediction)}\\
% A (Model Definition): \parencite{angelopoulos2021gentle}; \parencite{shafer2008tutorial} \\
% B (Parameter Range): \parencite[pp.~63–65]{shafer2008tutorial}; \parencite{vovk2005algorithmic} \\
% C (Execution): \parencite{angelopoulos2021gentle}; \parencite{shafer2008tutorial}
% \end{minipage}%
% }

% \pagebreak
% \end{otherlanguage}


\begin{otherlanguage}{ngerman}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Bezug ML in szenariobasierter Validierung autonomer Systeme
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Der aktuelle Stand im Bereich \gls{machinelearning} für die szenariobasierte Validierung autonomer Systeme setzt stark auf datenbasierte Modelle, um komplexe parametrisierte Situationen vorherzusagen, zum Beispiel im Verkehr. Das ingenieurtechnische Ersatzmodell als Surrogat soll Risiken bewerten und die Plausibilität von Szenarien prüfen, zum Beispiel wann eine Steuerung eine Situation vorhersagen soll. Dazu wird im folgenden Rahmen der Forschungsfragen und spezifischen Aufgaben erörtert. \par\vspace{1\baselineskip}\noindent

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pagebreak

\begin{samepage}
%\begin{minipage}



\textbf{R1} Welche auf \gls{machinelearning} basierenden Surrogatmodelle sind für die Quantifizierung von Unsicherheiten geeignet?

\begin{table}[!htpb]
  \centering
  \footnotesize
  \begin{tabularx}{\textwidth}{|l|X|X|}
    \hline
    \textbf{\gls{surrogat}} & \hspace{0.6em}\textbf{Eignungsgrund} & \hspace{0.6em}\textbf{Quellen} \\ \hline
    
    \multirow{7}{*}{\gls{Gaußsche Prozessregression}} &
    \begin{itemize}[topsep=0em, itemsep=0em, leftmargin=*, label={}]
      \item 1.1. Intrinsische probabilistische Ausgabe
      \item 1.2. Exakte Varianzschätzung für kleine Datensätze
      \item 1.3. Kernel-basierte Unsicherheitscharakterisierung
    \end{itemize}
    &
    \begin{itemize}[topsep=0em, itemsep=0em, leftmargin=*, label={}]
      \item Rasmussen et al. \parencite[Kap.~2]{rasmussen2006gaussian}
      \item Rasmussen et al. \parencite[S.~16–17]{rasmussen2006gaussian}
      \item Rasmussen et al. \parencite[Kap.~2.2]{rasmussen2006gaussian}
      \item Rasmussen et al. \parencite[Kap.~4]{rasmussen2006gaussian}
    \end{itemize}
    \\ \hline

    \multirow{7}{*}{Deep Ensembles} &
    \begin{itemize}[topsep=0em, itemsep=0em, leftmargin=*, label={}]
      \item 2.1. Redundante Modellierung reduziert Overconfidence
      \item 2.2. Einfache Integration in existierende Architekturen
      \item 2.3. Robust gegen Out-of-Distribution-Daten
    \end{itemize}
    &
    \begin{itemize}[topsep=0em, itemsep=0em, leftmargin=*, label={}]
      \item Lakshminarayanan et al. \parencite{lakshminarayanan2017simple}
      \item Lakshminarayanan et al. \parencite[S.~3]{lakshminarayanan2017simple}
      \item Lakshminarayanan et al. \parencite[S.~5]{lakshminarayanan2017simple}
      \item Ovadia et al. \parencite{ovadia2019can}
    \end{itemize}
    \\ \hline

    \multirow{7}{*}{Hybrid-Methoden} &
    \begin{itemize}[topsep=0em, itemsep=0em, leftmargin=*, label={}]
      \item 3.1. Kombiniert Stärken von Blackbox-Modellen und GPR
      \item 3.2. Nachrüstbar auf existierende Modelle
      \item 3.3. Recheneffiziente Unsicherheitspropagation
    \end{itemize}
    &
    \begin{itemize}[topsep=0em, itemsep=0em, leftmargin=*, label={}]
      \item Perdikaris et al. \parencite{perdikaris2017nonlinear}
      \item Perdikaris et al. \parencite[S.~5–6]{perdikaris2017nonlinear}
      \item Perdikaris et al. \parencite[S.~6]{perdikaris2017nonlinear}
      \item Lui et al. \parencite{liu2020multifidelity}
    \end{itemize}
    \\ \hline

    \multirow{7}{*}{\gls{Bayesianische neuronale Netze}} &
    \begin{itemize}[topsep=0em, itemsep=0em, leftmargin=*, label={}]
      \item 4.1. Systematische Integration von Priors
      \item 4.2. Theoretisch fundierte Parameterunsicherheit
      \item 4.3. Natürliche Regularisierung durch Bayes'sche Inferenz
    \end{itemize}
    &
    \begin{itemize}[topsep=0em, itemsep=0em, leftmargin=*, label={}]
      \item Gal et al. \parencite{gal2016uncertainty}
      \item Gal et al. \parencite[Kap.~2.3]{gal2016uncertainty}
      \item Gal et al. \parencite[S.~40–41]{gal2016uncertainty}
      \item Gal et al. \parencite[S.~41–42]{gal2016uncertainty}
    \end{itemize}
    \\ \hline
    
  \end{tabularx}
  \caption{R1 Vergleich von Unsicherheitsquantifizierungsmethoden in \gls{machinelearning}}
  \label{tab:chapter6r1}
\end{table}

% (Übersicht aus MC25) 


\end{samepage}
%\end{minipage}


\newpage



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{R2} Welche \textit{allgemeinen} und \textit{modellspezifischen} Faktoren beeinflussen das Lernen von Unsicherheiten in \gls{machinelearning}-Modellen?
\par\vspace{1\baselineskip}\noindent

\textbf{R2.1} \textit{Allgemeine Faktoren} welche das Lernen von Unsicherheiten in \gls{machinelearning}-Modellen beeinflussen.

\begin{table}[!htpb]
  \centering
  \footnotesize
  \begin{tabularx}{\textwidth}{|l|X|X|}
    \hline
    \textbf{Unsicherheitsdimensionen} & \hspace{0.6em}\textbf{Mögliche Werte} & \hspace{0.6em}\textbf{Quellen} \\ \hline
    \multirow{7}{*}{1. Lokalisierung im System} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Umgebung
      \item Modellierung
      \item Funktionen
      \item Ziele
      \item Verfügbare Ressourcen
    \end{itemize} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Kreutz et al. \parencite[S.~47–52]{AndreasKreutz2022}
    \end{itemize} \\ \hline

    \multirow{4}{*}{2. Natur} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Epistemisch
      \item Aleatorisch
    \end{itemize} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Kreutz et al. \parencite[S.~54]{AndreasKreutz2022}
    \end{itemize} \\ \hline

    \multirow{7}{*}{3. Grad der Unsicherheit} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Keine Unsicherheit
      \item Mangel an Wissen
      \item Mangel an Bewusstsein
      \item Mangel an Fähigkeit, Bewusstsein zu erlangen
    \end{itemize} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Kreutz et al. \parencite[S.~56–58]{AndreasKreutz2022}
    \end{itemize} \\ \hline

    \multirow{5}{*}{4. Entstehungszeit} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Anforderungsdefinition
      \item Entwicklungszeit
      \item Laufzeit
    \end{itemize} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Kreutz et al. \parencite[S.~60]{AndreasKreutz2022}
    \end{itemize} \\ \hline
  \end{tabularx}
  \caption{R2 Allg. Faktoren Klassifizierung Unsicherheit \gls{kuenstlicheintelligenz}-Systeme}
  \label{tab:chapter6r21}
\end{table}

\newpage

\textbf{R2.2} \textit{Modellspezifische Faktoren} die das Lernen von Unsicherheiten in \gls{machinelearning}-Modellen beeinflussen.

\begin{table}[!htpb]
  \centering
  \footnotesize
  \begin{tabularx}{\textwidth}{|l|X|X|}
    \hline
    \textbf{\gls{Bayesianische neuronale Netze}} & \hspace{0.6em}\textbf{Modellspezifische Faktoren} & \hspace{0.6em}\textbf{Quellen} \\ \hline

    \multirow{6}{*}{1. Prior-Verteilungen} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Wahl der Prioren beeinflusst die Unsicherheit
      \item Beeinflusst die Vorhersagegenauigkeit
    \end{itemize} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Gal et al. \parencite[Kap.~2.3]{gal2016uncertainty}
    \end{itemize} \\ \hline

    \multirow{6}{*}{2. Likelihood-Funktion} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Bestimmt, wie Unsicherheit in den Beobachtungen modelliert wird
      \item Beispielsweise durch Gaussian-Verteilungen
    \end{itemize} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Blundell et al. \parencite[Kap.~3]{blundell2015weight}
    \end{itemize} \\ \hline

    \multirow{6}{*}{3. Posterior Approximation} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item \gls{Markov Chain Monte Carlo} oder \gls{variationalinference} werden genutzt
      \item Schätzt den Posterior und die Unsicherheit
    \end{itemize} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Gal et al. \parencite[S.~40–41]{gal2016uncertainty}
    \end{itemize} \\ \hline

    \multirow{5}{*}{4. Regularisierung} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Hilft, Overfitting zu vermeiden
      \item Unterstützt die Kontrolle der Unsicherheit
    \end{itemize} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Gal et al. \parencite[S.~41–42]{gal2016uncertainty}
    \end{itemize} \\ \hline

    \multirow{4}{*}{5. Bayesische Optimierung} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Optimiert Hyperparameter
      \item Berücksichtigt dabei die Unsicherheit
    \end{itemize} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Rasmussen et al. \parencite[Kap.~7.4]{rasmussen2006gaussian}
    \end{itemize} \\ \hline

    \multirow{6}{*}{6. Datenqualität} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Schlechte Datenqualität erhöht die Unsicherheit
      \item Gute Qualität kann Unsicherheit verringern
    \end{itemize} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Bishop et al. \parencite[S.~16]{bishop2006pattern}
    \end{itemize} \\ \hline

    \multirow{4}{*}{7. Maßstab} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Der Maßstab des Modells beeinflusst die Unsicherheitsquantifizierung
    \end{itemize} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Gal et al. \parencite[S.~29–31]{gal2016uncertainty}
    \end{itemize} \\ \hline

  \end{tabularx}
  \caption{R2.2 Modellspezifische Faktoren zur Unsicherheitsklassifizierung \gls{Bayesianische neuronale Netze}}
  \label{tab:chapter6r22}
\end{table}



\begin{table}[!htpb]
  \centering
  \footnotesize
  \begin{tabularx}{\textwidth}{|l|X|X|}
    \hline
    \textbf{\gls{Evidenzbasierte neuronale Netze}} & \hspace{0.6em}\textbf{Modellspezifische Faktoren} & \hspace{0.6em}\textbf{Quellen} \\ \hline
    \multirow{3}{*}{1. Prior-Funktion} & Beeinflusst, wie Unsicherheit über Daten und Parameter modelliert wird. &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Sensoy et al. \parencite{sensoy2018evidential}
    \end{itemize} \\ \hline
    \multirow{3}{*}{2. Evidenzfunktion} & Modelliert Unsicherheit mit Evidenzparametern wie \( \alpha \), \( \beta \), und \( v \). &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Sensoy et al. \parencite[S.~2–3]{sensoy2018evidential}
    \end{itemize} \\ \hline
    \multirow{3}{*}{3. Posterior Approximation} & Näherung der Posterior-Verteilung zur Unsicherheitsbestimmung. &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Sensoy et al. \parencite[S.~4]{sensoy2018evidential}
    \end{itemize} \\ \hline
    \multirow{3}{*}{4. Evidenz Optimierung} & Optimierung der Evidenzparameter während des Trainings. &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Sensoy et al. \parencite[S.~5]{sensoy2018evidential}
    \end{itemize} \\ \hline
    \multirow{3}{*}{5. Evidenzbasierte Regularisierung} & Regularisiert Evidenzparameter, um Overfitting zu vermeiden. &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Sensoy et al. \parencite[S.~6]{sensoy2018evidential}
    \end{itemize} \\ \hline
    \multirow{3}{*}{6. Multimodalität} & Modelliert mehrere konkurrierende Unsicherheitsvorhersagen gleichzeitig. &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Sensoy et al. \parencite[S.~6–7]{sensoy2018evidential}
    \end{itemize} \\ \hline
    \multirow{3}{*}{7. Dateninhärente Unsicherheit} & Unsicherheit, die direkt aus den Daten selbst resultiert. &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Kendall et al. \parencite{kendall2017uncertainties}
    \end{itemize} \\ \hline
    \multirow{3}{*}{8. Datenqualität} & Schlechte Datenqualität erhöht die Unsicherheit im Modell. &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Kendall et al. \parencite{kendall2017uncertainties}
    \end{itemize} \\ \hline
    \multirow{3}{*}{9. Netzwerktiefe} & Die Tiefe beeinflusst die Fähigkeit, Unsicherheit zu erfassen. &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Sensoy et al. \parencite[S.~6]{sensoy2018evidential}
    \end{itemize} \\ \hline
  \end{tabularx}
  \caption{R2.2 Modellspezifische Faktoren zur Unsicherheitsklassifizierung \gls{Evidenzbasierte neuronale Netze}}
  \label{tab:chapter6r23}
\end{table}



%\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R3
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\clearpage



\begin{samepage}
%\begin{minipage}



\textbf{R3} Wie können diese Einflussfaktoren abgeschwächt werden, um die Unsicherheitsabschätzung zu verbessern?
\par\vspace{1\baselineskip}\noindent

Wie kann man \textit{allgemeine Faktoren} beim Lernen von Unsicherheiten in \gls{machinelearning}-Modellen abschwächen?

\begin{table}[!htpb]
  \centering
  \footnotesize
  \begin{tabularx}{\textwidth}{|l|X|X|}
    \hline
    \textbf{Unsicherheitsdimensionen} & \hspace{0.6em}\textbf{Mögliche Abschwächung} & \hspace{0.6em}\textbf{Quellen} \\ \hline
    \multirow{5}{*}{1. Lokalisierung im System} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Verbesserung der Modellgenauigkeit und der Ressourcennutzung durch gezielte Datensammlung und Modellanpassung.
    \end{itemize}
    &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Kreutz et al. \parencite[S.~47–52]{AndreasKreutz2022}
    \end{itemize} \\ \hline
    
    \multirow{4}{*}{2. Natur} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Einsatz von hybriden Modellen, die sowohl \gls{Epistemische Unsicherheit} als auch \gls{Aleatorische Unsicherheit} modellieren können.
    \end{itemize}
    &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Perdikaris et al. \parencite[S.~6–9]{perdikaris2017nonlinear}
    \end{itemize} \\ \hline

    \multirow{5}{*}{3. Grad der Unsicherheit} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Erhöhung des Modellspezifikationsgrades, zum Beispiel durch Mehrfachmodellierung und \gls{uncertaintyquantification}.
    \end{itemize}
    &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Ovadia et al. \parencite[S.~3]{ovadia2019can}
    \end{itemize} \\ \hline

    \multirow{5}{*}{4. Entstehungszeit} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Frühzeitige Einbindung von Unsicherheitsmodellierung in die Anforderungsdefinition und Entwicklungszeit.
    \end{itemize}
    &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Kreutz et al. \parencite[S.~60]{AndreasKreutz2022}
    \end{itemize} \\ \hline

  \end{tabularx}
  \caption{R3 Abschwächung allgemeiner Faktoren \gls{kuenstlicheintelligenz}-Systeme}
  \label{tab:chapter6r31}
\end{table}



\end{samepage}
%\end{minipage}



\pagebreak



Wie kann man \textit{modellspezifische Faktoren} beim Lernen von Unsicherheiten in \gls{machinelearning}-Modellen abschwächen?

\begin{table}[!htpb]
  \centering
  \footnotesize
  \begin{tabularx}{\textwidth}{|l|X|X|}
    \hline
    \textbf{Modellspezifische Faktoren} & \hspace{0.6em}\textbf{Abschwächung der Unsicherheitsabschätzung} & \hspace{0.6em}\textbf{Quellen} \\ \hline

    \multirow{3}{*}{1. Prior-Verteilungen} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Auswahl robusterer Priors und Anpassung der Priors an die Daten.
    \end{itemize}
    &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Gal et al. \parencite[Kap.~2.3]{gal2016uncertainty}
    \end{itemize} \\ \hline

    \multirow{3}{*}{2. Likelihood-Funktion} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Optimierung der Likelihood-Modelle, z. B. durch mehrdimensionale Likelihoods.
    \end{itemize}
    &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Blundell et al. \parencite[Kap.~3]{blundell2015weight}
    \end{itemize} \\ \hline

    \multirow{3}{*}{3. Posterior Approximation} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Verwendung effizienter Verfahren wie \gls{variationalinference}.
    \end{itemize}
    &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Gal et al. \parencite[S.~40–41]{gal2016uncertainty}
    \end{itemize} \\ \hline

    \multirow{3}{*}{4. Regularisierung} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Anwendung stärkerer Regularisierungstechniken.
    \end{itemize}
    &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Gal et al. \parencite[S.~41–42]{gal2016uncertainty}
    \end{itemize} \\ \hline

    \multirow{3}{*}{5. Bayesische Optimierung} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Optimierung von Hyperparametern unter Unsicherheit.
    \end{itemize}
    &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Rasmussen et al. \parencite[Kap.~7.4]{rasmussen2006gaussian}
    \end{itemize} \\ \hline

    \multirow{3}{*}{6. Datenqualität} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Verbesserung der Datenqualität durch Bereinigung.
    \end{itemize}
    &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Bishop et al. \parencite[S.~16]{bishop2006pattern}
    \end{itemize} \\ \hline

    \multirow{3}{*}{7. Maßstab} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Skalierung der Modelle auf größere Datenmengen.
    \end{itemize}
    &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Gal et al. \parencite[S.~29–31]{gal2016uncertainty}
    \end{itemize} \\ \hline

  \end{tabularx}
  \caption{R3.1 Abschwächung modellspezifischer Faktoren \gls{Bayesianische neuronale Netze}}
  \label{tab:chapter6r32}
\end{table}


\begin{table}[!htpb]
  \centering
  \footnotesize
  \begin{tabularx}{\textwidth}{|l|X|X|}
    \hline
    \textbf{Modellspezifische Faktoren} & \hspace{0.6em}\textbf{Abschwächung der Unsicherheitsabschätzung} & \hspace{0.6em}\textbf{Quellen} \\ \hline

    \multirow{4}{*}{1. Prior-Funktion} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Verwendung flexibler Prior-Funktionen, die an die Daten angepasst sind.
    \end{itemize}
    &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Sensoy et al. \parencite{sensoy2018evidential}
    \end{itemize} \\ \hline

    \multirow{4}{*}{2. Evidenzfunktion} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Einsatz multimodaler Evidenzfunktionen.
    \end{itemize}
    &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Sensoy et al. \parencite[S.~3–4]{sensoy2018evidential}
    \end{itemize} \\ \hline

    \multirow{3}{*}{3. Posterior Approximation} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Nutzung präziser Näherungsverfahren wie \gls{Markov Chain Monte Carlo}.
    \end{itemize}
    &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Sensoy et al. \parencite[S.~4]{sensoy2018evidential}
    \end{itemize} \\ \hline

    \multirow{5}{*}{4. Evidenz Optimierung} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Optimierung der Evidenzparameter zur Vermeidung hoher Unsicherheit.
    \end{itemize}
    &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Sensoy et al. \parencite[S.~5]{sensoy2018evidential}
    \end{itemize} \\ \hline

    \multirow{3}{*}{5. Evidenzbasierte Regularisierung} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Stärkere Regularisierung der Evidenzparameter.
    \end{itemize}
    &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Sensoy et al. \parencite[S.~6]{sensoy2018evidential}
    \end{itemize} \\ \hline

    \multirow{3}{*}{6. Multimodalität} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Einbindung multimodaler Modelle zur Abbildung verschiedener Unsicherheitsquellen.
    \end{itemize}
    &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Sensoy et al. \parencite[S.~6–7]{sensoy2018evidential}
    \end{itemize} \\ \hline

    \multirow{3}{*}{7. Dateninhärente Unsicherheit} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Reduktion des Rauschens in den Daten.
    \end{itemize}
    &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Kendall et al. \parencite{kendall2017uncertainties}
    \end{itemize} \\ \hline

    \multirow{4}{*}{8. Datenqualität} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Verbesserung der Datenqualität durch Datenaugmentation.
    \end{itemize}
    &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Kendall et al. \parencite{kendall2017uncertainties}
    \end{itemize} \\ \hline

    \multirow{4}{*}{9. Netzwerktiefe} &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Anpassung der Netzwerktiefe an die Komplexität der Aufgabe.
    \end{itemize}
    &
    \begin{itemize}[leftmargin=*, topsep=0em, itemsep=0em, label={}]
      \item Sensoy et al. \parencite[S.~6]{sensoy2018evidential}
    \end{itemize} \\ \hline

  \end{tabularx}
  \caption{R3.2 Abschwächung modellspezifischer Faktoren \gls{Evidenzbasierte neuronale Netze}}
  \label{tab:chapter6r33}
\end{table}

% \pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R4
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\textbf{R4} Inwieweit kann \gls{machinelearning}-basierte \gls{uncertaintyquantification} zuverlässig den in realen Anwendungsszenarien beobachteten Unsicherheiten entsprechen?
\par\vspace{1\baselineskip}\noindent

% Beweis aus Herleitung wie das einander entsprechen kann.
Gemäß \glqq{}Guide to the Uncertainty of Measurement\grqq{} (GUM) muss ingenieurstechnisch eine aussagekräftige Stichprobe über das reale Anwendungsszenario beobachtet worden sein, um eine synthetische Charakterisierung zur realen Messunsicherheit empirisch zu modellieren. Die Zuordnung von \gls{Aleatorische Unsicherheit}, \gls{Epistemische Unsicherheit} zu den im GUM beschriebenen Unsicherheitskomponenten erfolgt erläuternd im Anhang. Ein möglicher Ansatz zur Realitätsbewertung ist dann die softwaretechnische, datengetriebene Modellierung zur Signalrekonstruktion des Szenarios. Dabei müssen alle identifizierten Unsicherheitsquellen formal beschrieben sowie nach messtechnischen Kriterien kategorisiert werden, um die abgeleiteten Daten mit fundierten Vertrauens- und Zuverlässigkeitsaussagen belegen zu können.

% UQ-Pred-UQ-Data-EQ-Ensure-Framework
Bezieht man das auf gängige Optimierungen \gls{machinelearning}-basierter Surrogatmodelle im synthetischen Eingaberaum, liefern Lanini et. al ein Framework zur Bewertung von R4 zur Optimierung in einer Anwendungsdomäne. Ihre Recherche differenziert zur Beantwortung weiterhin datenbasierte und modellbasierte Unsicherheitsmetriken (vgl. Lanini et al. ~\parencite{Lanini2024}). 
\newline
Manchingal et al. distanzieren sich von der Optimierung auf Anwendungsdomänen. Als Paradigmenwechsel beschreiben Sie epistemische \gls{kuenstlicheintelligenz}. Im Kern soll nicht nur auf Wissen in Form von Daten, sondern auch auf Nicht-Wissen trainiert werden (vgl. Manchingal et al. \parencite{manchingal2025}). 

%TODO: Weiterführend argumentieren nach Feedback Daniel

\pagebreak


\textbf{Modell Evidentielles Wissen}

Ein in der Literatur üblicher Ansatz ist das Trainieren von \gls{Evidenzbasierte neuronale Netze} auf Evidentiellem Wissen zur Optimierung dessen in der Anwendungsdomäne. Manchingals Grafiken liefern die Übersicht für in VaMai in Betracht gezogene \gls{uncertaintyquantification}-Techniken in R.4.1, R.4.2, R.4.3. Dabei können insbesondere die Wahrscheinlichkeitsräume mittels Jøsangs Subjektiver Logik (\gls{subjectivelogic}) umfassend definiert werden. 

\begin{quote}
  \glqq{}Difference to [\dots] bayesian theory [is] \gls{Aleatorische Unsicherheit}, \gls{Epistemische Unsicherheit} is \textit{explicit} in \gls{subjectivelogic} [\dots].\grqq{}\par\vspace{0\baselineskip}\noindent
  \parencite[{vgl. J\o{}sang S. 42, Z.38 ff.}]{josang2016subjective}
\end{quote}

J\o{}sang liefert den Zusammenhang für \gls{Bayesianische neuronale Netze} (vgl. J\o{}sang ~\parencite[vgl. S.42]{josang2016subjective}). Er soll hier auch für \gls{EvidentialDeepLearning} gewählt werden. J\o{}sang erweitert \gls{Aleatorische Unsicherheit}, \gls{Epistemische Unsicherheit} als Unsicherheiten erster Ordnung zu Unsicherheiten zweiter Ordnung \glqq Aleatoric Opinion \grqq (\gls{aleatoricopinion}), \glqq Epistemic Opinion \grqq (\gls{epistemicopinion}) (vgl. J\o{}sang ~\parencite[{S.22, Z.10-16; S.22 Z. 17-26; S.23, Z. 5-; S.23 Z.9-12}]{josang2016subjective}). \par\vspace{1\baselineskip}\noindent

\gls{subjectivelogic} gibt eine klare Vergleichbarkeits-Hierarchie zur Mengenmodellierung für Zwischenzustände zur Unwissenheit trotz Evidenz für \gls{Evidenzbasierte neuronale Netze} zur Eingrenzung von \glqq Zero Evidence Regions \grqq{} (vgl. ~\parencite[{vgl. S.50}]{josang2016subjective}) unabhängig von gewählten in der Literatur stark individualisierten, variierenden Loss-Funktionen (vgl. Ulmer et al. \parencite{Ulmer2023}). Für VaMai interessant sind die Limitierungen evidentiellen Wissens in der Visualisierung vom binomiellen zum multinomiellen Modell, die Zuordnung dieser zu Dirichlet PDF's erster Ordnung und schließlich zweiter Ordnung in der Hyperebene zum Erarbeiten einer Meta-Unsicherheit \parencite[{S.39, 3.6.1 \glqq hyper-opinion representation\grqq, \glqq hyper-opinion and dirichlet HPDF \grqq}]{josang2016subjective} in der Szenario-Beobachtung \parencite[{S.39, Tabelle 3.3}]{josang2016subjective}. 

J\o{}sang füllt damit, \glqq [the] missing uniform definition of what is not known\grqq ~\parencite[{vgl. S.42}]{josang2016subjective} für \gls{Bayesianische neuronale Netze}, \gls{Evidenzbasierte neuronale Netze}. Unabhängig von J\o{}sangs Logik wird deutlich wie der Wahrscheinlichkeitsraum explizit evidentiell ausmodelliert, und damit über jedwede Metrik und Räume \textit{qualitativ} vergleichbar gemacht werden kann.  

Die Wahl der Logik für propabilistische Funktionen, die Glauben ausdrücken sollen, ist in der wissenschafltichen Literatur bis heute umstritten in Orientierung an erstens Bayes und zweitens Dempster Shafers Theorie (vgl. Bayes, Dempster \parencite{bayes1763essay, dempster1967upper, shafer1976mathematical}. Probabilistische Mengenmodellierung als konvexe Menge von Wahrscheinlichkeitsverteilungen der Statistik (\gls{statisticallearningtheory}) dient als \gls{machinelearning}-Grundlage (vgl. Caprio et al. \parencite{caprio2024credal}). Wobei Caprio et al. kürzliche Annahmen zur \textit{Domain Generalization} (\gls{domaingeneralization}) sowie \textit{Ground Truth} (\gls{GroundTruth}) verdeutlicht. Ebenso wird dort der VaMai begleitende Konflikt zwischen \textit{Domain Knowledge} (\gls{domainknowledge}) und \gls{domaingeneralization} aufgezeigt. Aktuell höchstes Ziel ist die autonome zeitkontinuierliche Akquise neuer Domänen eines aufgesetzten Systems. VaMai verfolgt Aspekte der \gls{domaingeneralization} in erstens hohen Dimensionalitäten, zweitens Generifizierbarkeit, drittens Modellagnostizität, sowie viertens Generalisierbarkeit über Benchmarks zur Validierung über die freie Wahl von Datensätzen mit dem Ausgangspunkt von Aminis Deep Evidential Regression (vgl. Amini et al. ~\parencite{amini2020deep}).

Hullermeier et al. zeigen dabei dahinterliegende probabilistische Mengenmodellierung (vgl. Hullermeier et al. \parencite{javanmardi2024conformalized}) in der Anwendung auf für Evidentielle Klassifikation, Denoeux für Evidentielle Regression (vgl. Denoeux \parencite{denoeux2022evidential}), jeweils in Bezug auf \gls{Aleatorische Unsicherheit}, \gls{Epistemische Unsicherheit}. In evidentieller Klassifikation äußert sich \gls{Aleatorische Unsicherheit} in der gleichmäßigen, flachen Verteilung der Massenfunktion auf die Klassen, \gls{Epistemische Unsicherheit} in einer hohen Masse auf der Vereinigungsmenge aller Klassen (auf Unbestimmtheit, Ignoranz), was auf mangelndes Wissen des Modells hindeutet. In Evidentieller Regression äußert sich \gls{Aleatorische Unsicherheit} in der Breite der Vorhersage-Intervalle, \gls{Epistemische Unsicherheit} in der Streuung oder \glqq{}Unsicherheit der Unsicherheiten\grqq{}, also darin, wie sicher das Modell selbst über seine Unsicherheitsangaben ist. Im Gegensatz zur evidenzbasierten Klassifikation ist evidenzbasierte Regression methodenunabhängig stets mit einer epistemischen Unsicherheit verbunden, die aus der Diskretisierung des kontinuierlichen Signals und der jeweiligen Modellannahme des Autors resultiert. Amini zeigt diese Zusammenhänge kompakt: \glqq Die evidenzbasierte Regression lernt gleichzeitig ein kontinuierliches Ziel mit aleatorischer (Daten) und epistemischer (Modell) Unsicherheit. Bei einer Eingabe wird das Netz so trainiert, dass es die Parameter [ $(\alpha, \beta, \sigma, \nu)$ ] einer Evidenzverteilung vorhersagt, die eine Wahrscheinlichkeitsverteilung höherer Ordnung [zur Zeit i.d.R. zweiter Ord.] über die einzelnen Likelihood-Parameter ($\mu$, $\sigma^{2}$) modelliert.\grqq{} (vgl. Amini et al. \parencite[{S.1, Abbildung 1}]{amini2020deep}).

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.5\textwidth]{../figures/x1.png}
  \caption{R4.1 \glqq Evidential Deep Learning\grqq{} nach Amini et al. 2020}
\end{figure}

% Grafik erläutern, beginnend mit Datum.
Als weiterer Methodenbaustein soll \glqq{}\textit{epistemic learning}\grqq{} nach Manchingal eingeführt werden. R4.1 stellt dies gegenüber dem konventionellem Lernprozess. Ein Datensatz (in R.4.2 \glqq{}Training set\grqq{}) $\mathcal{D} = \{ (\mathbf{x}_i, y_i) \}_{i=1}^N$ trägt nach Manchingal implizit die Kosten zum Erhalt der \gls{machinelearning} Label-Information des Datensatzes als Akquisitions-Funktion. Nicht jeder Datenpunkt bringt demnach denselben Informationsgewinn. Die \glqq{}Datum\grqq{}-Punkte stehen für unbeschriftete Datenbeispiele. Ihre Position in einem Diagramm würde zeigen, wie nützlich im Sinne der Reduktion \gls{Epistemische Unsicherheit} und wie kostenintensiv es wäre, gerade diese Punkte zu labeln, um das Vertrauen im Modell gezielt zu steigern. Das Label-Kosten-Verhältnis ist für Klassifikation sowie Regression gültig. 

\begin{align*}
\text{Acquisition}(x)
&:=
\left.
\frac{
I\bigl(y ; \theta \mid \mathcal{D}, x \bigr)
}{
c(x)
}
\right|_{\text{\gls{Bayesianische neuronale Netze}}}
\\[2ex]
&:=
\left.
\frac{
\mathrm{Var}\left[ \mu \mid x \right]
}{
c(x)
}
\right|_{\text{\gls{Evidenzbasierte neuronale Netze}}}
\end{align*}

Es ergibt sich im Active Learning als \gls{machinelearning}-Untergebiet allgemein nach Kosten-Nutzen-Rechnung mit Informationsgewinn als wählbare Unsicherheitsgröße - hier Information Gain für \gls{Bayesianische neuronale Netze}, Varianz für \gls{Evidenzbasierte neuronale Netze} - des jeweiligen Modells pro Kosten wie Houlsby für \gls{Bayesianische neuronale Netze} aufzeigt (vgl. Houlsby ~\parencite[S.9 \glqq{}Bayesian active learning by disagreement (BALD)\grqq{}]{houlsby2011bayesian}). 

\begin{figure}[!ht]
  \centering
  \includegraphics[width=\textwidth]{../figures/x3.png}
  \caption{R4.2 \glqq Epistemic Learning\grqq nach Manchingal et al. 2025}
\end{figure}

Akquisitions-kriterienbasiert wählt evidentielles Lernen Punkte niedriger Kosten, hohen Nutzens gewählter Unsicherheitsgröße und nicht nur unsichere Punkte wie im klassischen \gls{machinelearning}-Prozess. Kanten \glqq{}Learning\grqq{}, \glqq{}Epistemic Learning\grqq{} der Grafik R.4.2 repräsentieren das Zuordnen eines Punktes aus dem Datenset in den jeweiligen Modellraum. Flächen der jeweiligen Dimension markieren, die mit der Unsicherheit assoziierten Sigma-Bereiche im epistemischen Modell, im Gegensatz zur klassischen Punktdarstellung. In der Grafik Punkt zu Flächen, allgemein der Dimensions-Unterschied ist ebenso im Ziel- oder Parameterraum vorhanden. Das klassiche Modell liefert hier eine propabilistische Punktvorhersage im $n$-Simplex der Mannigfaltigkeit der Verteilungen über den Ziel- oder Parameterraum. Das epistemische Modell liefert einen Unterraum im $n$-Simplex der Mannigfaltigkeit der Verteilungen als probabilistische Fläche $n$-ter Dimension, der über Jøsangs \gls{subjectivelogic} ausdefiniert werden kann (vgl. Jøsang \parencite{subjectivelogic}).

\begin{figure}[!ht]
  \centering
  \includegraphics[width=\textwidth]{../figures/x2.png}
  \caption{R4.3 \glqq{}Major approaches to uncertainty in AI\grqq{} nach Manchingal et al. 2025}
\end{figure}

Abschließend für Evidentielles Wissen im Modell sollen nach R.4.3 die Hauptansätze nach Manchingal zur \gls{uncertaintyquantification} zusammengefasst werden wie sie auch in VaMai in Betracht gezogen werden, wobei diese Arbeit den Fokus auf den evidentiellen Ansatz legt.

\paragraph{Frequentistisch:} Modelliert nur \gls{Aleatorische Unsicherheit}. Keine \gls{Epistemische Unsicherheit} enthalten. Ergebnis sind Punkt-, Intervallschätzungen wie 
\(\hat{y} \pm \text{CI}\). Beispiel ist die klassische Regression.

\paragraph{Bayesisch:} Modelliert \gls{Epistemische Unsicherheit} über Wahrscheinlichkeitsverteilungen auf Parametern \(\theta\). Ergebnis: posterior 
\(p(\theta \mid \mathcal{D})\). Beispiel sind \gls{Bayesianische neuronale Netze}, Dropout.

\paragraph{Evidentiell:} Modelliert \gls{Aleatorische Unsicherheit} und \gls{Epistemische Unsicherheit} über Hyper-Verteilungen wie Dirichlet, Normal-Inverse-Gamma. Ergebnis sind  Hyperparameter \((\alpha, \beta, \nu, \sigma)\). Die Meta-Unsicherheit ist über Varianz der Hyperparameter messbar.

\paragraph{Plausibilitätsmengen:} Modelliert \gls{Epistemische Unsicherheit} als konvexe Mengen von Wahrscheinlichkeitsverteilungen. Ergebnis ist  
\(\mathcal{P} = \{ P \in \text{probabilities} : \text{constraints} \}\). Erlaubt Meta-Unsicherheit darüber, welche Verteilungen plausibel sind.

\par\vspace{1\baselineskip}\noindent



\textbf{Modell evidentielles Nicht-Wissen}

Während der vorige Abschnitt evidentielles Wissen behandelt, soll dieser komplementär die Modellierung expliziten Nicht-Wissens für \gls{Evidenzbasierte neuronale Netze}, insbesondere für Eingaben außerhalb des Trainingsbereichs, behandeln. Diese Technik adressiert primär \gls{Epistemische Unsicherheit}, indem das Modell gezielt darauf trainiert wird, bei unbekannten Eingaben geringe Evidenz auszugeben. Dazu werden \gls{Out-of-Distribution}-Beispiele in das Training integriert und die Loss-Funktion um eine \gls{kullbackleibler}-Divergenz ergänzt, welche die evidenzielle Dirichlet-Verteilung möglichst nahe an eine uniforme Verteilung bringt (vgl. Malinin et al. \parencite[S.3, Z.22-28]{malinin2019uncertainty}, Amini et al. \parencite[S.4, Z.10-16]{amini2020deep}, Ovadia et al. \parencite[S.4, Z.5-15]{ovadia2019can}):

\begin{equation}
\text{Loss}_{\text{total}} 
= \text{Loss}_{\text{in}} 
+ \lambda \cdot \text{KL}\bigl(\text{Dir}(\boldsymbol{\alpha}) \,\|\, \text{Uniform}\bigr).
\end{equation}

Dadurch wird verhindert, dass das Modell bei unbekannten Eingaben fälschlich hohe Evidenzwerte signalisiert, obwohl es in diesen Regionen unsicher ist. Bei Regression kann analog die Varianz gezielt maximiert werden, indem \(\alpha\) und \(\beta\) auf niedrige Werte gesetzt werden. So lernt das \gls{Evidenzbasierte neuronale Netze}, Nicht-Wissen explizit durch geringe Evidenz und hohe Unsicherheit auszudrücken. Dieses Konzept steht in engem Zusammenhang mit Jøsangs \glqq{}epistemic opinion\grqq{}, die bei fehlender Evidenz eine gleichmäßige Unwissenheitsverteilung ausdrückt (vgl. Jøsang \parencite[S. 22]{josang2016subjective}). Die explizite Modellierung evidenziellen Nicht-Wissens bietet so die Möglichkeit Modelle robuster gegen unbekannte Situationen zu machen. Die Praxis liefert dafür Benchmarkmethoden wie CleverHans zur Simulation eines \glqq{}Angriffs\grqq{} auf das Modell mit fälschlichen Angaben (vgl. Papernot et al. ~\parencite{papernot2016cleverhans}).



% Die spezifischen Aufgaben dieser Arbeit umfassen:

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% A1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{A1} Durchführung einer umfassenden Literaturübersicht über UQ-Techniken in der \gls{machinelearning}-basierten Surrogatmodellierung.
\par\vspace{1\baselineskip}\noindent

Der Beitrag zur umfassenden Literaturübersicht über UQ-Techniken in der \gls{machinelearning}-basierten Surrogatmodellierung wird auf \gls{Evidenzbasierte neuronale Netze} eingegrenzt. In \gls{Evidenzbasierte neuronale Netze} soll zwischen \textit{In-} und \textit{Exklusionskriterien} unterschieden werden.

\begin{table}[htbp]
\centering
\footnotesize
\begin{tabularx}{\textwidth}{|l|X|}
\hline
\textbf{Kriterium} & \hspace{0.6em}\textbf{Beschreibung} \\ \hline
\multirow{7}{*}{\centering Inklusionskriterien} &
\begin{itemize}[topsep=0em, itemsep=0em, leftmargin=*, label={}]
  \item Evidential Deep Learning oder evidenzbasierte Unsicherheitsmodellierung
  \item Peer-reviewed oder relevante arXiv-Preprints
  \item Mit Experimenten oder Anwendungen
  \item Publikationen 2016–2025
  \item Englischsprachig
\end{itemize} \\ \hline
\multirow{7}{*}{\centering Exklusionskriterien} &
\begin{itemize}[topsep=0em, itemsep=0em, leftmargin=*, label={}]
  \item Keine Implementierung oder rein theoretisch ohne \gls{EvidentialDeepLearning}-Bezug
  \item Nur Bayesian NNs/Ensembles ohne evidenzielle Ansätze
  \item Rein technische Papers ohne Unsicherheitsbezug
  \item Nicht-englischsprachig
  \item Nur Poster oder Abstracts ohne Volltext
\end{itemize} \\ \hline
\end{tabularx}

\caption{A1 Auswahlkriterien für die Literaturübersicht zu \gls{EvidentialDeepLearning}}
\label{tab:auswahlkriterien}
\end{table}


% Fragenkatalog der mit Scopes abgedeckt werden soll. 

% Wie wird Evidential Deep Learning zur Quantifizierung von Unsicherheit in neuronalen Netzen eingesetzt?

% Welche Methoden, Benchmarks und Anwendungen existieren für EDL?

% Was ist die optimale Loss-Funktion für EDL?

% Welche mathematischen Grundlagen liegen Evidential Deep Learning zugrunde?

% Wie ist die Verbindung zwischen EDL und Subjective Logic?

% Worin unterscheiden sich Evidential Deep Learning und Bayesian Deep Learning?

% Welche Architekturen eignen sich für Evidential Learning?

% Welche Modifikationen sind an klassischen CNNs, RNNs, Transformers für EDL nötig?

% Wie werden evidenzielle Layer in bestehende Architekturen integriert?

% Worin liegen die Unterschiede zwischen Evidential Loss und Standard-Loss-Funktionen wie Cross Entropy?

% Welche Rolle spielt KL-Regularisierung im Kontext von EDL?

% Wie geht EDL mit fehlerhaften oder unsicheren Labels um?

% Worin unterscheiden sich epistemische und aleatorische Unsicherheiten bei EDL?

% Wie können evidenzielle Parameter interpretiert werden?

% Welche Benchmarks werden typischerweise für EDL genutzt (z. B. MNIST, CIFAR-10, OOD-Tests)?

% Wie schneidet EDL im Vergleich zu Bayesian Neural Networks und Deep Ensembles ab?

% Welche Anwendungsgebiete gibt es für EDL, insbesondere in Bereichen wie Autonomous Driving oder Industrie 4.0?

% Welche Herausforderungen bestehen aktuell bei Training und Einsatz von Evidential Deep Learning?

% Welche Overconfidence-Probleme können bei EDL auftreten?

% Wie skalierbar ist Evidential Deep Learning auf große Modelle und Datensätze?

% Wie verhält sich EDL im Vergleich zu deterministischen Methoden mit nachträglicher Kalibrierung?

Für die Literaturübersicht wurde ein Fragenkatalog generiert, der mit seinen Schwerpunkten folgende Scopes ergeben hat. 

\begin{table}[htbp]
\centering
\footnotesize
\begin{tabularx}{\textwidth}{|l|X|}
\hline
\textbf{Scope} & \textbf{Beschreibung} \\ \hline

\multirow{3}{*}{1. Theoretische Grundlagen}\label{sec:edlscopesTheoretischeGrundlagenTab1} &
1.1. Mathematische Formulierung von \gls{EvidentialDeepLearning}\label{sec:edlscopesMathematischeFormulierungenVonEDLTab1} \newline
1.2. Verbindung zu Subjektiver Logik nach Jøsang\label{sec:edlscopesVerbindungZuSubjectiveLogicTab1} \newline
1.3. Unterschiede zu Bayesian Deep Learning\label{sec:edlscopesUnterschiedeZuBayesianDeepLearningTab1} \\ \hline

\multirow{3}{*}{2. Architekturen}\label{sec:edlscopesArchitekturenTab1} &
2.1. Netzarchitekturen für \gls{EvidentialDeepLearning}\label{sec:edlscopesNetzarchitekturenFuerEvidentialDeepLearningTab1} \newline
2.2. Modifikationen an klassischen CNNs, RNNs, Transformers\label{sec:edlscopesModifikationAnKlassischenCNNRNNTransformersTab1} \newline
2.3. Integration evidenzieller Layer\label{sec:edlscopesIntegrationEvidenziellerLayerTab1} \\ \hline

\multirow{3}{*}{3. Loss Funktionen}\label{sec:edlscopesLossFunctionsTab1} &
3.1. Evidential Loss vs. Standard Cross Entropy\label{sec:edlscopesEvidentialLossVSStandardCrossEntropyTab1} \newline
3.2. KL-Regularisierung\label{sec:edlscopesKLRegularisierungTab1} \newline
3.3. Umgang mit fehlerhaften Labels\label{sec:edlscopesUmgangMitFehlerhaftenLabelsTab1} \\ \hline

\multirow{2}{*}{4. Unsicherheitstypisierung} \label{sec:edlscopesUnsicherheitstypisierungTab1} &
4.1. \gls{Epistemische Unsicherheit} vs. \gls{Aleatorische Unsicherheit}\label{sec:edlscopesEpistemischeVSAleatorischeUnsicherheitTab1} \newline
4.2. Interpretation evidenzieller Parameter\label{sec:edlscopesInterpretationEvidenziellerParameterTab1} \\ \hline

\multirow{2}{*}{5. Benchmarks}\label{sec:edlscopesBenchmarksTab1} &
5.1. Typische Datensätze (MNIST, CIFAR-10, OOD-Tests)\label{sec:edlscopesTypsischeDatensätzeTab1} \newline
5.2. Vergleich zu Bayesian NNs und Ensembles\label{sec:edlscopesVergleichZuBayesianNNundEnsemblesTab1} \\ \hline

\multirow{2}{*}{6. Anwendungsgebiete}\label{sec:edlscopesAnwendungsgebieteTab1} &
6.1. Autonomes Fahren\label{sec:edlscopesAutonomesFahrenTab1} \newline
6.2. Industrie 4.0\label{sec:edlscopesIndustieVierNullTab1} \\ \hline

\multirow{3}{*}{7. Vergleich zu anderen Methoden}\label{sec:edlscopesVergleichZuAnderenMethodenTab1} &
7.1. \gls{Bayesianische neuronale Netze}\label{sec:edlscopesBayesianNeuralNetworksTab1} \newline
7.2. Deep Ensembles\label{sec:edlscopesDeepEnsemblesTab1} \newline
7.3. Deterministische Methoden mit Calibration\label{sec:edlscopesDeterministischeMethodenMitCalibrationTab1} \\ \hline

\multirow{3}{*}{8. Herausforderungen}\label{sec:edlscopesHerausforderungenTab1} &
8.1. Trainingsstabilität\label{sec:edlscopesTrainingsstabilitaetTab1} \newline
8.2. Overconfidence-Probleme\label{sec:edlscopesOverconfidenceProblemeTab1} \newline
8.3. Skalierbarkeit auf große Modelle\label{sec:edlscopesSkalierbarkeitGrosseModelleTab1} \\ \hline

\end{tabularx}
\caption{A1 Scopes der Fragen der Literaturübersicht zu \gls{EvidentialDeepLearning}}
\label{tab:edl_scopes}
\end{table}

\pagebreak

Mit den \textbf{A1} \textit{Scopes der Fragen der Literaturübersicht zu \gls{EvidentialDeepLearning}} wurden folgende 
\textbf{A1} \textit{Scopes der Antworten der Literaturübersicht zu \gls{EvidentialDeepLearning}} mit zugehörigen Quellen definiert. 

% \begin{table}[htbp]
% \centering
% \footnotesize
% \begin{tabularx}{\textwidth}{|>{\centering\arraybackslash}l|X|l|}
% \hline
% \textbf{Scope} & \textbf{Beschreibung} & \textbf{Quelle} \\ \hline

% \multirow{2}{*}{1.1.}\label{sec:edlscopesMathematischeFormulierungenVonEDLTab2} &
% \href{https://arxiv.org/abs/1806.01768}{Sensoy et al. (2018): Evidential Deep Learning to Quantify Classification Uncertainty} \newline
% \href{https://proceedings.mlr.press/v202/pandey23a/pandey23a.pdf}{Sensoy et al. (2023): Evidential Deep Learning: Theory and Practice}
% &
% \begin{tabular}[t]{@{}l@{}}
% \cite{sensoy2018evidential} \\
% \cite{sensoy2023tutorial}
% \end{tabular} \\ \hline

% \multirow{1}{*}{1.2.}\label{sec:edlscopesVerbindungZuSubjectiveLogicTab2} &
% \href{https://doi.org/10.1007/978-3-319-42337-1}{Jøsang (2016): Subjective Logic}
% &
% \begin{tabular}[t]{@{}l@{}}
% \cite{josang2016subjective}
% \end{tabular} \\ \hline

% \multirow{2}{*}{1.3.}\label{sec:edlscopesUnterschiedeZuBayesianDeepLearningTab2} &
% \href{https://arxiv.org/abs/1703.04977}{Kendall \& Gal (2017): What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?} \newline
% \href{https://arxiv.org/abs/2306.10174}{Peters et al. (2023): On the Mathematical Consistency of Evidential Learning}
% &
% \begin{tabular}[t]{@{}l@{}}
% \cite{kendall2017uncertainties} \\
% \cite{peters2023consistency}
% \end{tabular} \\ \hline

% \multirow{2}{*}{2.1.}\label{sec:edlscopesNetzarchitekturenFuerEvidentialDeepLearningTab2} &
% \href{https://arxiv.org/abs/1910.02600}{Amini et al. (2020): Deep Evidential Regression} \newline
% \href{https://arxiv.org/abs/2404.11806}{Tian et al. (2024): Evidential Graph Neural Networks}
% &
% \begin{tabular}[t]{@{}l@{}}
% \cite{amini2020deep} \\
% \cite{tian2024egnn}
% \end{tabular} \\ \hline

% \multirow{2}{*}{2.2.}\label{sec:edlscopesModifikationAnKlassischenCNNRNNTransformersTab2} &
% \href{https://arxiv.org/abs/2003.02037}{Sensoy et al. (2020): Uncertainty-Aware Deep Classification} \newline
% Dordevic et al. (2024): Evidential Transformers for Improved Image Retrieval
% &
% \begin{tabular}[t]{@{}l@{}}
% \cite{sensoy2020uncertainty} \\
% \cite{dordevic2024evidential}
% \end{tabular} \\ \hline

% \multirow{2}{*}{2.3.}\label{sec:edlscopesIntegrationEvidenziellerLayerTab2} &
% \href{https://arxiv.org/abs/2205.14871}{Zhou et al. (2022): Evidential Transformer Networks} \newline
% Dordevic et al. (2024): Evidential Transformers for Improved Image Retrieval
% &
% \begin{tabular}[t]{@{}l@{}}
% \cite{zhou2022evidential} \\
% \cite{dordevic2024evidential}
% \end{tabular} \\ \hline

% \multirow{1}{*}{3.1.}\label{sec:edlscopesEvidentialLossVSStandardCrossEntropyTab2} &
% \href{https://arxiv.org/abs/1806.01768}{Sensoy et al. (2018): Evidential Loss Function (Evidential Deep Learning)}
% &
% \begin{tabular}[t]{@{}l@{}}
% \cite{sensoy2018evidential}
% \end{tabular} \\ \hline

% \multirow{2}{*}{3.2.}\label{sec:edlscopesKLRegularisierungTab2} &
% \href{https://arxiv.org/abs/2003.02037}{Sensoy et al. (2020): KL-Regularization in Evidential Networks} \newline
% \href{https://arxiv.org/abs/2307.08743}{Amini et al. (2023): Improved KL Regularization for Evidential Regression}
% &
% \begin{tabular}[t]{@{}l@{}}
% \cite{sensoy2020uncertainty} \\
% \cite{amini2023kl}
% \end{tabular} \\ \hline

% \multirow{1}{*}{3.3.}\label{sec:edlscopesUmgangMitFehlerhaftenLabelsTab2} &
% \href{https://arxiv.org/abs/1802.04865}{Dhamija et al. (2018): Reducing Model Confidence for Out-of-Distribution Detection}
% &
% \begin{tabular}[t]{@{}l@{}}
% \cite{dhamija2018reducing}
% \end{tabular} \\ \hline

% \multirow{2}{*}{4.1.}\label{sec:edlscopesEpistemischeVSAleatorischeUnsicherheitTab2} &
% \href{https://arxiv.org/abs/1703.04977}{Kendall \& Gal (2017): Aleatoric and Epistemic Uncertainty} \newline
% Tran et al. (2023): Separating Aleatoric and Epistemic Uncertainty in Evidential Models
% &
% \begin{tabular}[t]{@{}l@{}}
% \cite{kendall2017uncertainties} \\
% \cite{tran2023separating}
% \end{tabular} \\ \hline

% \multirow{1}{*}{4.2.}\label{sec:edlscopesInterpretationEvidenziellerParameterTab2} &
% \href{https://arxiv.org/abs/1910.02600}{Amini et al. (2020): Interpreting evidential parameters in regression tasks}
% &
% \begin{tabular}[t]{@{}l@{}}
% \cite{amini2020deep}
% \end{tabular} \\ \hline

% \multirow{2}{*}{5.1.}\label{sec:edlscopesTypsischeDatensätzeTab2} &
% \href{https://arxiv.org/abs/1910.02600}{Amini et al. (2020): Evaluation on MNIST, CIFAR-10, OOD} \newline
% Bohlke et al. (2023): Evaluation on CIFAR-100C, ImageNet-O
% &
% \begin{tabular}[t]{@{}l@{}}
% \cite{amini2020deep} \\
% \cite{dordevic2024evidential}
% \end{tabular} \\ \hline

% \multirow{2}{*}{5.2.}\label{sec:edlscopesVergleichZuBayesianNNundEnsemblesTab2} &
% \href{https://arxiv.org/abs/1612.01474}{Lakshminarayanan et al. (2017): Deep Ensembles as Baseline for Uncertainty} \newline
% Tran et al. (2023): Comparative Benchmarks
% &
% \begin{tabular}[t]{@{}l@{}}
% \cite{lakshminarayanan2017simple} \\
% \cite{tran2023separating}
% \end{tabular} \\ \hline

% \multirow{1}{*}{6.1.}\label{sec:edlscopesAutonomesFahrenTab2} &
% \href{https://arxiv.org/abs/2210.10992}{Feng et al. (2022): Evidential Uncertainty in Autonomous Driving}
% &
% \begin{tabular}[t]{@{}l@{}}
% \cite{feng2022review}
% \end{tabular} \\ \hline

% \multirow{2}{*}{6.2.}\label{sec:edlscopesIndustieVierNullTab2} &
% \href{https://doi.org/10.1109/TII.2022.3190238}{Wang et al. (2022): Uncertainty Modeling in Industrial AI} \newline
% Gupta et al. (2023): Evidential Learning for Industrial Predictive Maintenance \newline
% Chen et al. (2024): Uncertainty Estimation in Vision-Language Models
% &
% \begin{tabular}[t]{@{}l@{}}
% \cite{wang2022uncertainty} \\
% \cite{gupta2023industrialedl} \\
% \cite{chen2024vlm}
% \end{tabular} \\ \hline

% \multirow{1}{*}{7.1.}\label{sec:edlscopesBayesianNeuralNetworksTab2} &
% \href{https://arxiv.org/abs/1506.02142}{Gal \& Ghahramani (2016): Dropout as Bayesian Approximation}
% &
% \begin{tabular}[t]{@{}l@{}}
% \cite{gal2016dropout}
% \end{tabular} \\ \hline

% \multirow{1}{*}{7.2.}\label{sec:edlscopesDeepEnsemblesTab2} &
% \href{https://arxiv.org/abs/1612.01474}{Lakshminarayanan et al. (2017): Deep Ensembles}
% &
% \begin{tabular}[t]{@{}l@{}}
% \cite{lakshminarayanan2017simple}
% \end{tabular} \\ \hline

% \multirow{2}{*}{7.3.}\label{sec:edlscopesDeterministischeMethodenMitCalibrationTab2} &
% \href{https://arxiv.org/abs/1706.04599}{Guo et al. (2017): On Calibration of Modern Neural Networks} \newline
% Tran et al. (2023): Comparison of calibration in evidential vs. deterministic methods
% &
% \begin{tabular}[t]{@{}l@{}}
% \cite{guo2017calibration} \\
% \cite{tran2023separating}
% \end{tabular} \\ \hline

% \multirow{2}{*}{8.1.}\label{sec:edlscopesTrainingsstabilitaetTab2} &
% \href{https://arxiv.org/abs/2003.02037}{Sensoy et al. (2020): Training stability in evidential networks} \newline
% \href{https://arxiv.org/abs/2306.10174}{Peters et al. (2023): Loss function degeneracies}
% &
% \begin{tabular}[t]{@{}l@{}}
% \cite{sensoy2020uncertainty} \\
% \cite{peters2023consistency}
% \end{tabular} \\ \hline

% \multirow{2}{*}{8.2.}\label{sec:edlscopesOverconfidenceProblemeTab2} &
% \href{https://arxiv.org/abs/1802.04865}{Dhamija et al. (2018): Overconfidence in neural networks} \newline
% Chen et al. (2024): Overconfidence in multimodal evidential learning
% &
% \begin{tabular}[t]{@{}l@{}}
% \cite{dhamija2018reducing} \\
% \cite{chen2024vlm}
% \end{tabular} \\ \hline

% \multirow{2}{*}{8.3.}\label{sec:edlscopesSkalierbarkeitGrosseModelleTab2} &
% \href{https://arxiv.org/abs/2205.14871}{Zhou et al. (2022): Scalability of evidential transformers} \newline
% Bohlke et al. (2023): Scalability challenges in large Vision Transformers
% &
% \begin{tabular}[t]{@{}l@{}}
% \cite{zhou2022evidential} \\
% \cite{dordevic2024evidential}
% \end{tabular} \\ \hline

% \end{tabularx}
% \caption{A1 Scopes der Antworten der Literaturübersicht zu \gls{EvidentialDeepLearning} mit aktuellen Quellen (2016–2025)}
% \label{tab:edl_scopes_sources_updated}
% \end{table}

\begin{footnotesize}
\begin{longtable}{|>{\centering\arraybackslash}p{0.8cm}|p{11.8cm}|p{0.8cm}|}
\hline
\textbf{Scope} & \textbf{Beschreibung} & \textbf{Quelle} \\
\hline
\endfirsthead

\hline
\textbf{Scope} & \textbf{Beschreibung} & \textbf{Quelle} \\
\hline
\endhead

\hline
\multicolumn{3}{r}{\textit{Fortsetzung auf nächster Seite}} \\
\endfoot

\endlastfoot

% --- Table Content Starts Here ---

\multirow{2}{*}{1.1.} &
\href{https://arxiv.org/abs/1806.01768}{Sensoy et al. (2018): Evidential Deep Learning to Quantify Classification Uncertainty} \newline
\href{https://proceedings.mlr.press/v202/pandey23a/pandey23a.pdf}{Sensoy et al. (2023): Evidential Deep Learning: Theory and Practice}
&
\begin{tabular}[t]{@{}l@{}}
\cite{sensoy2018evidential} \\
\cite{sensoy2023tutorial}
\end{tabular} \\ \hline

1.2. &
\href{https://doi.org/10.1007/978-3-319-42337-1}{Jøsang (2016): Subjective Logic}
&
\cite{josang2016subjective} \\ \hline

\multirow{2}{*}{1.3.} &
\href{https://arxiv.org/abs/1703.04977}{Kendall \& Gal (2017): What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?} \newline
\href{https://arxiv.org/abs/2306.10174}{Peters et al. (2023): On the Mathematical Consistency of Evidential Learning}
&
\begin{tabular}[t]{@{}l@{}}
\cite{kendall2017uncertainties} \\
\cite{peters2023consistency}
\end{tabular} \\ \hline

\multirow{2}{*}{2.1.} &
\href{https://arxiv.org/abs/1910.02600}{Amini et al. (2020): Deep Evidential Regression} \newline
\href{https://arxiv.org/abs/2404.11806}{Tian et al. (2024): Evidential Graph Neural Networks}
&
\begin{tabular}[t]{@{}l@{}}
\cite{amini2020deep} \\
\cite{tian2024egnn}
\end{tabular} \\ \hline

\multirow{2}{*}{2.2.} &
\href{https://arxiv.org/abs/2003.02037}{Sensoy et al. (2020): Uncertainty-Aware Deep Classification} \newline
Dordevic et al. (2024): Evidential Transformers for Improved Image Retrieval
&
\begin{tabular}[t]{@{}l@{}}
\cite{sensoy2020uncertainty} \\
\cite{dordevic2024evidential}
\end{tabular} \\ \hline

\multirow{2}{*}{2.3.} &
\href{https://arxiv.org/abs/2205.14871}{Zhou et al. (2022): Evidential Transformer Networks} \newline
Dordevic et al. (2024): Evidential Transformers for Improved Image Retrieval
&
\begin{tabular}[t]{@{}l@{}}
\cite{zhou2022evidential} \\
\cite{dordevic2024evidential}
\end{tabular} \\ \hline

3.1. &
\href{https://arxiv.org/abs/1806.01768}{Sensoy et al. (2018): Evidential Loss Function (Evidential Deep Learning)}
&
\cite{sensoy2018evidential} \\ \hline

\multirow{2}{*}{3.2.} &
\href{https://arxiv.org/abs/2003.02037}{Sensoy et al. (2020): KL-Regularization in Evidential Networks} \newline
\href{https://arxiv.org/abs/2307.08743}{Amini et al. (2023): Improved KL Regularization for Evidential Regression}
&
\begin{tabular}[t]{@{}l@{}}
\cite{sensoy2020uncertainty} \\
\cite{amini2023kl}
\end{tabular} \\ \hline

3.3. &
\href{https://arxiv.org/abs/1802.04865}{Dhamija et al. (2018): Reducing Model Confidence for Out-of-Distribution Detection}
&
\cite{dhamija2018reducing} \\ \hline

\multirow{2}{*}{4.1.} &
\href{https://arxiv.org/abs/1703.04977}{Kendall \& Gal (2017): Aleatoric and Epistemic Uncertainty} \newline
Tran et al. (2023): Separating Aleatoric and Epistemic Uncertainty in Evidential Models
&
\begin{tabular}[t]{@{}l@{}}
\cite{kendall2017uncertainties} \\
\cite{tran2023separating}
\end{tabular} \\ \hline

4.2. &
\href{https://arxiv.org/abs/1910.02600}{Amini et al. (2020): Interpreting evidential parameters in regression tasks}
&
\cite{amini2020deep} \\ \hline

\multirow{2}{*}{5.1.} &
\href{https://arxiv.org/abs/1910.02600}{Amini et al. (2020): Evaluation on MNIST, CIFAR-10, OOD} \newline
Bohlke et al. (2023): Evaluation on CIFAR-100C, ImageNet-O
&
\begin{tabular}[t]{@{}l@{}}
\cite{amini2020deep} \\
\cite{dordevic2024evidential}
\end{tabular} \\ \hline

\multirow{2}{*}{5.2.} &
\href{https://arxiv.org/abs/1612.01474}{Lakshminarayanan et al. (2017): Deep Ensembles as Baseline for Uncertainty} \newline
Tran et al. (2023): Comparative Benchmarks
&
\begin{tabular}[t]{@{}l@{}}
\cite{lakshminarayanan2017simple} \\
\cite{tran2023separating}
\end{tabular} \\ \hline

6.1. &
\href{https://arxiv.org/abs/2210.10992}{Feng et al. (2022): Evidential Uncertainty in Autonomous Driving}
&
\cite{feng2022review} \\ \hline

\multirow{3}{*}{6.2.} &
\href{https://doi.org/10.1109/TII.2022.3190238}{Wang et al. (2022): Uncertainty Modeling in Industrial AI} \newline
Gupta et al. (2023): Evidential Learning for Industrial Predictive Maintenance \newline
Chen et al. (2024): Uncertainty Estimation in Vision-Language Models
&
\begin{tabular}[t]{@{}l@{}}
\cite{wang2022uncertainty} \\
\cite{gupta2023industrialedl} \\
\cite{chen2024vlm}
\end{tabular} \\ \hline

7.1. &
\href{https://arxiv.org/abs/1506.02142}{Gal \& Ghahramani (2016): Dropout as Bayesian Approximation}
&
\cite{gal2016dropout} \\ \hline

7.2. &
\href{https://arxiv.org/abs/1612.01474}{Lakshminarayanan et al. (2017): Deep Ensembles}
&
\cite{lakshminarayanan2017simple} \\ \hline

\multirow{2}{*}{7.3.} &
\href{https://arxiv.org/abs/1706.04599}{Guo et al. (2017): On Calibration of Modern Neural Networks} \newline
Tran et al. (2023): Comparison of calibration in evidential vs. deterministic methods
&
\begin{tabular}[t]{@{}l@{}}
\cite{guo2017calibration} \\
\cite{tran2023separating}
\end{tabular} \\ \hline

\multirow{2}{*}{8.1.} &
\href{https://arxiv.org/abs/2003.02037}{Sensoy et al. (2020): Training stability in evidential networks} \newline
\href{https://arxiv.org/abs/2306.10174}{Peters et al. (2023): Loss function degeneracies}
&
\begin{tabular}[t]{@{}l@{}}
\cite{sensoy2020uncertainty} \\
\cite{peters2023consistency}
\end{tabular} \\ \hline

\multirow{2}{*}{8.2.} &
\href{https://arxiv.org/abs/1802.04865}{Dhamija et al. (2018): Overconfidence in neural networks} \newline
Chen et al. (2024): Overconfidence in multimodal evidential learning
&
\begin{tabular}[t]{@{}l@{}}
\cite{dhamija2018reducing} \\
\cite{chen2024vlm}
\end{tabular} \\ \hline

\multirow{2}{*}{8.3.} &
\href{https://arxiv.org/abs/2205.14871}{Zhou et al. (2022): Scalability of evidential transformers} \newline
Bohlke et al. (2023): Scalability challenges in large Vision Transformers
&
\begin{tabular}[t]{@{}l@{}}
\cite{zhou2022evidential} \\
\cite{dordevic2024evidential}
\end{tabular} \\ \hline

\caption{A1 Scopes der Antworten der Literaturübersicht zu \gls{EvidentialDeepLearning} mit aktuellen Quellen (2016–2025)}
\label{tab:edl_scopes_sources_updated}

\end{longtable}
\end{footnotesize}

Hochwertige, zentrale Umfragen sind Ulmer et al. \parencite{Ulmer2023}, Gawlikowski et al. \parencite{Gawlikowski2023}. 
Der Zusammenhang der modellbasierten, evidenzbasierten Unsicherheit zu jener der Realdaten ist im Anhang. %\ref{sec:enn_gum_derivation}.

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% A2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{A2} Identifizierung und Analyse geeigneter Unsicherheitsmetriken für Surrogatmodelle, wobei zwischen \gls{Aleatorische Unsicherheit} und \gls{Epistemische Unsicherheit} unterschieden wird.

\begin{table}[!htpb]
  \centering
  \scriptsize
  \begin{tabularx}{\textwidth}{|>{\centering\arraybackslash}l|X|X|}
    \hline
    & \hspace{0.6em}\textbf{Datenbasierte Metriken} & \hspace{0.6em}\textbf{Modellbasierte Metriken} \\
    \hline

    \multirow{10}{*}{\textbf{\gls{Aleatorische Unsicherheit}}} &
    \parbox[t]{\linewidth}{
      \begin{itemize}[topsep=0em, itemsep=0.4em, leftmargin=*, label={}]
        \item Standardabweichung des Rauschens:
        
        \( \sigma = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2} \)
        
        \begin{scriptsize}\textit{Quelle:} Bishop et al. \parencite[S.~28–30]{bishop2006pattern}\end{scriptsize}
        
        \item Varianz der Residuen:
        
        \( \text{Var} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 \)
        
        \begin{scriptsize}\textit{Quelle:} Bishop et al. \parencite[S.~28–30]{bishop2006pattern}\end{scriptsize}
      \end{itemize}
    }
    &
    \parbox[t]{\linewidth}{
      \begin{itemize}[topsep=0em, itemsep=0.4em, leftmargin=*, label={}]
        \item Bayesianische Unsicherheit (Posterior):
        
        \( p(\theta \mid \mathcal{D}) \)
        
        \begin{scriptsize}\textit{Quelle:} Rasmussen et al. \parencite[Kap.~2]{rasmussen2006gaussian}\end{scriptsize}
        
        \item Kreuzvalidierung:
        
        Bewertung auf Trainings- und Testdaten
        
        \begin{scriptsize}\textit{Quelle:} Blundell et al. \parencite{blundell2015weight}\end{scriptsize}
      \end{itemize}
    }
    \\ \hline

    \multirow{10}{*}{\textbf{\gls{Epistemische Unsicherheit}}} &
    \parbox[t]{\linewidth}{
      \begin{itemize}[topsep=0em, itemsep=0.4em, leftmargin=*, label={}]
        \item Fehleranalyse auf Testdaten:
        
        \( \text{Fehler} = \sum_{i=1}^{n} |y_i - \hat{y}_i| \)
        
        \begin{scriptsize}\textit{Quelle:} Bishop et al. \parencite[S.~30–32]{bishop2006pattern}\end{scriptsize}
      \end{itemize}
    }
    &
    \parbox[t]{\linewidth}{
      \begin{itemize}[topsep=0em, itemsep=0.4em, leftmargin=*, label={}]
        \item Konfidenzintervall:
        
        \( \hat{y} \pm z \cdot \sigma \)
        
        \begin{scriptsize}\textit{Quelle:} Gal et al. \parencite[S.~40–42]{gal2016uncertainty}\end{scriptsize}
        
        \item Entropie der Posterior-Verteilung:
        
        \( H(p) = - \sum_{i} p(x_i) \log(p(x_i)) \)
        
        \begin{scriptsize}\textit{Quelle:} Sensoy et al. \parencite{sensoy2018evidential}\end{scriptsize}
      \end{itemize}
    }
    \\ \hline

  \end{tabularx}
  \caption{A2 Unsicherheitsmetriken für Surrogatmodelle}
  \label{tab:chapter6r61}
\end{table}



\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% A3
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{A3} Vergleich \textit{modellspezifischer} und \textit{anwendungsspezifischer} Bewertungsmetriken für die Quantifizierung von Unsicherheit.
\par\vspace{1\baselineskip}\noindent
% Beispiel-Anwendungsdomäne: [Beispiel-Domäne]
Für den Vergleich werden Anwendungen im Ingenieurswesen vorgeschlagen: 

\begin{table}[!htbp]
\scriptsize
\begin{tabularx}{\textwidth}{|l|X|}
\hline
\textbf{Domäne} & \textbf{Typische Anwendungen} \\
\hline
Strukturmechanik & Spannungsanalyse, Lebensdauerberechnung \\
\hline
Aerodynamik & CFD-Simulation, Drag/Lift-Koeffizienten \\
\hline
Fahrzeugbau & Crashsimulation, Akustik, Thermomanagement \\
\hline
Akustik & Modalanalyse, Schallausbreitung \\
\hline
Materialwissenschaft & Materialeigenschaften, Werkstoffdesign \\
\hline
Geophysik & Erdbebensimulation, Bodenmechanik \\
\hline
Prozesssimulation & Chemische Reaktoren, Prozessoptimierung \\
\hline
Energie & Batterie-Management, Netzstabilität \\
\hline
\end{tabularx}
\caption{Anwendungsdomänen im Ingenieurwesen für \gls{machinelearning}-Surrogatmodelle nach Gawlikowski, Ulmer}
\label{tab:ingenieurwesen-domains-small}
\end{table}

% Anwendungsspezifikation:
Als Beispiel-Domäne zum Vergleich der \textit{modellspezifischen} und \textit{anwendungsspezifischen} Unsicherheitsmetriken für Surrogatmodelle im Autonomen Fahren wird der Fahrzeugbau gewählt. Die genannten Anwendungsdomänen sind zusammengetragen aus Gawlikowski et al. \parencite{Gawlikowski2023} sowie Ulmer et al. \parencite{Ulmer2023}. Beide Werke behandeln typische Einsatzfelder von \gls{machinelearning}-basierten Surrogatmodellen im Ingenieurwesen.

\begin{table}[!htpb]
	\centering
	\footnotesize
	\begin{tabularx}{\textwidth}{|>{\centering\arraybackslash}l|X|X|}
		\hline
		& \hspace{0.6em}\textbf{Modellspezifische Metriken} 
		& \hspace{0.6em}\textbf{Anwendungsspezifische Metriken} \\
		\hline
		
		\multirow{14}{*}{\textbf{\gls{Aleatorische Unsicherheit}}} &
		
		\begin{itemize}[topsep=0em, itemsep=0.125em, leftmargin=*, label={}]
			\item \texttt{RMSE:} Abweichung zwischen vorhergesagten und tatsächlichen Sensordaten (z. B. Positionen von Objekten) \par
			\begin{scriptsize}\textit{Quelle:} Bishop et al. \parencite[S.~224–226]{bishop2006pattern}\end{scriptsize}
			
			\item \texttt{MAE:} Mittlere absolute Abweichung bei Objekterkennung oder Trajektorien \par
			\begin{scriptsize}\textit{Quelle:} Bishop et al. \parencite[S.~224–226]{bishop2006pattern}\end{scriptsize}
			
			\item \texttt{KL($P\Vert Q$):} Abweichung zwischen Vorhersage- und Ground-Truth-Wahrscheinlichkeitsverteilungen \par
			\begin{scriptsize}\textit{Quelle:} Rasmussen et al. \parencite[Kap.~2]{rasmussen2006gaussian}\end{scriptsize}
		\end{itemize}
		&
		
		\begin{itemize}[topsep=0em, itemsep=0.125em, leftmargin=*, label={}]
			\item \texttt{Accuracy:} Korrektheit der Objekterkennung (z. B. Fußgänger erkannt/nicht erkannt) \par
			\begin{scriptsize}\textit{Quelle:} Bishop et al. \parencite[S.~40–42]{bishop2006pattern}\end{scriptsize}
			
			\item \texttt{F1-Score:} Balance zwischen Präzision und Recall bei der Objekterkennung \par
			\begin{scriptsize}\textit{Quelle:} Bishop et al. \parencite[S.~40–42]{bishop2006pattern}\end{scriptsize}
			
			\item \texttt{AUC:} Trennschärfe bei der Klassifikation sicherer vs. unsicherer Szenarien \par
			\begin{scriptsize}\textit{Quelle:} Bishop et al. \parencite[S.~40–42]{bishop2006pattern}\end{scriptsize}
		\end{itemize}
		\\
		\hline
		
		\multirow{12}{*}{\textbf{\gls{Epistemische Unsicherheit}}} &
		
		\begin{itemize}[topsep=0em, itemsep=0.125em, leftmargin=*, label={}]
			\item \texttt{$\mathcal{L}(\theta)$:} Loss-Funktion inkl. Unsicherheitsanteile (z. B. evidentieller Loss) \par
			\begin{scriptsize}\textit{Quelle:} Sensoy et al. \parencite{sensoy2018evidential}\end{scriptsize}
			
			\item \texttt{BMA:} Mittelung mehrerer Modellposteriors für robustere Unsicherheiten \par
			\begin{scriptsize}\textit{Quelle:} Blundell et al. \parencite{blundell2015weight}\end{scriptsize}
			
			\item \texttt{CI:} Konfidenzintervalle für kritische Größen (z. B. Zeit bis Kollision) \par
			\begin{scriptsize}\textit{Quelle:} Gal et al. \parencite[S.~40–42]{gal2016uncertainty}\end{scriptsize}
		\end{itemize}
		&
		
		\begin{itemize}[topsep=0em, itemsep=0.125em, leftmargin=*, label={}]
			\item \texttt{Fehler $\epsilon$:} Abweichung von vorhergesagten zu tatsächlichen Sicherheitsabständen \par
			\begin{scriptsize}\textit{Quelle:} Bishop et al. \parencite[S.~233–235]{bishop2006pattern}\end{scriptsize}
			
			\item \texttt{$H(p)$:} Entropie der Klassifikationsausgabe als Maß epistemischer Unsicherheit \par
			\begin{scriptsize}\textit{Quelle:} Ovadia et al. \parencite{ovadia2019can}\end{scriptsize}
			
			\item \texttt{AUC-PR:} Leistungsfähigkeit bei seltenen, kritischen Klassen (z. B. seltene Gefahrensituationen) \par
			\begin{scriptsize}\textit{Quelle:} Ovadia et al. \parencite{ovadia2019can}\end{scriptsize}
		\end{itemize}
		\\
		\hline
		
	\end{tabularx}
	\caption{Vergleich modellspezifischer und anwendungsspezifischer Unsicherheitsmetriken für Surrogatmodelle im autonomen Fahren}
	\label{tab:chapter6r71}
\end{table}



\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% A4
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{A4} Untersuchung und Vergleich verschiedener \gls{uncertaintyquantification}-Ansätze für \gls{machinelearning}-basierte Surrogatmodelle, insbesondere \gls{Bayesianische neuronale Netze} und \gls{Conformal Prediction}.
\par\vspace{1\baselineskip}\noindent

% A4 Untersuchung:
Zur Untersuchung von A4 wird der Vergleich zwischen \gls{Bayesianische neuronale Netze}s und \gls{Conformal Prediction} auf Grundlage identischer Modellarchitekturen und Datensätze durchgeführt. Für \gls{Bayesianische neuronale Netze}s werden die Implementierungen von Herrn Mavani in NumPyro/JAX genutzt (HMC und SVI) \parencite{nmavani2025}. Für \gls{Conformal Prediction} wird ein separates Skript erstellt, das auf denselben Netzen basiert, jedoch \gls{confidenceinterval} mittels Konformitäts-Quantilen auf einem Calibration-Set berechnet.

\begin{table}[htbp]
  \centering
  \footnotesize
  \begin{tabularx}{\textwidth}{|l|X|}
  \hline
  \textbf{Aspekt} & \hspace{0.6em}\textbf{Details} \\ \hline

  \multirow{7}{*}{\textbf{Vergleichskriterien}} &
  \begin{itemize}[topsep=0em, itemsep=0em, leftmargin=*, label={}]
    \item RMSE, MAE der Punktvorhersagen
    \item \gls{calibrationerror}
    \item Coverage-Rate der \gls{confidenceinterval}
    \item Durchschnittliche Breite der \gls{confidenceinterval}
    \item Rechenzeit für Training und Vorhersage
  \end{itemize}
  \\ \hline

  \multirow{6}{*}{\textbf{Ziel der Analyse}} &
  \begin{itemize}[topsep=0em, itemsep=0em, leftmargin=*, label={}]
    \item Unterschiede der Verfahren hinsichtlich:
      \begin{itemize}[topsep=0em, itemsep=0em, leftmargin=*, label={}]
        \item Trennung \gls{Epistemische Unsicherheit} und \gls{Aleatorische Unsicherheit} (nur bei \gls{Bayesianische neuronale Netze}s)
        \item Strikten Garantien für Unsicherheitsintervalle (nur bei \gls{Conformal Prediction})
        \item Ressourcenbedarf und Skalierbarkeit
      \end{itemize}
  \end{itemize}
  \\ \hline

  \end{tabularx}
  \caption{A4 Vergleichskriterien und Analyseziele für \gls{EvidentialDeepLearning} zu anderen Methoden}
  \label{tab:vergleichskriterien}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% A5
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{A5} Untersuchung des theoretischen Einflusses verschiedener Faktoren auf die \gls{uncertaintyquantification} ausgewählter Modelle.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  A5 /assets/repos/BA__U-i-mlb-Sm-f-d-s-V-a-S__tex/prototypes/prototype_s8-02-07-25/prototype_s8-02-07-25.py
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% A5 Vergleich

\begin{table}[!htpb]
  \centering
  \footnotesize
  \begin{tabularx}{\textwidth}{|>{\centering\arraybackslash}l|X|X|}
    \hline
      & \hspace{0.6em}\textbf{\gls{Bayesianische neuronale Netze}} 
      & \hspace{0.6em}\textbf{\gls{Conformal Prediction}} \\
    \hline

    \multirow{9}{*}{\textbf{\gls{Aleatorische Unsicherheit}}} &

    \begin{minipage}[t]{\linewidth}
    \vspace{0.3em}
    \begin{itemize}[leftmargin=*, label={}, itemsep=0.2em, topsep=0em, parsep=0em]
      \item Posterior-Verteilung \( p(\theta \mid \mathcal{D}) \)
      \item \begin{scriptsize}\textit{Quelle:} Blundell et al. \parencite[Kap.~3]{blundell2015weight}\end{scriptsize}
      \item Unsicherheitsquantifizierung über Modellparameter auf Trainingsdaten
      \item \begin{scriptsize}\textit{Quelle:} Gal et al. \parencite[S.~40–42]{gal2016uncertainty}\end{scriptsize}
      \item MC Dropout
      \item \begin{scriptsize}\textit{Quelle:} Gal et al. \parencite[S.~40–42]{gal2016uncertainty}\end{scriptsize}
    \end{itemize}
    \vspace{0.3em}
    \end{minipage}
    &

    \begin{minipage}[t]{\linewidth}
    \vspace{0.3em}
    \begin{itemize}[leftmargin=*, label={}, itemsep=0.2em, topsep=0em, parsep=0em]
      \item Konfidenzintervall \( \hat{y} \pm z \cdot \sigma \)
      \item \begin{scriptsize}\textit{Quelle:} Vovk et al. \parencite[S.~4–5]{vovk2005algorithmic}\end{scriptsize}
      \item Unsicherheitsquantifizierung durch Konfidenzintervalle
      \item \begin{scriptsize}\textit{Quelle:} Angelopoulos et al. \parencite{angelopoulos2021gentle}\end{scriptsize}
      \item Ensemble-Methoden
      \item \begin{scriptsize}\textit{Quelle:} Angelopoulos et al. \parencite{angelopoulos2021gentle}\end{scriptsize}
    \end{itemize}
    \vspace{0.3em}
    \end{minipage} \\
    \hline

    \multirow{9}{*}{\textbf{\gls{Epistemische Unsicherheit}}} &

    \begin{minipage}[t]{\linewidth}
    \vspace{0.3em}
    \begin{itemize}[leftmargin=*, label={}, itemsep=0.2em, topsep=0em, parsep=0em]
      \item Bayesianische Unsicherheit \( p(\theta \mid \mathcal{D}) \)
      \item \begin{scriptsize}\textit{Quelle:} Gal et al. \parencite[S.~40–42]{gal2016uncertainty}\end{scriptsize}
      \item \gls{bayesianischeinferenz}: Unsicherheitsquantifizierung über bay. Modellparameter
      \item \begin{scriptsize}\textit{Quelle:} Mac Kay et al. \parencite{mackay1992practical}\end{scriptsize}
      \item \gls{variationalinference}: Posterior-Approximation
      \item \begin{scriptsize}\textit{Quelle:} Gal et al. \parencite[S.~40–42]{gal2016uncertainty}\end{scriptsize}
    \end{itemize}
    \vspace{0.3em}
    \end{minipage}
    &

    \begin{minipage}[t]{\linewidth}
    \vspace{0.3em}
    \begin{itemize}[leftmargin=*, label={}, itemsep=0.2em, topsep=0em, parsep=0em]
      \item Vertrauensregionen
      \item \begin{scriptsize}\textit{Quelle:} Angelopoulos et al. \parencite{angelopoulos2021gentle}\end{scriptsize}
      \item Prädiktive Unsicherheitsquantifizierung durch Konfidenzintervalle
      \item \begin{scriptsize}\textit{Quelle:} Shafer et al. \parencite[S.~63–65]{shafer2008tutorial}\end{scriptsize}
      \item GPR: UQ-Ansatz mit Kernel-Methoden und Training
      \item \begin{scriptsize}\textit{Quelle:} Rasmussen et al. \parencite{rasmussen2006gaussian}\end{scriptsize}
    \end{itemize}
    \vspace{0.3em}
    \end{minipage} \\
    \hline

  \end{tabularx}
  \caption{A5 Vergleich der \gls{uncertaintyquantification}-Ansätze für \gls{Bayesianische neuronale Netze} und \gls{Conformal Prediction}}
  \label{tab:chapter6r81}
\end{table}



\paragraph{Vergleichs-Score} Der Vergleichs-Score wird berechnet als:
{
  \[\footnotesize
  \text{Score} = w_\text{err} \cdot \frac{\text{RMSE}}{\text{Norm}_\text{RMSE}}
  + w_\text{ECE} \cdot \frac{\text{ECE}}{\text{Norm}_\text{ECE}}
  + w_\text{width} \cdot \frac{\text{IntervalWidth}}{\text{Norm}_\text{Width}}
  + w_\text{runtime} \cdot \frac{\text{Runtime}}{\text{Norm}_\text{Runtime}}
  \]
  \[
  \footnotesize
  = 0{,}5 \cdot \frac{\text{RMSE}}{10{,}0}
  + 0{,}3 \cdot \frac{\text{ECE}}{1{,}0}
  + 0{,}1 \cdot \frac{\text{IntervalWidth}}{5{,}0}
  + 0{,}1 \cdot \frac{\text{Runtime}}{30{,}0}
  \]
}

\paragraph{Begründung der Norm-Parametrisierung für Vergleichs-Score} Empirisch ergab sich aus der Ausführung des Vergleichsskripts: Erstens, die RMSE schwankt zwischen $0{,}3$ und $3{,}0$, daher wird $\text{Norm}_\text{RMSE} = 10{,}0$ gesetzt, um ausreichend Spielraum zu lassen. Zweitens, die ECE ist eine Wahrscheinlichkeit im Intervall $[0,1]$, sodass sich $\text{Norm}_\text{ECE} = 1{,}0$ direkt ergibt. Drittens, die Intervallbreite liegt auf Hardwarekonfiguration 1 zwischen $2{,}0$ und $4{,}5$, weshalb $\text{Norm}_\text{Width} = 5{,}0$ als konservative Obergrenze gewählt wird. Viertens, die Laufzeit reicht von etwa $2\,\text{s}$ (CP) bis $25\,\text{s}$ (\gls{hmc}), daher wird $\text{Norm}_\text{Runtime} = 30{,}0$ gewählt, um die gesamte Spanne abzudecken.
\par\vspace{1\baselineskip}\noindent

\paragraph{Begründung der Gewichtungsfaktoren für Vergleichs-Score} Erstens, das Fehlermaß RMSE geht mit $w_\text{err} = 0{,}5$ am stärksten in die Bewertung ein, da die Vorhersagegenauigkeit im Zentrum der Modellgüte steht. Zweitens, die Kalibrierung wird durch $w_\text{ECE} = 0{,}3$ gewichtet, da eine realistische Unsicherheitsquantifizierung für verlässliche Modelle essenziell ist. Drittens, die mittlere Intervallbreite wird mit $w_\text{width} = 0{,}1$ berücksichtigt, da sie als sekundäres Kriterium eher die Informationsdichte als die primäre Modellqualität beeinflusst.  Viertens, die Laufzeit geht mit $w_\text{runtime} = 0{,}1$ ein, um recheneffiziente Modelle bevorzugt zu behandeln, ohne Genauigkeit und Kalibrierung zu überlagern.



\clearpage



\begin{table}[!htbp]
  \centering
  \footnotesize
  \begin{tabularx}{\textwidth}{|>{\arraybackslash}X|X|X|X|X|X|X|}
  \hline
  \textbf{Methode} & \textbf{RMSE} & \textbf{MAE} & \textbf{Coverage} & \textbf{\gls{calibrationerror}} & \textbf{\gls{meanconfidenceintervalwidth}} & \textbf{Score} \\
  \hline
  \gls{Bayesianische neuronale Netze} \gls{hmc} & 6.845 & 5.697 & 0.010 & 0.990 & 2.404 & 1.3988 \\
  \hline
  \gls{Bayesianische neuronale Netze} \gls{svi} & 1367.638 & 1046.232 & 0.020 & 0.980 & 70.001 & 69.8022 \\
  \hline
  \gls{Conformal Prediction} & 0.096 & 0.075 & 0.870 & 0.130 & 0.267 & 0.0493 \\
  \hline
  \end{tabularx}
  \caption{Vergleich der Modelle \gls{Bayesianische neuronale Netze} (\gls{hmc}, \gls{svi}) und \gls{Conformal Prediction} hinsichtlich Performanz und Unsicherheitsquantifizierung.}
  \label{tab:r8_results}
\end{table}



% \par\vspace{1\baselineskip}\noindent
\paragraph{Interpretation der Ergebnisse}\par\vspace{1\baselineskip}\noindent

1. \textbf{\gls{Bayesianische neuronale Netze} \gls{hmc}}: Liefert moderaten Fehler (RMSE $\approx$ 6{,}8), geringe \gls{Epistemische Unsicherheit}, aber extrem geringe Coverage. Die Unsicherheitsintervalle decken die wahren Werte kaum ab, was ein Overconfidence-Problem zeigt.\\
2. \textbf{\gls{Bayesianische neuronale Netze} \gls{svi}}: Scheitert deutlich. Sehr hoher RMSE ($\approx$ 1367) und große epistemische Varianz deuten auf Instabilität oder falsche Konvergenz hin.\\
3. \textbf{\gls{Conformal Prediction}}: Erzielt sehr niedrige Fehler (RMSE $\approx$ 0{,}096), gute Coverage (ca. 87\,\%) und den besten Score. Die Methode empfiehlt sich auf diesem Datensatz.



\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% A6
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{A6} Untersuchung des theoretischen Einflusses verschiedener Faktoren auf die Unsicherheitsschätzungen ausgewählter Modelle.
\par\vspace{1\baselineskip}\noindent

A6 soll mit minimaler Sensitivitätsanalyse am Beispiel \gls{Evidenzbasierte neuronale Netze} ausgeführt werden, um den theoretischen Modellparameter-Einfluss auf die \gls{uncertaintyquantification} zu quantifizieren. Variiert werden die Evidenzparameter $\nu$ sowie Trainingsdatengröße $N_{train}$ für geringen Analyseaufwand.

% Untersuchung - Most Minimal Sensitivitäts-Analyse: 
% S1: Modelldefinition: 
% S2: Parameterbereich
% S3: Durchführung der Analyse

% Vergleich ausgewählter Modelle

\begin{table}[!htpb]
  \centering
  \footnotesize
  \begin{tabularx}{\textwidth}{|>{\centering\arraybackslash}l|X|X|X|}
    \hline
    & \hspace{0.6em}\textbf{BNN} 
    & \hspace{0.6em}\textbf{CP} 
    & \hspace{0.6em}\textbf{ENN} \\
    \hline

    \multirow{7}{*}{\textbf{A}} & 
    \begin{minipage}[t]{\linewidth}
    \vspace{0.3em}
    \begin{itemize}[leftmargin=*, label={}, itemsep=0.125em, topsep=0em, parsep=0em]
        \item Post. \( p(\theta \mid \mathcal{D}) \) \par
        \begin{scriptsize}\textit{Quelle:} Blundell et al. \parencite*[Kap.~3]{blundell2015weight}\end{scriptsize}
        \item \gls{uncertaintyquantification} ü. Modellparameter \par
        \begin{scriptsize}\textit{Quelle:} Gal et al. \parencite*[S.~40–42]{gal2016uncertainty}\end{scriptsize}
        \item MC Dropout \par
        \begin{scriptsize}\textit{Quelle:} Gal et al. \parencite*[S.~40–42]{gal2016uncertainty}\end{scriptsize}
    \end{itemize}
    \vspace{0.3em}
    \end{minipage} &

    \begin{minipage}[t]{\linewidth}
    \vspace{0.3em}
    \begin{itemize}[leftmargin=*, label={}, itemsep=0.125em, topsep=0em, parsep=0em]
        \item CI \( \hat{y} \pm z \cdot \sigma \) \par
        \begin{scriptsize}\textit{Quelle:} Vovk et al. \parencite*[S.~4–5]{vovk2005algorithmic}\end{scriptsize}
        \item \gls{uncertaintyquantification} ü. Konfidenzintervalle \par
        \begin{scriptsize}\textit{Quelle:} Angelopoulos et al. \parencite*{angelopoulos2021gentle}\end{scriptsize}
        \item Ensemble \par
        \begin{scriptsize}\textit{Quelle:} Angelopoulos et al. \parencite*{angelopoulos2021gentle}\end{scriptsize}
    \end{itemize}
    \vspace{0.3em}
    \end{minipage} &

    \begin{minipage}[t]{\linewidth}
    \vspace{0.3em}
    \begin{itemize}[leftmargin=*, label={}, itemsep=0.125em, topsep=0em, parsep=0em]
        \item Prediktive Vert. \( p(y \mid \mu, \alpha, \beta, \nu) \)
        \item Evidenzparameter \( \nu, \alpha, \beta \)
    \end{itemize}
    \vspace{0.3em}
    \end{minipage} \\
    \hline

    \multirow{7}{*}{\textbf{B}} & 
    \begin{minipage}[t]{\linewidth}
    \vspace{0.3em}
    \begin{itemize}[leftmargin=*, label={}, itemsep=0.125em, topsep=0em, parsep=0em]
        \item Modellparameter: Gewichte \( w_i \) \par
        \begin{scriptsize}\textit{Quelle:} Mac Kay et al. \parencite*[S.~448–450]{mackay1992practical}\end{scriptsize}
        \item Einfluss von Prioren \par
        \begin{scriptsize}\textit{Quelle:} Rasmussen et al. \parencite*[Kap.~5]{rasmussen2006gaussian}\end{scriptsize}
        \item Hyperparameter-Sensitivität \par
        \begin{scriptsize}\textit{Quelle:} Rasmussen et al. \parencite*[Kap.~5]{rasmussen2006gaussian}\end{scriptsize}
    \end{itemize}
    \vspace{0.3em}
    \end{minipage} &

    \begin{minipage}[t]{\linewidth}
    \vspace{0.3em}
    \begin{itemize}[leftmargin=*, label={}, itemsep=0.125em, topsep=0em, parsep=0em]
        \item \gls{uncertaintyquantification} über CI \par
        \begin{scriptsize}\textit{Quelle:} Shafer et al. \parencite*[S.~63–65]{shafer2008tutorial}\end{scriptsize}
        \item Einfluss von \gls{confidenceregion} \par
        \begin{scriptsize}\textit{Quelle:} Vovk et al. \parencite*{vovk2005algorithmic}\end{scriptsize}
    \end{itemize}
    \vspace{0.3em}
    \end{minipage} &

    \begin{minipage}[t]{\linewidth}
    \vspace{0.3em}
    \begin{itemize}[leftmargin=*, label={}, itemsep=0.125em, topsep=0em, parsep=0em]
        \item Evidenzparameter \( \nu, \alpha, \beta \)
        \item steuern Unsicherheitsanteile.
    \end{itemize}
    \vspace{0.3em}
    \end{minipage} \\
    \hline

    \multirow{5}{*}{\textbf{C}} & 
    \begin{minipage}[t]{\linewidth}
    \vspace{0.3em}
    \begin{itemize}[leftmargin=*, label={}, itemsep=0.125em, topsep=0em, parsep=0em]
        \item Bayessche Inferenz zur \gls{uncertaintyquantification} \par
        \begin{scriptsize}\textit{Quelle:} Gal et al. \parencite*[S.~41–42]{gal2016uncertainty}\end{scriptsize}
        \item MC-Simulation mit Dropout \par
        \begin{scriptsize}\textit{Quelle:} Blundell et al. \parencite*{blundell2015weight}\end{scriptsize}
    \end{itemize}
    \vspace{0.3em}
    \end{minipage} &

    \begin{minipage}[t]{\linewidth}
    \vspace{0.3em}
    \begin{itemize}[leftmargin=*, label={}, itemsep=0.125em, topsep=0em, parsep=0em]
        \item Ensemble zur \gls{uncertaintyquantification} \par
        \begin{scriptsize}\textit{Quelle:} Angelopoulos et al. \parencite*{angelopoulos2021gentle}\end{scriptsize}
        \item \gls{confidenceregion}, \gls{confidenceinterval}-Analyse \par
        \begin{scriptsize}\textit{Quelle:} Shafer et al. \parencite*{shafer2008tutorial}\end{scriptsize}
    \end{itemize}
    \vspace{0.3em}
    \end{minipage} &

    \begin{minipage}[t]{\linewidth}
    \vspace{0.3em}
    \begin{itemize}[leftmargin=*, label={}, itemsep=0.125em, topsep=0em, parsep=0em]
        \item Keine Sampling-Approx. nötig
        \item \gls{kullbackleibler}-Regularisierung steuert \( E \)
    \end{itemize}
    \vspace{0.3em}
    \end{minipage} \\
    \hline

  \end{tabularx}
  \caption{A6 Übersicht der \gls{uncertaintyquantification}-Methoden \gls{Bayesianische neuronale Netze}, \gls{Conformal Prediction} und \gls{Evidenzbasierte neuronale Netze}}
  \label{tab:chapter6r91_clean}
\end{table}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% A6 **/assets/repos/BA__U-i-mlb-Sm-f-d-s-V-a-S__tex/prototypes/prototype_s9-02-07-25/*.py
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\clearpage



% S4: Auswertung
\newline 
\paragraph{Parametrisierung der Sensitivitätsanalyse \gls{Evidenzbasierte neuronale Netze}} 
\begin{equation*}
  \nu \in \{1,\ 5,\ 10,\ 20\}
\end{equation*}
\vspace{-0.2cm}
\begin{align*}
  \text{Architektur:} \quad & \text{Dense(64)} \rightarrow \text{Dense(64)} \rightarrow \text{Output: } (\gamma, \log v, \log\alpha, \log\beta) \\
  \text{Varianzen:} \quad &
      \begin{cases}
          \text{Aleatorisch: } \sigma^2_{\text{alea}} = \frac{\beta}{\alpha - 1} \\
          \text{Epistemisch: } \sigma^2_{\text{epis}} = \frac{\beta}{\nu(\alpha - 1)}
      \end{cases}
\end{align*}

\begin{table}[!htbp]
\centering
\footnotesize
\begin{tabularx}{\textwidth}{|X|X|X|X|X|X|}
\hline
\vspace{0.15em}$\nu$\vspace{0.25em}
& \vspace{0.15em}$\bar{\sigma}^2_{\text{total}}$\vspace{0.25em}
& \vspace{0.15em}$\bar{\sigma}^2_{\text{aleatoric}}$\vspace{0.25em}
& \vspace{0.15em}$\bar{\sigma}^2_{\text{epistemic}}$\vspace{0.25em}
& \vspace{0.15em}RMSE\vspace{0.25em}
& \vspace{0.15em}RUI\vspace{0.25em} \\
\hline
1  & $1.6191 \pm 0.1344$ & $0.8095 \pm 0.0672$ & $0.8095 \pm 0.0672$ & $155.7554$ & $0.0082$ \\
\hline
5  & $1.0007 \pm 0.1152$ & $0.8339 \pm 0.0960$ & $0.1668 \pm 0.0192$ & $155.8031$ & $0.0064$ \\
\hline
10 & $0.8591 \pm 0.0482$ & $0.7810 \pm 0.0439$ & $0.0781 \pm 0.0044$ & $155.0450$ & $0.0060$ \\
\hline
20 & $0.8376 \pm 0.0804$ & $0.7978 \pm 0.0766$ & $0.0399 \pm 0.0038$ & $156.6731$ & $0.0058$ \\
\hline
\end{tabularx}
\caption{A6 Min. Sensitivitätsanalyse \gls{Evidenzbasierte neuronale Netze} mit $\pm 2\sigma$}
\label{tab:enn_results}
\end{table}

Der Parameter $\nu$ steuert im \gls{Evidenzbasierte neuronale Netze} die Gewichtung zwischen \gls{Epistemische Unsicherheit} und \gls{Aleatorische Unsicherheit}, wobei kleine $\nu$-Werte die \gls{Epistemische Unsicherheit} dominieren lassen und große $\nu$-Werte die Unsicherheitszerlegung stärker zugunsten der \gls{Aleatorische Unsicherheit} Komponente verschieben.



\newline

\paragraph{Parametrisierung der Sensitivitätsanalyse \gls{Bayesianische neuronale Netze}} 
\begin{equation*}
  \text{Dropout-Raten: } \delta \in \{0.05,\ 0.10,\ 0.20,\ 0.50\}
\end{equation*}
\vspace{-0.2cm}
\begin{align*}
  \text{Architektur:} \quad & \text{Dense(64)} \rightarrow \text{Dropout}(\delta) \rightarrow \text{Dense(64)} \rightarrow \text{Dropout}(\delta) \rightarrow \text{Output: } \mu, \log\sigma^2 \\
  \text{Loss:} \quad & \mathcal{L}_{\text{BNN}} = \frac{1}{2} \log\sigma^2 + \frac{(y - \mu)^2}{2\sigma^2}
\end{align*}

\begin{table}[!htbp]
\centering
\footnotesize
\begin{tabularx}{\textwidth}{|X|X|X|X|X|X|}
\hline
\vspace{0.15em}$p_{\text{dropout}}$\vspace{0.25em} 
&\vspace{0.15em} $\bar{\sigma}^2_{\text{total}}$\vspace{0.25em}
&\vspace{0.15em} $\bar{\sigma}^2_{\text{aleatoric}}$\vspace{0.25em}
&\vspace{0.15em} $\bar{\sigma}^2_{\text{epistemic}}$\vspace{0.25em}
&\vspace{0.15em} RMSE \vspace{0.25em}
&\vspace{0.15em} \gls{relativeuncertaintyindex}\vspace{0.25em} \\
\hline
0.05 & $0.0079 \pm 0.0162$ & $0.0051 \pm 0.0108$ & $0.0028 \pm 0.0059$ & $6.8592$ & $0.0129$ \\
\hline
0.10 & $0.0164 \pm 0.0382$ & $0.0099 \pm 0.0219$ & $0.0065 \pm 0.0167$ & $6.5767$ & $0.0195$ \\
\hline
0.20 & $0.0347 \pm 0.0859$ & $0.0198 \pm 0.0460$ & $0.0150 \pm 0.0409$ & $7.2445$ & $0.0257$ \\
\hline
0.50 & $0.1482 \pm 0.3429$ & $0.0783 \pm 0.1419$ & $0.0699 \pm 0.2080$ & $8.9771$ & $0.0429$ \\
\hline
\end{tabularx}
\caption{A6 Min. Sensitivitätsanalyse \gls{Bayesianische neuronale Netze} mit $\pm 2\sigma$}
\label{tab:bnn_results}
\end{table} 

Die Dropout-Rate im \gls{Bayesianische neuronale Netze} beeinflusst direkt die \gls{Epistemische Unsicherheit}, da höhere Dropout-Raten mehr Modellvariabilität zulassen und somit größere \gls{Epistemische Unsicherheit} in den Vorhersagen erzeugen.



\newline
\paragraph{Parametrisierung der Sensitivitätsanalyse \gls{Conformal Prediction}} 
\begin{equation*}
    \alpha \in \{0.20,\ 0.10,\ 0.05,\ 0.01\}
\end{equation*}
\vspace{-0.2cm}
\begin{align*}
    \text{Modell:} \quad & \text{Random Forest Regressor (n=100)} \\
    \text{Kalibrierung:} \quad & \text{Residual-basiertes Intervall: } [\hat{y} - q_{1-\alpha},\ \hat{y} + q_{1-\alpha}]
\end{align*}

\begin{table}[!htbp]
\centering
\footnotesize
\begin{tabularx}{\textwidth}{|X|X|X|X|X|X|X|}
\hline
\vspace{0.15em}$\alpha$\vspace{0.25em}
& \vspace{0.15em}Coverage\vspace{0.25em}
& \vspace{0.15em}Mean CI-Width\vspace{0.25em}
& \vspace{0.15em}$\bar{\sigma}^2_{\text{aleatoric}}$\vspace{0.25em}
& \vspace{0.15em}$\bar{\sigma}^2_{\text{epistemic}}$\vspace{0.25em}
& \vspace{0.15em}$\bar{\sigma}^2_{\text{total}}$\vspace{0.25em}
& \vspace{0.15em}\gls{relativeuncertaintyindex}\vspace{0.25em} \\
\hline
0.20 & 0.820 & 1.0022 & $0.2088 \pm 0.9139$ & $0.3612 \pm 0.4821$ & $0.5700 \pm 0.4821$ & $1.8978$ \\
\hline
0.10 & 0.913 & 1.3215 & $0.2088 \pm 0.9139$ & $0.3612 \pm 0.4821$ & $0.5700 \pm 0.4821$ & $1.8978$ \\
\hline
0.05 & 0.953 & 1.7910 & $0.2088 \pm 0.9139$ & $0.3612 \pm 0.4821$ & $0.5700 \pm 0.4821$ & $1.8978$ \\
\hline
0.01 & 1.000 & 3.0993 & $0.2088 \pm 0.9139$ & $0.3612 \pm 0.4821$ & $0.5700 \pm 0.4821$ & $1.8978$ \\
\hline
\end{tabularx}
\caption{A6 Min. Sensitivitätsanalyse \gls{Conformal Prediction} mit $\pm 2\sigma$}
\label{tab:cp_results}
\end{table}

Das Signifikanzniveau $\alpha$ bestimmt bei \gls{Conformal Prediction} die Breite der Vorhersageintervalle, wobei kleinere $\alpha$-Werte zu höheren Konfidenzniveaus und damit breiteren, konservativeren Unsicherheitsintervallen führen.



\paragraph{Vergleichende Auswertung Modelle \gls{Bayesianische neuronale Netze}, \gls{Conformal Prediction}, \gls{Evidenzbasierte neuronale Netze}}

Die drei Tabellen zeigen die Sensitivitätsanalysen für \gls{Evidenzbasierte neuronale Netze}, \gls{Bayesianische neuronale Netze} und \gls{Conformal Prediction} unter Variation ihrer jeweiligen Steuerungsgrößen (\(\nu\), Dropout-Rate, \(\alpha\)). Als gemeinsame Kennzahlen wurden die mittlere Gesamtvarianz \(\overline{\sigma}(y)^{2}\), die mittlere aleatorische Varianz \(\overline{\sigma}^{2}_{\text{\gls{Aleatorische Unsicherheit}}}\), die mittlere epistemische Varianz \(\overline{\sigma_{\text{\gls{Epistemische Unsicherheit}}}^2}\), daneben der RMSE sowie der \gls{relativeuncertaintyindex} ausgewertet.  

Im direkten Vergleich zeigen \gls{Evidenzbasierte neuronale Netze} insgesamt höhere Varianzen, zum Beispiel bis \(\overline{\sigma}(y)^{2} \approx 1.6\), während der RMSE relativ stabil bei etwa \(155\) liegt. Die Zerlegung der Unsicherheit zeigt bei \gls{Evidenzbasierte neuronale Netze} für kleine \(\nu\) etwa gleiche Anteile zwischen \(\overline{\sigma}^{2}_{\text{\gls{Aleatorische Unsicherheit}}}\) und \(\overline{\sigma}^{2}_{\text{\gls{Epistemische Unsicherheit}}}\). Mit steigender Evidenz \(\nu\) sinkt \(\overline{\sigma}^{2}_{\text{\gls{Epistemische Unsicherheit}}}\) deutlich, wodurch sich der Anteil der Unsicherheit zunehmend auf die aleatorische Komponente verlagert. Dies verdeutlicht, dass zu geringe \(\nu\)-Werte eine \textit{Overconfidence} verhindern können, da das Modell dann größere epistemische Unsicherheit zulässt.  



\clearpage



Die \gls{Bayesianische neuronale Netze} liefern deutlich kleinere Varianzen, teilweise unter \(\overline{\sigma(y)}^{2} < 0.02\), bei gleichzeitig wesentlich niedrigerem RMSE zwischen \(6\) und \(9\). Höhere Dropout-Raten führen jedoch zu steigenden Werten sowohl für \(\overline{\sigma}^{2}_{\text{\gls{Epistemische Unsicherheit}}}\) als auch für \(\overline{\sigma}^{2}_{\text{\gls{Aleatorische Unsicherheit}}}\), was auf zunehmende Unsicherheitsstreuung hinweist. Allerdings kann ein zu niedriges Dropout-Raten-Niveau bei \gls{Bayesianische neuronale Netze}s \textit{Overconfidence} fördern, da epistemische Unsicherheit dann unterrepräsentiert bleibt.  

\gls{Conformal Prediction} liefert über alle \(\alpha\)-Level hinweg konstante mittlere Varianzwerte, da der zugrundeliegende Random-Forest-Fit unverändert bleibt. Hier beträgt \(\overline{\sigma(y)}^{2} \approx 0.57\), zusammengesetzt aus einer moderaten epistemischen Varianz \(\overline{\sigma}^{2}_{\text{\gls{Epistemische Unsicherheit}}} \approx 0.36\) und einer geringeren aleatorischen Komponente \(\overline{\sigma}^{2}_{\text{\gls{Aleatorische Unsicherheit}}} \approx 0.21\). Die \gls{relativeuncertaintyindex}-Werte liegen bei \gls{Conformal Prediction} mit ca. \(1.9\) deutlich höher, was eine relativ große Unsicherheitsbreite im Verhältnis zum RMSE (hier \(< 0.4\)) reflektiert. Durch die direkte Intervallberechnung schützt \gls{Conformal Prediction} per Konstruktion stärker gegen \textit{Overconfidence}, bleibt jedoch konservativer.  

Insgesamt zeigen die Modelle unterschiedliche Profile: Erstens, \gls{Evidenzbasierte neuronale Netze} weisen die höchsten Unsicherheitsniveaus bei konstant hohem RMSE auf. Zweitens, \gls{Bayesianische neuronale Netze} erzielen geringere Fehler und niedrigere Unsicherheiten, doch reagieren sensibel auf die gewählte Dropout-Rate. Drittens, \gls{Conformal Prediction} liefert stabile, eher breite Intervalle und sichert robuste Kalibrierung. Zusammenfassend erlauben die Kennzahlen \(\overline{\sigma(y)}^{2}\), \(\overline{\sigma}^{2}_{\text{\gls{Aleatorische Unsicherheit}}}\), \(\overline{\sigma}^{2}_{\text{\gls{Epistemische Unsicherheit}}}\), RMSE und \gls{relativeuncertaintyindex} eine methodenübergreifende Bewertung der Unsicherheiten und helfen wie grundlegend aufgezeigt \textit{Overconfidence} frühzeitig zu erkennen.



\begin{table}[!htbp]
\centering
\footnotesize
\begin{tabularx}{\textwidth}{|c|X|}
\hline
\textbf{Methode} & \hspace{0.5em}\textbf{Sensitivitätsaspekte} \\
\hline

\multirow{4}{*}{\centering \textbf{\gls{Bayesianische neuronale Netze}}} &
\begin{itemize}[topsep=0em, itemsep=0em, leftmargin=*, label={}]
    \item Breitere Posterior bei schwachen Priors; stärkere \gls{Epistemische Unsicherheit}.
    \item Höhere Dropout-Rate \(\rightarrow\) erhöht \gls{Epistemische Unsicherheit}.
\end{itemize}
\\
\hline

\multirow{6}{*}{\centering \textbf{\gls{Conformal Prediction}}} &
\begin{itemize}[topsep=0em, itemsep=0em, leftmargin=*, label={}]
    \item \gls{Conformal Prediction}-Breite steigt bei höherem Konfidenzniveau.
    \item Kleinere Calibration-Sets führen zu unsteten \gls{Conformal Prediction}s.
    \item Coverage sinkt bei zu engen Regionen; Intervallbreite steigt bei höherem \(\alpha\).
    \item Heteroskedastische Daten erzeugen stark variierende \gls{Conformal Prediction}-Breiten.
\end{itemize}
\\
\hline

\multirow{6}{*}{\centering \textbf{\gls{Evidenzbasierte neuronale Netze}}} &
\begin{itemize}[topsep=0em, itemsep=0em, leftmargin=*, label={}]
    \item Hohe \gls{Epistemische Unsicherheit} bei kleinen \(\nu\)-Werten.
    \item Niedrige \(\nu\) \(\rightarrow\) mehr epistemische Varianz.
    \item Größere Datenmengen reduzieren Unsicherheit.
    \item Zu starke KL-Regularisierung reduziert Modellvertrauen übermäßig.
\end{itemize}
\\
\hline

\end{tabularx}
\caption{A6 Zusammenfassung Sensitivität \gls{uncertaintyquantification}-Methoden \gls{Bayesianische neuronale Netze}, \gls{Conformal Prediction}, \gls{Evidenzbasierte neuronale Netze}}
\label{tab:sensitivity_r9_transposed}
\end{table}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Datensätze
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

~\nocite{BostonHousing2013}
~\nocite{CombinedCyclePowerPlant2014}
~\nocite{ConcreteCompressiveStrength1998}
~\nocite{ConditionBasedMaintenanceOfNavalPropulsionPlants2014}
~\nocite{EnergyEfficiency2012}
~\nocite{Fisher1936}
~\nocite{Cortez2009}
%~\nocite{Gains2024}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Software 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

~\nocite{DuckDBDevelopers.2024}
~\nocite{EdlPytorchDevelopers.2024}
~\nocite{LoguruDevelopers.2024}
~\nocite{MatplotlibDevelopers.2024}
~\nocite{NotebookDevelopers.2024}
~\nocite{NumpyDevelopers.2024}
~\nocite{OpenpyxlDevelopers.2024}
~\nocite{PandasDevelopers.2024}
~\nocite{ProperscoringDevelopers.2024}
~\nocite{PyroPplDevelopers.2024}
~\nocite{PytestDevelopers.2024}
~\nocite{RuffDevelopers.2024}
~\nocite{ScikitLearnDevelopers.2024}
~\nocite{ScipyDevelopers.2024}
~\nocite{SeabornDevelopers.2024}
~\nocite{SphinxDevelopers.2024}
~\nocite{TensorflowDevelopers.2024}
~\nocite{TorchDevelopers.2024}
~\nocite{TorchmetricsDevelopers.2024}
~\nocite{TorchvisionDevelopers.2024}
~\nocite{XlrdDevelopers.2024}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Repos
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

~\nocite{amini2020deep}
~\nocite{amini2020deepfork}
~\nocite{sensoy2018evidential}
~\nocite{nmavani2025}
~\nocite{windler2025}



\end{otherlanguage}
