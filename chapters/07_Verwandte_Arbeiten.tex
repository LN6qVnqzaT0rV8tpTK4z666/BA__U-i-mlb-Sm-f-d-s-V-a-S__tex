% !TeX root = ../main.tex

\chapter{Verwandte Arbeiten}\label{chapter:verwandte-arbeiten}

\parencite{Depeweg2019}
\parencite{Ulmer2023}

% \begin{itemize}
%   \item {R1} Welche auf maschinellem Lernen basierenden Surrogatmodelle sind für die Quantifizierung von Unsicherheiten geeignet?
%   \item {R2} Welche allgemeinen und modellspezifischen Faktoren beeinflussen das Lernen von Unsicherheiten in ML-Modellen?
%   \item {R3} Wie können diese Einflussfaktoren abgeschwächt werden, um die Unsicherheitsabschätzung zu verbessern?
%   \item {R4} Inwieweit kann ML-basierte Unsicherheitsquantifizierung zuverlässig den in realen Anwendungsszenarien beobachteten Unsicherheiten entsprechen?
% \end{itemize}

% Die spezifischen Aufgaben dieser Arbeit umfassen:

% \begin{itemize}
%   \item {R5} Durchführung einer umfassenden Literaturübersicht über UQ-Techniken in der ML-basierten Surrogatmodellierung.
%   \item {R6} Identifizierung und Analyse geeigneter Unsicherheitsmetriken für Surrogatmodelle, wobei zwischen aleatorischer und epistemischer Unsicherheit unterschieden wird.
%   \item {R7} Vergleich modellspezifischer und anwendungsspezifischer Bewertungsmetriken für die Quantifizierung von Unsicherheit.
%   \item {R8} Untersuchung und Vergleich verschiedener UQ-Ansätze für ML-basierte Surrogatmodelle, insbesondere Bayes'sche neuronale Netze und konforme Vorhersagen.
%   \item {R9} Untersuchung des theoretischen Einflusses verschiedener Faktoren auf die Unsicherheitsschätzungen ausgewählter Modelle.
%   \item {R10} Implementierung und Validierung der entwickelten Unsicherheitsmetriken und Modellierungstechniken in einer realistischen Anwendung, wie z.\,B. der Unsicherheitsabschätzung in kritischen Regionen von Simulationsdaten.
%   \item {R11} Verfassen eines kurzen Jupyter Notebooks, das die wichtigsten Ansätze und Ergebnisse der Arbeit zusammenfasst.
% \end{itemize}

~\parencite{Pandey.30.11.2022}




\section{Abgrenzung der Arbeit}

Die vorliegende Arbeit behandelt nicht die Entwicklung neuer Machine-Learning-Architekturen, sondern setzt bestehende Modellstrukturen Evidential Deep Learning gezielt zur Unsicherheitsbewertung in szenariobasierten Surrogatmodellen ein. Es wird keine generelle Systemidentifikation, Validierung oder Regelung entwickelt, sondern der Fokus liegt auf der Analyse, Aggregation und Interpretation von Unsicherheiten, nicht auf der dynamischen Kompensation.
Es erfolgt keine Exploration vollständiger Regelungssysteme oder klassischer MPC-Implementierungen, sondern eine Modellbetrachtung im Kontext unsicherer Eingaberaum-Szenarien. Ebenso werden keine physikalischen AUV-Experimente oder Realzeitsysteme implementiert, sondern Simulationen bzw. modellbasierte Methoden betrachtet. Die Arbeit grenzt sich außerdem ab von reiner Fehlerdiagnose, klassischer statistischer Qualitätskontrolle, vollständigen Safety-Cases oder normativer Zertifizierungsmethodik. (Ferner wird keine vollständige Methodenentwicklung im Sinne eines Software-Frameworks angestrebt, sondern eine exemplarische und forschungsnahe Anwendung dokumentiert.)
