% % !TeX root = ../main.tex

\chapter{Methodische Grundlagen}
\label{chapter:methodik}



\begin{otherlanguage}{american}
% \section{Machine Learning}

% Machine learning (ML) refers to the class of algorithms \( f_{\theta} : \mathcal{X} \rightarrow \mathcal{Y} \) that learn a model \( f_{\theta} \) from data 
% \( \mathcal{D} = \{ (x_i, y_i) \}_{i=1}^{N} \) to learn a model \( f_{\theta} \) that maps inputs \( x \in \mathcal{X} \) to predictions \( \hat{y} \in \mathcal{Y} \). This is done by optimizing the parameters \( \theta \) using an error function \( \mathcal{L}_{\text{loss}}(y, \hat{y}) \).

% \subsection{Architectures}

% The runtime for adjusting the weights of a neural network (NN) to a target function can be optimized by using different architectures for specific tasks. The abbreviations for the architectures refer to their characteristic structure.

% \paragraph{NN – Neural Network}
% A neural network approximates a function \( f_{\theta}(x) = \sigma(Wx + b) \). Here, \( \sigma \) is a nonlinear activation function, typically \textit{ReLU} or \textit{Tanh}. The parameters of the model are given by \( \theta = \{ W, b \} \), where:

% \begin{itemize}
%   \item \( W \) represents the weight matrix, e.g. 
%     \[
%       W = 
%       \begin{pmatrix}
%         w_{11} & w_{12} & \dots  & w_ {1j} \\
%         w_{21} & w_{22} & \dots  & w_{2j} \\
%         \vdots & \vdots & \ddots & \vdots \\
%         w_{i1} & w_{i2} & \dots  & w_{ij} \\
%       \end{pmatrix}
%       \in \mathbb{R}^{i \times j}
%     \]
%   \item \( b \) is a bias term that shifts the activation independently of the input signal.
% \end{itemize}

% A layer in a neural network consists of:
% \begin{enumerate}
%   \item a linear transformation: \( z = Wx + b \),
%   \item a nonlinear activation: \( f(x) = \sigma(z) \).
% \end{enumerate}


% \section*{DNN – Deep Neural Network}

% A \textbf{Deep Neural Network (DNN)} extends a neural network (NN) by adding several layers. This increases the depth of the network:

% \[
% f(x) = \sigma_L\left(W_L \cdot \sigma_{L-1}\left(\ldots \sigma_1\left(W_1 \cdot x + b_1\right) \ldots \right) + b_L\right)
% \]

% In addition to linear transformation, a DNN allows the modeling of complex nonlinearities and thus deeper learning of relevant features by propagating across multiple layers.

% \section*{BNN – Bayesian Neural Network}

% A Bayesian Neural Network (BNN) models the weights $\boldsymbol{\theta}$ as random variables $p(\theta)$. The prediction corresponds to the expected value across all possible models:

% \[
% p(y \mid x, D) = \int p(y \mid x, \theta) \cdot p(\theta \mid D) \, d\theta
% \]

% This makes the \textbf{epistemic uncertainty} (EC) about the posterior distribution of the weights quantifiable.

% \section*{EDN – Evidential Deep Neural Network}

% % \gls{Evidence-based neural networks}

% An \textbf{evidential deep neural network (\gls{evidence-based neural networks})} directly learns the parameters of a probability distribution over uncertainties through an evidence measure $e$, e.g., within a normal inverse gamma distribution $p(y \mid \mu, \sigma^2, e)$. The advantage is that no explicit Monte Carlo sampling strategy is necessary to determine aleatory (AC) and epistemic uncertainties (EC).

% \subsubsection*{Parameter meaning:}
% \begin{itemize}
%   \item $\mu$: Expected value of the target variable (e.g., position, error measure)
%   \item $v$: Scale parameter (inverse variance), models confidence
%   \item $\alpha$: Shape parameter of the NIG distribution, linked to epistemic evidence
%   \item $\beta$: Scale parameter of the variance, linked to aleatory evidence
%   \item $E = \alpha - 1$: Total evidence, as a measure of confidence in the model
% \end{itemize}

% The combined uncertainty is given by:

% \begin{equation}
% \text{Total Uncertainty} = \underbrace{\frac{\beta}{\alpha - 1}}_{\text{epistemic}} + \underbrace{\frac{\beta}{v(\alpha - 1)}}_{\text{aleatory}}
% \end{equation}

% This form allows a single model prediction to simultaneously estimate both types of uncertainty.
\end{otherlanguage}



\begin{otherlanguage}{ngerman}
\section{Machine Learning}

\gls{machinelearning} bezeichnet die Klasse von Algorithmen \( f_{\theta} : \mathcal{X} \rightarrow \mathcal{Y} \), die aus Daten \( \mathcal{D} = \{ (x_i, y_i) \}_{i=1}^{N} \) ein Modell \( f_{\theta} \) lernen, das Eingaben \( x \in \mathcal{X} \) Vorhersagen \( \hat{y} \in \mathcal{Y} \) zuordnet. Dies geschieht durch Optimierung der Parameter \( \theta \) mittels einer Fehlerfunktion \( \mathcal{L}_{\text{loss}}(y, \hat{y}) \).

\subsection{Architekturen}

Die Laufzeit zur Anpassung der Gewichtungen eines neuronalen Netzwerks (\gls{neuronalesnetzwerk}) an eine Zielfunktion kann durch unterschiedliche Architekturen für spezifische Aufgaben optimiert werden. Die Kürzel der Architekturen verweisen jeweils auf ihre charakteristische Struktur.

\paragraph{NN – Neuronales Netzwerk}
Ein \gls{neuronalesnetzwerk} approximiert eine Funktion \( f_{\theta}(x) = \sigma(Wx + b) \). Dabei ist \( \sigma \) eine nichtlineare Aktivierungsfunktion, typischerweise \textit{ReLU} oder \textit{Tanh}. Die Parameter des Modells sind gegeben durch \( \theta = \{ W, b \} \), wobei:

\begin{itemize}
  \item \( W \) die Gewichtsmatrix darstellt, z.\,B. 
    \[
      W = 
      \begin{pmatrix}
        w_{11} & w_{12} & \dots  & w_{1j} \\
        w_{21} & w_{22} & \dots  & w_{2j} \\
        \vdots & \vdots & \ddots & \vdots \\
        w_{i1} & w_{i2} & \dots  & w_{ij} \\
      \end{pmatrix}
      \in \mathbb{R}^{i \times j}
    \]
  \item \( b \) ein Bias-Term ist, der unabhängig vom Eingangssignal die Aktivierung verschiebt.
\end{itemize}

Eine Schicht in einem \gls{neuronalesnetzwerk} besteht aus:
\begin{enumerate}
  \item einer linearen Transformation: \( z = Wx + b \),
  \item einer nichtlinearen Aktivierung: \( f(x) = \sigma(z) \).
\end{enumerate}


\section*{DNN - Deep Neural Network}

Ein \textbf{Deep Neural Network (\gls{DeepNeuralNetwork})} erweitert ein \gls{neuronalesnetzwerk} um mehrere versteckte Schichten, Hidden Layer. Wobei $L$ die Tiefe des \gls{neuronalesnetzwerk} äquivalent ist zur Anzahl gewichteter Schichten des \gls{neuronalesnetzwerk}:

\[
f(x) = \sigma_L\left(W_L \cdot \sigma_{L-1}\left(\ldots \sigma_1\left(W_1 \cdot x + b_1\right) \ldots \right) + b_L\right)
\]

Neben der linearen Transformation erlaubt ein \gls{DeepNeuralNetwork} durch das Propagieren über mehrere versteckte Schichten die Modellierung komplexer Nichtlinearitäten und somit ein tieferes Lernen relevanter Merkmale.

\section*{BNN - Bayesian Neural Network}

Ein \textbf{Bayesian Neural Network (\gls{Bayesianische neuronale Netze})} modelliert die Gewichte $\boldsymbol{\theta}$ als Zufallsvariablen $p(\theta)$. Die Vorhersage entspricht dem Erwartungswert über alle möglichen Modelle:

\[
p(y \mid x, D) = \int p(y \mid x, \theta) \cdot p(\theta \mid D) \, d\theta
\]

Dadurch wird die \textbf{\gls{Epistemische Unsicherheit}} über die Posterior-Verteilung der Gewichte quantifizierbar.

\section*{\gls{Evidenzbasierte neuronale Netze} - Evidential Deep Neural Network}

Ein \textbf{Evidential Deep Neural Network (\gls{Evidenzbasierte neuronale Netze})} lernt direkt die Parameter einer Wahrscheinlichkeitsverteilung über Unsicherheiten durch eine Evidenzgröße $E$, z.\,B. innerhalb einer Normal-Inversen-Gamma-Verteilung (\gls{noninversegammadistribution}) $p(y \mid \mu, \sigma^2, e)$. Vorteilhaft ist, dass keine explizite \gls{MonteCarloSampling}-Strategie notwendig ist, um \gls{Aleatorische Unsicherheit} und \gls{Epistemische Unsicherheit} zu bestimmen.

\subsubsection*{Parameterbedeutung:}
\begin{itemize}
  \item $\mu$: Erwartungswert der Zielgröße (z.\,B. Position, Fehlermaß)
  \item $v$: Skalenparameter (inverse Varianz), modelliert die Konfidenz
  \item $\alpha$: Formparameter der NIG-Verteilung, verknüpft mit epistemischer Evidenz
  \item $\beta$: Skalenparameter der Varianz, verknüpft mit aleatorischer Evidenz
  \item $E = \alpha - 1$: Gesamt-Evidenz, als Vertrauensmaß des Modells
\end{itemize}

Die kombinierte Unsicherheit ergibt sich durch:

\begin{equation}
\text{Total Uncertainty} = \underbrace{\frac{\beta}{\alpha - 1}}_{\text{epistemisch}} + \underbrace{\frac{\beta}{v(\alpha - 1)}}_{\text{aleatorisch}}
\end{equation}

Diese Form erlaubt eine einmalige Modellvorhersage zur gleichzeitigen Schätzung beider Unsicherheitsarten.  
\end{otherlanguage}



% \section{Forschungsstand und identifizierte Lücken}

% Trotz zahlreicher Ansätze zur Quantifizierung aleatorischer und epistemischer Unsicherheiten fehlt bislang ein \textbf{systematischer, modellagnostischer und formal integrierter Ansatz} zur kombinierten Behandlung beider Unsicherheitsarten im Rahmen der szenariobasierten Validierung autonomer Systeme.

% Insbesondere bleibt die \textbf{methodische Abgrenzung eines formalen Kritikalitätsraums} in vielen Arbeiten unklar. Der Übergang von lokalen Unsicherheiten zu globalen Risikomaßen ist in der Literatur lediglich punktuell adressiert.

% Zwar bieten Verfahren wie \textit{Evidential Deep Learning} oder \textit{Bayessche Modelle} theoretische Möglichkeiten zur Repräsentation sowohl epistemischer als auch aleatorischer Unsicherheiten, jedoch ist bisher nicht geklärt, wie diese im Zusammenspiel zur robusten Bewertung sicherheitsrelevanter Szenarien eingesetzt werden können.

% Diese Arbeit zielt darauf ab, zur Schließung dieser Forschungslücken beizutragen. Der Fokus liegt auf der Entwicklung eines transparenten und nachvollziehbaren Verfahrens zur Unsicherheitsbewertung, das sich für sicherheitskritische Anwendungen eignet und bestehende Lücken zwischen Theorie und Praxis adressiert.

% \section{Ableitung der methodischen Forschungsfragen}

% Die in dieser Arbeit bearbeiteten Forschungsfragen (Research Questions, RQ) leiten sich direkt aus den identifizierten Lücken im Forschungsstand ab. Während bestehende Ansätze typischerweise \emph{entweder} aleatorische \emph{oder} epistemische Unsicherheiten isoliert betrachten, fehlt ein integrierter, verallgemeinerbarer Zugang zur kombinierten Quantifizierung, Aggregation und Bewertung.

% Darüber hinaus bestehen methodische Unklarheiten in folgenden Aspekten:

% \begin{itemize}
%   \item der \textbf{Definition eines formalen Kritikalitätsraums} zur Isolierung sicherheitsrelevanter Szenarien,
%   \item der \textbf{Aggregation lokal berechneter Unsicherheiten} zu global interpretierbaren Vertrauensmaßen,
%   \item sowie der \textbf{Modellbewertung über eine Meta-Unsicherheitsgröße}, die unterschiedliche ML-Modelle vergleichbar macht.
% \end{itemize}

% Die Beantwortung dieser Fragen erfolgt entlang eines methodischen Rahmens, der auf machine-learning-basierten Verfahren zur Unsicherheitsquantifizierung aufbaut. Ziel ist es, durch eine geeignete Aggregation aussagekräftige Kennwerte zur Bewertung der Vertrauenswürdigkeit von Surrogatmodellen zu entwickeln.

% \section{Positionierung der Arbeit}

% Diese Bachelorarbeit positioniert sich an der Schnittstelle zwischen Unsicherheitsmodellierung, sicherheitsgerichteter Validierung und maschinellem Lernen. Die Methodik soll einen Beitrag leisten zur:

% \begin{enumerate}
%   \item Entwicklung eines formalen, datengetriebenen Kritikalitätsraums,
%   \item Kombination evidenzbasierter und strukturierter Metriken zur Unsicherheitsquantifizierung,
%   \item praktischen Anwendung in einem surrogatmodellbasierten Validierungsframework für autonome Unterwasserfahrzeuge (AUVs).
% \end{enumerate}



\nocite{krause2025}
