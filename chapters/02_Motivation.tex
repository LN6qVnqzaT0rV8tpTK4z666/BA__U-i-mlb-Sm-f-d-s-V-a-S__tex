% !TeX root = ../main.tex

\chapter{Motivation}
\label{chapter:motivation}



\begin{otherlanguage}{american}
% The use of such AUVs involves uncertain processes, which are increasingly being used in engineering sciences for risk assessment and decision support. The verification of such systems is increasingly shifting from real to virtual test environments, which motivates the use of synthetic data.

% \section{Machine learning as a methodological basis}

% Machine learning methods are now central tools in data processing and automation technology ~\parencite{Nof2023}. In the areas of supervised, unsupervised, and reinforcement learning, models are trained to classify, structure, or optimize data through rewards. Classical methods such as classification and regression form the methodological foundation of these approaches.

% \section{Uncertainty-prone methods in the ML context}

% In uncertainty quantification, two types are distinguished in the ML context~\parencite{Hullermeier2021}:

% \begin{itemize}
%   \item \textbf{Aleatory uncertainty (AC):} random uncertainty, e.g., due to sensor data noise; cannot be reduced by additional data.
%   \item \textbf{Epistemic uncertainty (EC):} model-related uncertainty due to insufficient data or model structure; potentially reducible.
% \end{itemize}

% \noindent
% Typical metrics for quantifying AC include RMSE, MAE, CRPS, NLL, PICP, and MPIW. For EC, KL divergence, OOD scores, uncertainty intervals, and model entropies are used, among others.

% \section{Correlation and controllable uncertainties}

% Literature sources such as ~\parencite{ArthurHoarau2025} describe a dynamic relationship between aleatory and epistemic uncertainty. Recent work assumes that these uncertainties – especially in conjunction with evidence-based methods – can be specifically influenced or controlled under certain conditions.

% \section{Conclusion}

% The increasing importance of reliable uncertainty analyses in autonomous, safety-critical systems motivates the in-depth investigation of machine learning methods from an uncertainty perspective. The goal is to design models that are not only powerful, but also trustworthy and explainable.
\end{otherlanguage}



\begin{otherlanguage}{ngerman}
Für den Einsatz solcher AUVs kommen unsicherheitsbehaftete Verfahren zum Einsatz, welche in den Ingenieurwissenschaften zunehmend zur Risikoabschätzung und Entscheidungsunterstützung verwendet werden. Die Verifikation solcher Systeme verlagert sich dabei zunehmend von realen in virtuelle Testumgebungen, was den Einsatz synthetischer Daten motiviert. Im Projekt VaMai sind diese Unsicherheiten auf verarbeitender Ebene zu unterscheiden zwischenen denen der KI-Module, sowie deren der Surrogates in der Validierung jener Module.

% \gls{Autonomous Underwater Vehicle}s

\section{Maschinelles Lernen als methodische Grundlage}

\gls{machinelearning}-Verfahren sind heute zentrale Werkzeuge in der Datenverarbeitung und Automatisierungstechnik (vgl. Nof et al. ~\parencite{Nof2023}). Im Bereich supervised, unsupervised und reinforcement learning werden Modelle trainiert, um Daten zu klassifizieren, zu strukturieren oder durch Belohnung zu optimieren. Klassische Methoden wie Klassifikation und Regression bilden das methodische Fundament dieser Ansätze.

\section{Unsicherheitsbehaftete Verfahren im \gls{machinelearning}-Kontext}

In der \textit{Unsicherheitsquantifizierung} (\gls{uncertaintyquantification}) werden im \gls{machinelearning}-Kontext unter anderem zwei Arten unterschieden (vgl. Hullermeier et al. ~\parencite{Hullermeier2021}):

\begin{itemize}
  \item \textbf{\gls{Epistemische Unsicherheit}:} \textit{modellbedingte} Unsicherheit aufgrund unzureichender Daten oder Modellstruktur; potenziell reduzierbar.
  \item \textbf{\gls{Aleatorische Unsicherheit}:} \textit{zufallsbedingte} Unsicherheit, z.\,B.\ durch Sensordatenrauschen; nicht reduzierbar durch zusätzliche Daten.
\end{itemize}

Die \gls{Aleatorische Unsicherheit} kann weiter in \textit{homoskedastische} Unsicherheit, das heißt Unsicherheit, die für verschiedene Eingaben konstant bleibt, und \textit{heteroskedastische} Unsicherheit unterteilt werden. Heteroskedastische Unsicherheit hängt von den Eingaben in das Modell ab, wobei einige Eingaben potenziell verrauschtere Ausgaben haben als andere (vgl. Kendall et al. ~\parencite[S. 2, Z. 1-5]{kendall2017}).

% \noindent
% Typische Metriken zur Quantifizierung von \gls{Aleatorische Unsicherheit} sind z.\,B.\ RMSE, MAE, CRPS, NLL, PICP oder MPIW. Für EC werden u.\,a.\ KL-Divergenz, OOD-Scores, Unsicherheitsintervalle oder Modellentropien verwendet.

\section{Zusammenhang und steuerbare Unsicherheiten}

Quellen wie Hoarau et al. 2025 beschreiben eine dynamische Beziehung zwischen \gls{Aleatorische Unsicherheit} und \gls{Epistemische Unsicherheit} bei Untersuchung zusammenhängender Modalitäten ~\parencite[S. 2, Z.]{ArthurHoarau2025} in Regression. Neuere Arbeiten gehen davon aus, dass diese Unsicherheiten, insbesondere im Zusammenspiel mit evidenzbasierten Verfahren, unter bestimmten Bedingungen gezielt beeinflussbar beziehungsweise steuerbar sind (vgl. Hoarau et al. ~\parencite[S. 2, Z. 43-45]{ArthurHoarau2025}): 

\begin{quote}
\glqq These findings indicate that both aleatoric and epistemic uncertainty can be influenced and reduced through targeted acquisition strategies, particularly in evidence-based modeling frameworks. \grqq 
\end{quote}

\section{Schlussfolgerung}
Die steigende Bedeutung verlässlicher Unsicherheitsanalysen in autonomen, sicherheitskritischen Systemen motiviert die vertiefte Untersuchung \gls{machinelearning}-Verfahren unter Unsicherheitsgesichtspunkten. Ziel ist es, Modelle nicht nur leistungsfähig, sondern auch vertrauenswürdig und erklärbar zu gestalten.



\end{otherlanguage}
