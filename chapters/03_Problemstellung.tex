% !TeX root = ../main.tex

\chapter{Problemstellung}
\label{chapter:problemstellung}



\begin{otherlanguage}{american}
% \chapter{Problem Statement}
% \label{chapter:problemstatement}

% The central problem statement of this thesis lies in the determination and analysis of \textbf{aleatory} and \textbf{epistemic uncertainty} within a so-called \emph{criticality space}, which is defined by the violation of safety-relevant limits in a machine learning-based surrogate model.

% In complex application scenarios—especially in the simulation-based validation of autonomous systems—the criticality space represents that subset of the entire scenario space in which the system behavior can be classified as potentially critical or risky.

% It is important to precisely identify and distinguish between two different sources of uncertainty:

% \begin{itemize}
%   \item \textbf{Aleatory uncertainty}, caused by stochastic variability in the input data,
%   \item \textbf{Epistemic uncertainty}, caused by structural model uncertainty and lack of knowledge.
% \end{itemize}

% The central challenge is to aggregate these two types of uncertainty across the criticality space to produce a reliable overall uncertainty measure. This aggregated measure should serve as a criterion for both the reliability of a model and the relevance of certain scenarios.

% Classic methods for quantifying uncertainty reach their methodological limits here. Either they model only one of the two types of uncertainty, or they do not take into account explicit spatial boundaries such as those provided by the criticality space.

% The aim of this work is therefore to overcome existing limitations and create a methodological foundation for aggregated uncertainty analysis in safety-critical ML applications.
\end{otherlanguage}



\begin{otherlanguage}{ngerman}
Die zentrale Problemstellung dieser Arbeit liegt in der Bestimmung und Analyse der \textbf{aleatorischen} und \textbf{epistemischen Gesamtunsicherheit} innerhalb eines sogenannten \emph{Kritikalitätsraums}, welcher durch die Verletzung sicherheitsrelevanter Grenzen in einem machine-learning-basierten Surrogatmodell definiert ist.\newline

In komplexen Anwendungsszenarien – insbesondere bei der simulationsgestützten Validierung autonomer Systeme – stellt der Kritikalitätsraum jene Teilmenge des gesamten Szenarienraums dar, in der das Systemverhalten als potenziell kritisch oder risikobehaftet einzustufen ist.\newline

Dabei gilt es, zwei unterschiedliche Unsicherheitsquellen präzise zu erfassen und voneinander abzugrenzen:

\begin{itemize}
  \item \textbf{Aleatorische Unsicherheit}, verursacht durch stochastische Variabilität in den Eingabedaten,
  \item \textbf{Epistemische Unsicherheit}, bedingt durch strukturelle Modellunsicherheit und fehlendes Wissen.
\end{itemize}

Die zentrale Herausforderung besteht darin, diese beiden Unsicherheitsarten über den Kritikalitätsraum hinweg zu \emph{aggregieren}, sodass eine verlässliche Gesamtunsicherheitsmasse entsteht. Diese aggregierte Größe soll sowohl als Kriterium für die \textbf{Vertrauenswürdigkeit} eines Modells als auch für die \textbf{Relevanz} bestimmter Szenarien dienen können.\newline

Klassische Verfahren zur Unsicherheitsquantifizierung stoßen hierbei an ihre methodischen Grenzen. Entweder modellieren sie nur eine der beiden Unsicherheitsarten oder sie berücksichtigen keine explizite räumliche Abgrenzung wie sie durch den Kritikalitätsraum gegeben ist.\newline

Ziel dieser Arbeit ist es daher, bestehende Limitierungen zu überwinden und ein methodisches Fundament für die aggregierte Unsicherheitsanalyse in sicherheitskritischen ML-Anwendungen zu schaffen.
\end{otherlanguage}
