% !TeX root = ../main.tex

\chapter{Problemstellung}
\label{chapter:problemstellung}



\begin{otherlanguage}{american}
% \chapter{Problem Statement}
% \label{chapter:problemstatement}

% The central problem statement of this thesis lies in the determination and analysis of \textbf{aleatory} and \textbf{epistemic uncertainty} within a so-called \emph{criticality space}, which is defined by the violation of safety-relevant limits in a machine learning-based surrogate model.

% In complex application scenarios—especially in the simulation-based validation of autonomous systems—the criticality space represents that subset of the entire scenario space in which the system behavior can be classified as potentially critical or risky.

% It is important to precisely identify and distinguish between two different sources of uncertainty:

% \begin{itemize}
%   \item \textbf{Aleatory uncertainty}, caused by stochastic variability in the input data,
%   \item \textbf{Epistemic uncertainty}, caused by structural model uncertainty and lack of knowledge.
% \end{itemize}

% The central challenge is to aggregate these two types of uncertainty across the criticality space to produce a reliable overall uncertainty measure. This aggregated measure should serve as a criterion for both the reliability of a model and the relevance of certain scenarios.

% Classic methods for quantifying uncertainty reach their methodological limits here. Either they model only one of the two types of uncertainty, or they do not take into account explicit spatial boundaries such as those provided by the criticality space.

% The aim of this work is therefore to overcome existing limitations and create a methodological foundation for aggregated uncertainty analysis in safety-critical ML applications.
\end{otherlanguage}



\begin{otherlanguage}{ngerman}
Die zentrale Problemstellung dieser Arbeit liegt in der Bestimmung und Analyse der \textbf{aleatorischen Unsicherheit (\gls{Aleatorische Unsicherheit})} und \textbf{epistemischen Unsicherheit (\gls{Epistemische Unsicherheit})} zu einer Gesamtunsicherheit innerhalb eines sogenannten \emph{Kritikalitätsraums}. Im Projekt VaMai ist der Kritikalitätsraum äquivalent zum Szenarioraum. Dieser umfasst die Startparameter, sowie die Kritikalitätsbewertung des Szenarios durch eine Metrik als quantifizierte Verletzung sicherheitsrelevanter Grenzen. In diesem Fall ist der Kritikalitätsraum der Gesamtraum als höchste Raumeinheit. \newline

% , welcher durch die Verletzung sicherheitsrelevanter Grenzen in einem \gls{machinelearning}-basierten Surrogatmodell definiert ist.

In komplexen Anwendungsszenarien, insbesondere bei der simulationsgestützten Validierung autonomer Systeme, stellt der Kritikalitätsraum jene Teilmenge des gesamten Szenarienraums dar, in der das Systemverhalten als potenziell kritisch oder risikobehaftet einzustufen ist, zum Beispiel durch Kollision von Objekten.\newline

Dabei gilt es, zwei unterschiedliche Unsicherheitsquellen präzise zu erfassen und voneinander abzugrenzen:

\begin{itemize}
  \item \textbf{\gls{Aleatorische Unsicherheit}}, verursacht durch stochastische Variabilität in den Eingabedaten,
  \item \textbf{\gls{Epistemische Unsicherheit}}, bedingt durch strukturelle Modellunsicherheit und fehlendes Wissen.
\end{itemize}

Die zentrale Herausforderung besteht darin, diese beiden Unsicherheitsarten über den Kritikalitätsraum hinweg zu erfassen, sodass eine verlässliche Gesamtunsicherheitsmasse entsteht. Diese Größe soll sowohl als Kriterium für die \textbf{Vertrauenswürdigkeit} eines Modells als auch für die \textbf{Relevanz} bestimmter Szenarien dienen können.\newline

Klassische Verfahren zum Beispiel auf Bayesischen Ansätzen wie Bayesische Neuronale Netze zur \gls{uncertaintyquantification} stoßen hierbei an ihre methodischen Grenzen. Entweder modellieren sie nur eine der beiden Unsicherheitsarten oder sie berücksichtigen keine explizite räumliche Abgrenzung wie sie durch den Kritikalitätsraum gegeben ist.\newline

Ziel dieser Arbeit ist es daher, bestehende Limitierungen zu überwinden und ein methodisches Fundament für die Unsicherheitsanalyse in sicherheitskritischen \gls{machinelearning}-Anwendungen zu schaffen.
\end{otherlanguage}
