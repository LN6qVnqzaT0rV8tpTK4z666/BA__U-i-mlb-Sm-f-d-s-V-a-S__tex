% !TeX root = ../main.tex

\chapter{Durchführung}\label{chapter:durchfuehrung}



\begin{otherlanguage}{american}
  
\end{otherlanguage}



\begin{otherlanguage}{ngerman}
\section*{Bekannte Ansätze}

% amini2020deep

% sensoy2018evidential

\begin{figure}[h]
  \centering
  \begin{minipage}{0.5\textwidth}
      \centering
      \includegraphics[width=\textwidth]{../figures/bnn_posterior_predictive.png}
      \caption{Ninand Mavani Visual Benchmark BNN HMC}
  \end{minipage}%
  \begin{minipage}{0.5\textwidth}
      \centering
      \includegraphics[width=\textwidth]{../figures/bnn_svi_predictive.png}
      \caption{Ninand Mavani Visual Benchmark BNN SVI}
  \end{minipage}
\end{figure}

\section*{Eigenentwicklung}

Benötigt wurde eine Datenpipeline. In Entwicklung mit Herr M.Sc. N. Mavani sollte für den Vergleich von BNN, ENN als Baseline von Mavanis Seite auf \parencite{Depeweg2019}, von meiner Seite auf \parencite{Ulmer2023} aufgesetzt werden.\newline

Dazu wurden von \parencite{Depeweg2019} verwendete Datensätze verwendet und ergänzt um in \hyperref[sec:datensaetze]{Datensätze} gelistete. Aufgesetzte Stufen der Datenpipeline sind eine Vorverarbeitung zum Umwandeln von Formaten, Einlesen in Torch Dataset Klassen, Torch Trainingsklassen, Visualisierungsklassen.\newline

Aus den Datensätzen wurden Trainings und Visualisierungen abgeleitet und generifiziert. Ebenso wurden recherchierte Loss-Funktionen generifiziert. Trainings wurden auf einen modernen Standard ergänzt wie Checkpoints, Patience-Epochen, vergleichbar und generifiziert. Nach Generifizierung bleiben einer Klasse überwiegend nur noch konfigurierbare Anteile vorbehalten. Eine Konfiguration wurde als Refactor geplant und soll von dort aus zu einer zentralen Konfiguration hochgereicht werden.\newline

Im Projekt behandelte Metriken wurden aufgefasst mit einer Klasse Metrik, Metrik-Thresholds, Metrik-Registry, Metrik-Registry-Defintions deren Name die Funktion hinreichend vorgibt.\newline

Integriert wurden Lösungen von Herr M.Sc. Mavani der sich zur BNN Auswertung für ein Python Pyro Jax Backend entschieden und damit Lösungen nach den Pyroworkflows für Hamilton Monte Carlo (HMC), Stochastic Variational Inference (SVI) geliefert hat.


% \subsection*{Experiment}

\begin{table}[htbp]
\centering
\begin{tabular}{|l|l|l|l|l|l|l|l|}
\hline
 & \texttt{nll} & \texttt{abs} & \texttt{mse} & \texttt{kl} & \texttt{scaled} & \texttt{variational} & \texttt{full} \\
\hline
EDNN Accuracy & & & & & & & \\
\hline
BNN Accuracy & & & & & & & \\
\hline
\end{tabular}
\caption{Zusammenfassung der Evidential Loss Varianten}
\end{table}

% \subsection*{Schnittstelle}

% \subsection*{Benchmark EDNN}

% \subsection*{Benchmark BNN-EDNN}

% \begin{table}[h!]
% \centering
% \resizebox{\textwidth}{!}{
% \begin{tabular}{|c|c|c|c|c|}
% \hline
% \textbf{Sigma (Standard Deviation)} & \textbf{BNN Variance} & \textbf{BNN Accuracy (\%)} & \textbf{EDNN Variance} & \textbf{EDNN Accuracy (\%)} \\
% \hline
% 0 & 0.0 & 0 & 0.0 & 0 \\
% \hline
% \end{tabular}
% }
% \caption{Vergleich von BNN und EDNN mit Meta-Metrik im 2-Sigma-Bereich}
% \label{tab:BNN_EDNN_Comparison}
% \end{table}
\end{otherlanguage}
