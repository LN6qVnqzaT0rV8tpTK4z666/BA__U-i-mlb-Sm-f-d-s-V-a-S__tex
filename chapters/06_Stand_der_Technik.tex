% !TeX root = ../main.tex

\chapter{Stand der Technik}
\label{chapter:stand-der-technik}

\begin{otherlanguage}{american}
%
%
%
\end{otherlanguage}


\begin{otherlanguage}{ngerman}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R1 Welche auf maschinellem Lernen basierenden Surrogatmodelle sind für die Quantifizierung von Unsicherheiten geeignet?

\begin{table}[!htpb]
  \centering
  \footnotesize
  \begin{tabularx}{\textwidth}{|l|X|}
    \hline
    \textbf{\gls{surrogat}} & \textbf{Eignungsgrund} \\
    \hline
    \begin{itemize}[topsep=0em, itemsep=0.25em, left=0em, labelsep=0.25em]
      \item 1. \gls{Gaußsche Prozessregression}
    \end{itemize} &  
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item 1.1. Intrinsische probabilistische Ausgabe
      \item 1.2. Exakte Varianzschätzung für kleine Datensätze
      \item 1.3. Kernel-basierte Unsicherheitscharakterisierung
    \end{itemize} \\ 
    \hline
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item 2. Deep Ensembles
    \end{itemize} & 
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item 2.1. Redundante Modellierung reduziert Overconfidence
      \item 2.2. Einfache Integration in existierende Architekturen
      \item 2.3. Robust gegen Out-of-Distribution-Daten
    \end{itemize} \\
    \hline
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item 3. Hybrid-Methoden
    \end{itemize} & 
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item 3.1. Kombiniert Stärken von Blackbox-Modellen und GPR
      \item 3.2. Nachrüstbar auf existierende Modelle
      \item 3.3. Recheneffiziente Unsicherheitspropagation
    \end{itemize} \\
    \hline
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item 4. \gls{Bayesianische neuronale Netze}s
    \end{itemize} & 
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item 4.1. Systematische Integration von Priors
      \item 4.2. Theoretisch fundierte Parameterunsicherheit
      \item 4.3. Natürliche Regularisierung durch Bayes'sche Inferenz
    \end{itemize} \\
    \hline
  \end{tabularx}
  \caption{R1 Vgl. v. Unsicherheitsquantifizierungsmethoden in ML}
  \label{tab:chapter6r1}
\end{table}

\footnote{%
\begin{minipage}[t]{\textwidth}
\scriptsize
\textbf{Quellen zu Tab. \ref{tab:chapter6r1}:}\\
1. \parencite[Kap.~2]{rasmussen2006gaussian}, 
1.1. \parencite[S.~16–17]{rasmussen2006gaussian}, 
1.2. \parencite[Kap.~2.2]{rasmussen2006gaussian},
1.3. \parencite[Kap.~4]{rasmussen2006gaussian}\\[0.3em]
2. \parencite{lakshminarayanan2017simple},
2.1. \parencite[S.~3]{lakshminarayanan2017simple},
2.2. \parencite[S.~5]{lakshminarayanan2017simple},
2.3. \parencite{ovadia2019can}\\[0.3em]
3. \parencite{perdikaris2017nonlinear}, 
3.1. \parencite[S.~5–6]{perdikaris2017nonlinear},
3.2. \parencite[S.~6]{perdikaris2017nonlinear},
3.3. \parencite{liu2020multifidelity}\\[0.3em]
4. \parencite{gal2016uncertainty}, 
4.1. \parencite[Kap.~2.3]{gal2016uncertainty}, 
4.2. \parencite[S.~40–41]{gal2016uncertainty}, 
4.3. \parencite[S.~41–42]{gal2016uncertainty}
\end{minipage}%
}

% (Übersicht aus MC25) 

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R2 Welche allgemeinen und modellspezifischen Faktoren beeinflussen das Lernen von Unsicherheiten in ML-Modellen?

\newline
R2.1 Allgemeine Faktoren

\begin{table}[!htpb]
  \centering
  \footnotesize
  \begin{tabularx}{\textwidth}{|l|X|}
    \hline
    \textbf{Unsicherheitsdimensionen} & \textbf{Mögliche Werte} \\
    \hline
    1. Lokalisierung im System & Umgebung, Modellierung, Funktionen, Ziele, Verfügbare Ressourcen \\
    \hline
    2. Natur & Epistemisch, Aleatorisch \\
    \hline
    3. Grad der Unsicherheit & Keine Unsicherheit, Mangel an Wissen, Mangel an Bewusstsein, Mangel an Fähigkeit Bewusstsein zu erlangen \\
    \hline
    4. Entstehungszeit & Anforderungsdefinition, Entwicklungszeit, Laufzeit \\
    \hline
  \end{tabularx}
  \caption{R2 Allg. Faktoren Klassifizierung Unsicherheit KI-Systeme nach A. Kreuz ~\nocite{AndreasKreutz2022} ~\nocite{AndreasKreutz2022b}}
  \label{tab:chapter6r21}
\end{table}

\newline
R2.2 Modellspezifische Faktoren

\begin{table}[!htpb]
  \centering
  \footnotesize
  \begin{tabularx}{\textwidth}{|l|X|}
    \hline
    \textbf{\gls{Bayesianische neuronale Netze}} & \textbf{Modellspezifische Faktoren} \\
    \hline
    1. Prior-Verteilungen & Wahl der Prioren beeinflusst die Unsicherheit und Vorhersagegenauigkeit. \\
    \hline
    2. Likelihood-Funktion & Bestimmt, wie Unsicherheit in den Beobachtungen modelliert wird (z.B. durch Gaussian). \\
    \hline
    3. Posterior Approximation & MCMC oder Variational Inference schätzt den Posterior und die Unsicherheit. \\
    \hline
    4. Regularisierung & Hilft, Overfitting zu vermeiden und Unsicherheit zu kontrollieren. \\
    \hline
    5. Bayesische Optimierung & Optimiert Hyperparameter unter Berücksichtigung der Unsicherheit. \\
    \hline
    6. Datenqualität & Schlechte Datenqualität erhöht Unsicherheit, gute Qualität verringert sie. \\
    \hline
    7. Maßstab & Der Maßstab des Modells beeinflusst die Unsicherheitsquantifizierung. \\
    \hline
  \end{tabularx}
  \caption{R2.2 Modellspezifische Faktoren zur Unsicherheitsklassifizierung \gls{Bayesianische neuronale Netze}}\label{tab:chapter6r22}
\end{table}

\begin{table}[!htpb]
  \centering
  \footnotesize
  \begin{tabularx}{\textwidth}{|l|X|}
    \hline
    \textbf{\gls{Evidenzbasierte neuronale Netze}} & \textbf{Modellspezifische Faktoren} \\
    \hline
    1. Prior-Funktion & Beeinflusst, wie Unsicherheit über Daten und Parameter modelliert wird. \\
    \hline
    2. Evidenzfunktion & Modelliert Unsicherheit mit Evidenzparametern wie \( \alpha \), \( \beta \), und \( v \). \\
    \hline
    3. Posterior Approximation & Näherung der Posterior-Verteilung zur Unsicherheitsbestimmung. \\
    \hline
    4. Evidenz Optimierung & Optimierung der Evidenzparameter während des Trainings. \\
    \hline
    5. Evidenzbasierte Regularisierung & Regularisiert Evidenzparameter, um Overfitting zu vermeiden. \\
    \hline
    6. Multimodalität & Modelliert mehrere konkurrierende Unsicherheitsvorhersagen gleichzeitig. \\
    \hline
    7. Dateninhärente Unsicherheit & Unsicherheit, die direkt aus den Daten selbst resultiert. \\
    \hline
    8. Datenqualität & Schlechte Datenqualität erhöht die Unsicherheit im Modell. \\
    \hline
    9. Netzwerktiefe & Die Tiefe beeinflusst die Fähigkeit, Unsicherheit zu erfassen. \\
    \hline
  \end{tabularx}
  \caption{R2.2 Modellspezifische Faktoren zur Unsicherheitsklassifizierung \gls{Evidenzbasierte neuronale Netze}}\label{tab:chapter6r23}
\end{table}

\footnote{%
\begin{minipage}[t]{\textwidth}
\scriptsize
\textbf{Quellen zu Tab. \ref{tab:chapter6r21}, Tab. \ref{tab:chapter6r22}, Tab. \ref{tab:chapter6r23}:}\\[0.125em]
\textbf{R2.1 Allgemeine Faktoren}: 
1. \parencite[S.~47–52]{AndreasKreutz2022},
2. \parencite[S.~54]{AndreasKreutz2022},
3. \parencite[S.~56–58]{AndreasKreutz2022},
4. \parencite[S.~60]{AndreasKreutz2022}\\[0.125em]

\textbf{R2.2.1 Bayesianische neuronale Netze}: 
1. \parencite[Kap.~2.3]{gal2016uncertainty},
2. \parencite[Kap.~3]{blundell2015weight},
3. \parencite[S.~40–41]{gal2016uncertainty},
4. \parencite[S.~41–42]{gal2016uncertainty},
5. \parencite[Kap.~7.4]{rasmussen2006gaussian},
6. \parencite[S.~16]{bishop2006pattern},
7. \parencite[S.~29–31]{gal2016uncertainty}\\[0.125em]

\textbf{R2.2.2 Evidenzbasierte neuronale Netze}: 
1. \parencite{sensoy2018evidential},
2. \parencite[S.~2–3]{sensoy2018evidential},
3. \parencite[S.~4]{sensoy2018evidential},
4. \parencite[S.~5]{sensoy2018evidential},
5. \parencite[S.~6]{sensoy2018evidential},
6. \parencite[S.~6–7]{sensoy2018evidential},
7. \parencite{kendall2017uncertainties},
8. \parencite{kendall2017uncertainties},
9. \parencite[S.~6]{sensoy2018evidential}
\end{minipage}%
}


\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R3
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R3 Wie können diese Einflussfaktoren abgeschwächt werden, um die Unsicherheitsabschätzung zu verbessern?

\newline
Wie Allgemeine Faktoren abschwächen?

\begin{table}[!htpb]
  \centering
  \footnotesize
  \begin{tabularx}{\textwidth}{|l|X|}
    \hline
    \textbf{Unsicherheitsdimensionen} & \textbf{Mögliche Abschwächung} \\
    \hline
    1. Lokalisierung im System & Verbesserung der Modellgenauigkeit und der Ressourcennutzung durch gezielte Datensammlung und Modellanpassung. \\
    \hline
    2. Natur & Einsatz von Hybriden Modellen, die sowohl epistemische als auch aleatorische Unsicherheit modellieren können. \\
    \hline
    3. Grad der Unsicherheit & Erhöhung des Modellspezifikationsgrades, z. B. durch Mehrfachmodellierung und Unsicherheitsquantifizierung. \\
    \hline
    4. Entstehungszeit & Frühzeitige Einbindung von Unsicherheitsmodellierung in die Anforderungsdefinition und Entwicklungszeit. \\
    \hline
  \end{tabularx}
  \caption{R3 Abschwächung allgemeiner Faktoren KI Systeme}\label{tab:chapter6r31}
\end{table}

\newline
Wie Modellspezifische Faktoren abschwächen?

\begin{table}[!htpb]
  \centering
  \footnotesize
  \begin{tabularx}{\textwidth}{|l|X|}
    \hline
    \textbf{Modellspezifische Faktoren} & \textbf{Abschwächung der Unsicherheitsabschätzung} \\
    \hline
    1. Prior-Verteilungen & Auswahl robusterer Priors und der Anpassung der Priors an die Daten zur Vermeidung von zu starker Unsicherheit. \\
    \hline
    2. Likelihood-Funktion & Optimierung der Likelihood-Modelle, z. B. durch mehrdimensionale Likelihoods für die Unsicherheit. \\
    \hline
    3. Posterior Approximation & Verwendung effizienter Approximationstechniken wie Variational Inference zur besseren Unsicherheitsabschätzung. \\
    \hline
    4. Regularisierung & Anwendung von stärkeren Regularisierungstechniken, um Overfitting zu vermeiden und die Unsicherheit gezielt zu verringern. \\
    \hline
    5. Bayesische Optimierung & Optimierung von Hyperparametern unter Unsicherheit zur gezielten Reduzierung der Unsicherheit im Modell. \\
    \hline
    6. Datenqualität & Verbesserung der Datenqualität durch Datenbereinigung und Zusammenstellung von Trainingsdatensätzen, die die Unsicherheit reduzieren. \\
    \hline
    7. Maßstab & Verwendung von Skalenmodellen zur Reduzierung von Unsicherheit durch Skalierung des Modells auf größere Datenmengen. \\
    \hline
  \end{tabularx}
  \caption{R3.1 Abschwächung Modellspezifische Faktoren zur Unsicherheitsklassifizierung \textbf{\gls{Bayesianische neuronale Netze}}}\label{tab:chapter6r32}
\end{table}

\begin{table}[!htpb]
  \centering
  \footnotesize
  \begin{tabularx}{\textwidth}{|l|X|}
    \hline
    \textbf{Modellspezifische Faktoren} & \textbf{Abschwächung der Unsicherheitsabschätzung} \\
    \hline
    1. Prior-Funktion & Verwendung von flexiblen Prior-Funktionen, die auf den spezifischen Unsicherheitsgrad der Daten abgestimmt sind. \\
    \hline
    2. Evidenzfunktion & Verbesserung der Evidenzparameter, z. B. durch den Einsatz von multimodalen Evidenzfunktionen, um Unsicherheit besser zu modellieren. \\
    \hline
    3. Posterior Approximation & Anwendung von genauen MCMC-Methoden oder besseren Näherungsverfahren zur genaueren Posterior-Bestimmung. \\
    \hline
    4. Evidenz Optimierung & Evidenzparameter optimieren, um unsichere Parameterbereiche zu vermeiden und so Unsicherheit zu reduzieren. \\
    \hline
    5. Evidenzbasierte Regularisierung & Stärkere Regularisierung der Evidenzparameter zur Vermeidung von zu großer Unsicherheit bei der Modellierung. \\
    \hline
    6. Multimodalität & Integration von multimodalen Unsicherheitsmodellen, um verschiedene Unsicherheitsquellen gleichzeitig zu verarbeiten. \\
    \hline
    7. Dateninhärente Unsicherheit & Reduktion der Datenrauschen und Verbesserung der Datenvorverarbeitung, um die Datenunsicherheit zu minimieren. \\
    \hline
    8. Datenqualität & Optimierung der Datenqualität durch Verwendung besserer Datensätze und Datenaugmentation. \\
    \hline
    9. Netzwerktiefe & Optimierung der Netzwerktiefe unter Berücksichtigung der Modellkomplexität, um unnötige Unsicherheiten zu vermeiden. \\
    \hline
  \end{tabularx}
  \caption{R3.2 Abschwächung Modellspezifische Faktoren zur Unsicherheitsklassifizierung \textbf{\gls{Evidenzbasierte neuronale Netze}}}\label{tab:chapter6r33}
\end{table}

\footnote{%
\begin{minipage}[t]{\textwidth}
\scriptsize
\textbf{Quellen zu Tab. \ref{tab:chapter6r31}, Tab. \ref{tab:chapter6r32}, Tab. \ref{tab:chapter6r33}:}\\[0.125em]
\textbf{R3 Allgemeine Faktoren}\\
1. \parencite[S.~47–52]{AndreasKreutz2022},
2. \parencite[S.~6–9]{perdikaris2017nonlinear},
3. \parencite[S.~3]{ovadia2019can},
4. \parencite[S.~60]{AndreasKreutz2022} \\[0.125em]

\textbf{R3.1 Bayesianische neuronale Netze}\\
1. \parencite[Kap.~2.3]{gal2016uncertainty},
2. \parencite[Kap.~3]{blundell2015weight},
3. \parencite[S.~40–41]{gal2016uncertainty},
4. \parencite[S.~41–42]{gal2016uncertainty},
5. \parencite[Kap.~7.4]{rasmussen2006gaussian},
6. \parencite[S.~16]{bishop2006pattern},
7. \parencite[S.~29–31]{gal2016uncertainty} \\[0.125em]

\textbf{R3.2 Evidenzbasierte neuronale Netze}\\
1. \parencite{sensoy2018evidential},
2. \parencite[S.~3–4]{sensoy2018evidential},
3. \parencite[S.~4]{sensoy2018evidential},
4. \parencite[S.~5]{sensoy2018evidential},
5. \parencite[S.~6]{sensoy2018evidential},
6. \parencite[S.~6–7]{sensoy2018evidential},
7. \parencite{kendall2017uncertainties},
8. \parencite{kendall2017uncertainties},
9. \parencite[S.~6]{sensoy2018evidential}
\end{minipage}%
}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R4
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R4 Inwieweit kann ML-basierte Unsicherheitsquantifizierung zuverlässig den in realen Anwendungsszenarien beobachteten Unsicherheiten entsprechen?
% Beweis aus Herleitung wie das einander entsprechen kann.
\newline
% UQ-Pred-UQ-Data-EQ-Ensure-Framework
Lanini et. al liefern ein Framework zur Bewertung von R4 ~\parencite{Lanini2024} zur Optimierung in einer Anwendungsdomäne. Ihre Recherche differenziert zur Beantwortung weiterhin datenbasierte und modellbasierte Unsicherheitsmetriken. 
\newline
Manchingal et al. distanzieren sich von der Optimierung auf Anwendungsdomänen. Als Paradigmenwechsel beschreiben Sie epistemische Künstliche Intelligenz. Im Kern soll nicht nur auf Wissen in Form von Daten, sondern auch auf Nicht-Wissen trainiert werden. \parencite{manchingal2025}

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{../figures/x3.png}
  \caption{R4.1}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{../figures/x2.png}
  \caption{R4.2}
\end{figure}

% Die spezifischen Aufgaben dieser Arbeit umfassen:

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R5
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R5 Durchführung einer umfassenden Literaturübersicht über UQ-Techniken in der ML-basierten Surrogatmodellierung.

Der Beitrag zur umfassenden Literaturübersicht über UQ-Techniken in der ML-basierten Surrogatmodellierung wird auf \gls{Evidenzbasierte neuronale Netze} eingegrenzt. In \gls{Evidenzbasierte neuronale Netze} soll zwischen In- und Exklusionskriterien unterschieden werden.

\begin{table}[htbp]
\centering
\footnotesize
\begin{tabularx}{\textwidth}{|l|X|}
\hline
\textbf{Kriterium} & \textbf{Beschreibung} \\ \hline

\textbf{Inklusionskriterien} & 
Evidential Deep Learning oder evidenzbasierte Unsicherheitsmodellierung \newline
Peer-reviewed oder relevante arXiv-Preprints \newline
Mit Experimenten oder Anwendungen \newline
Publikationen 2016–2025 \newline
Englischsprachig \\ \hline

\textbf{Exklusionskriterien} &
Keine Implementierung oder rein theoretisch ohne EDL-Bezug \newline
Nur Bayesian NNs/Ensembles ohne evidenzielle Ansätze \newline
Rein technische Papers ohne Unsicherheitsbezug \newline
Nicht-englischsprachig \newline
Nur Poster oder Abstracts ohne Volltext \\ \hline

\end{tabularx}
\caption{R5 Auswahlkriterien für die Literaturübersicht zu Evidential Deep Learning}
\label{tab:auswahlkriterien}
\end{table}

% Fragenkatalog der mit Scopes abgedeckt werden soll. 

% Wie wird Evidential Deep Learning zur Quantifizierung von Unsicherheit in neuronalen Netzen eingesetzt?

% Welche Methoden, Benchmarks und Anwendungen existieren für EDL?

% Was ist die optimale Loss-Funktion für EDL?

% Welche mathematischen Grundlagen liegen Evidential Deep Learning zugrunde?

% Wie ist die Verbindung zwischen EDL und Subjective Logic?

% Worin unterscheiden sich Evidential Deep Learning und Bayesian Deep Learning?

% Welche Architekturen eignen sich für Evidential Learning?

% Welche Modifikationen sind an klassischen CNNs, RNNs, Transformers für EDL nötig?

% Wie werden evidenzielle Layer in bestehende Architekturen integriert?

% Worin liegen die Unterschiede zwischen Evidential Loss und Standard-Loss-Funktionen wie Cross Entropy?

% Welche Rolle spielt KL-Regularisierung im Kontext von EDL?

% Wie geht EDL mit fehlerhaften oder unsicheren Labels um?

% Worin unterscheiden sich epistemische und aleatorische Unsicherheiten bei EDL?

% Wie können evidenzielle Parameter interpretiert werden?

% Welche Benchmarks werden typischerweise für EDL genutzt (z. B. MNIST, CIFAR-10, OOD-Tests)?

% Wie schneidet EDL im Vergleich zu Bayesian Neural Networks und Deep Ensembles ab?

% Welche Anwendungsgebiete gibt es für EDL, insbesondere in Bereichen wie Autonomous Driving oder Industrie 4.0?

% Welche Herausforderungen bestehen aktuell bei Training und Einsatz von Evidential Deep Learning?

% Welche Overconfidence-Probleme können bei EDL auftreten?

% Wie skalierbar ist Evidential Deep Learning auf große Modelle und Datensätze?

% Wie verhält sich EDL im Vergleich zu deterministischen Methoden mit nachträglicher Kalibrierung?

Für die Literaturübersicht wurde ein Fragenkatalog generiert, der mit seinen Schwerpunkten folgende Scopes ergeben hat. 

\begin{table}[htbp]
\centering
\footnotesize
\begin{tabularx}{\textwidth}{|l|X|}
\hline
\textbf{Scope} & \textbf{Beschreibung} \\ \hline

1. Theoretische Grundlagen &
1.1. Mathematische Formulierung von EDL \newline
1.2. Verbindung zu Subjective Logic \newline
1.3. Unterschiede zu Bayesian Deep Learning \\ \hline

2. Architekturen &
2.1. Netzarchitekturen für Evidential Learning \newline
2.2. Modifikationen an klassischen CNNs, RNNs, Transformers \newline
2.3. Integration evidenzieller Layer \\ \hline

3. Loss Functions &
3.1. Evidential Loss vs. Standard Cross Entropy \newline
3.2. KL-Regularisierung \newline
3.3. Umgang mit fehlerhaften Labels \\ \hline

4. Uncertainty Types &
4.1. Epistemische vs. aleatorische Unsicherheit \newline
4.2. Interpretation evidenzieller Parameter \\ \hline

5. Benchmarks &
5.1. Typische Datensätze (MNIST, CIFAR-10, OOD-Tests) \newline
5.2. Vergleich zu Bayesian NNs und Ensembles \\ \hline

6. Anwendungsgebiete &
6.1. Autonomous Driving \newline
6.2. Industrie 4.0 \\ \hline

7. Vergleich zu anderen Methoden &
7.1. Bayesian Neural Networks \newline
7.2. Deep Ensembles \newline
7.3. Deterministische Methoden mit Calibration \\ \hline

8. Herausforderungen &
8.1. Trainingsstabilität \newline
8.2. Overconfidence-Probleme \newline
8.3. Skalierbarkeit auf große Modelle \\ \hline

\end{tabularx}
\caption{R5 Scopes der Fragen der Literaturübersicht zu Evidential Deep Learning}
\label{tab:edl_scopes}
\end{table}

\pagebreak

Mit den R5 Scopes der Fragen der Literaturübersicht zu Evidential Deep Learning wurden folgende 
R5 Scopes der Antworten der Literaturübersicht zu Evidential Deep Learning mit zugehörigen Quellen definiert. 

\begin{table}[htbp]
\centering
\footnotesize
\begin{tabularx}{\textwidth}{|l|X|}
\hline
\textbf{Scope} & \textbf{Beschreibung / Quellen} \\ \hline

1.1. & Sensoy et al. (2018): Evidential Deep Learning to Quantify Classification Uncertainty \cite{sensoy2018evidential} \newline
         Sensoy et al. (2023): Evidential Deep Learning: Theory and Practice \cite{sensoy2023tutorial} \\ 
1.2. & Jøsang (2016): Subjective Logic \cite{josang2016subjective} \\ 
1.3. & Kendall \& Gal (2017): What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision? \cite{kendall2017uncertainties} \newline
         Peters et al. (2023): On the Mathematical Consistency of Evidential Learning \cite{peters2023consistency} \\ \hline

2.1. & Amini et al. (2020): Deep Evidential Regression \cite{amini2020deep} \newline
         Tian et al. (2024): Evidential Graph Neural Networks \cite{tian2024egnn} \\ 
2.2. & Sensoy et al. (2020): Uncertainty-Aware Deep Classification \cite{sensoy2020uncertainty} \newline
         Bohlke et al. (2023): Evidential Vision Transformers \cite{bohlke2023evidentialvit} \\ 
2.3. & Zhou et al. (2022): Evidential Transformer Networks \cite{zhou2022evidential} \newline
         Bohlke et al. (2023): Evidential Vision Transformers \cite{bohlke2023evidentialvit} \\ \hline

3.1. & Sensoy et al. (2018): Evidential Loss Function (Evidential Deep Learning) \cite{sensoy2018evidential} \\ 
3.2. & Sensoy et al. (2020): KL-Regularization in Evidential Networks \cite{sensoy2020uncertainty} \newline
         Amini et al. (2023): Improved KL Regularization for Evidential Regression \cite{amini2023kl} \\ 
3.3. & Dhamija et al. (2018): Reducing Model Confidence for Out-of-Distribution Detection \cite{dhamija2018reducing} \\ \hline

4.1. & Kendall \& Gal (2017): Aleatoric and Epistemic Uncertainty \cite{kendall2017uncertainties} \newline
         Tran et al. (2023): Separating Aleatoric and Epistemic Uncertainty in Evidential Models \cite{tran2023separating} \\ 
4.2. & Amini et al. (2020): Interpreting evidential parameters in regression tasks \cite{amini2020deep} \\ \hline

5.1. & Amini et al. (2020): Evaluation on MNIST, CIFAR-10, OOD \cite{amini2020deep} \newline
         Bohlke et al. (2023): Evaluation on CIFAR-100C, ImageNet-O \cite{bohlke2023evidentialvit} \\ 
5.2. & Lakshminarayanan et al. (2017): Deep Ensembles as Baseline for Uncertainty \cite{lakshminarayanan2017simple} \newline
         Tran et al. (2023): Comparative Benchmarks \cite{tran2023separating} \\ \hline

6.1. & Feng et al. (2022): Evidential Uncertainty in Autonomous Driving \cite{feng2022review} \\ 
6.2. & Wang et al. (2022): Uncertainty Modeling in Industrial AI \cite{wang2022uncertainty} \newline
         Gupta et al. (2023): Evidential Learning for Industrial Predictive Maintenance \cite{gupta2023industrialedl} \newline
         Chen et al. (2024): Uncertainty Estimation in Vision-Language Models \cite{chen2024vlm} \\ \hline

7.1. & Gal \& Ghahramani (2016): Dropout as Bayesian Approximation \cite{gal2016dropout} \\ 
7.2. & Lakshminarayanan et al. (2017): Deep Ensembles \cite{lakshminarayanan2017simple} \\ 
7.3. & Guo et al. (2017): On Calibration of Modern Neural Networks \cite{guo2017calibration} \newline
         Tran et al. (2023): Comparison of calibration in evidential vs. deterministic methods \cite{tran2023separating} \\ \hline

8.1. & Sensoy et al. (2020): Training stability in evidential networks \cite{sensoy2020uncertainty} \newline
         Peters et al. (2023): Loss function degeneracies \cite{peters2023consistency} \\ 
8.2. & Dhamija et al. (2018): Overconfidence in neural networks \cite{dhamija2018reducing} \newline
         Chen et al. (2024): Overconfidence in multimodal evidential learning \cite{chen2024vlm} \\ 
8.3. & Zhou et al. (2022): Scalability of evidential transformers \cite{zhou2022evidential} \newline
         Bohlke et al. (2023): Scalability challenges in large Vision Transformers \cite{bohlke2023evidentialvit} \\ \hline

\end{tabularx}
\caption{R5 Scopes der Antworten der Literaturübersicht zu Evidential Deep Learning mit aktuellen Quellen (2016–2025)}
\label{tab:edl_scopes_sources_updated}
\end{table}

Hochwertige, zentrale Umfragen sind \parencite{Ulmer2023}, \parencite{Gawlikowski2023}. 

Der Zusammenhang der modellbasierten, evidenzbasierten Unsicherheit zu jener der Realdaten ist im Anhang \ref{sec:enn_gum_derivation}.

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R6
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R6 Identifizierung und Analyse geeigneter Unsicherheitsmetriken für Surrogatmodelle, wobei zwischen aleatorischer und epistemischer Unsicherheit unterschieden wird.

\begin{table}[htpb]
  \centering
  \begin{tabularx}{\textwidth}{|l|l|X|}
    \hline
    & \textbf{Datenbasierte Metriken} & \textbf{Modellbasierte Metriken} \\
    \hline
    \textbf{AC} & 
    \begin{tabular}[c]{@{}l@{}} 
      \( \sigma = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2} \) \\ 
      Standardabweichung (Rauschen) \\[1ex]
      \( \text{Var} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 \) \\ 
      Varianz der Residuen
    \end{tabular}
    & 
    \begin{tabular}[c]{@{}l@{}} 
      \( p(\theta \mid \mathcal{D}) \) \\ 
      Bayesianische Unsicherheit (Posterior) \\[1ex]
      Kreuzvalidierung (Training/Testdaten)
    \end{tabular} \\
    \hline
    \textbf{EC} & 
    \begin{tabular}[c]{@{}l@{}} 
      \( \text{Fehler} = \sum_{i=1}^{n} |y_i - \hat{y}_i| \) \\ 
      Fehleranalyse auf Testdaten
    \end{tabular}
    & 
    \begin{tabular}[c]{@{}l@{}} 
      \( \hat{y} \pm z \cdot \sigma \) \\ 
      Konfidenzintervall \\[1ex]
      \( H(p) = - \sum_{i} p(x_i) \log(p(x_i)) \) \\ 
      Entropie der Posterior-Verteilung
    \end{tabular} \\
    \hline
  \end{tabularx}
  \caption{R6 Unsicherheitsmetriken für Surrogatmodelle}\label{tab:chapter6r61}
\end{table}


\footnote{%
\begin{minipage}[t]{\textwidth}
\scriptsize
\textbf{Quellen zu Tab. \ref{tab:chapter6r61}:}\\[0.125em]
\textbf{AC (Aleatorische Unsicherheit)}\\
\quad Datenbasierte Metriken: \parencite[S.~28–30]{bishop2006pattern}, 
\quad Modellbasierte Metriken: \parencite[Kap.~2]{rasmussen2006gaussian}; \parencite{blundell2015weight}\\ [0.125em]

\textbf{EC (Epistemische Unsicherheit)}\\
\quad Datenbasierte Metriken: \parencite[S.~30–32]{bishop2006pattern}, 
\quad Modellbasierte Metriken: \parencite[S.~40–42]{gal2016uncertainty}; \parencite{sensoy2018evidential}, 
\end{minipage}%
}


\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R7
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R7 Vergleich modellspezifischer und anwendungsspezifischer Bewertungsmetriken für die Quantifizierung von Unsicherheit.

% Beispiel-Anwendungsdomäne: [Beispiel-Domäne]
Für den Vergleich werden Anwendungen im Ingenieurswesen vorgeschlagen: 

\begin{table}[!htbp]
\centering
\scriptsize
\begin{tabularx}{\textwidth}{|l|X|}
\hline
\textbf{Domäne} & \textbf{Typische Anwendungen} \\
\hline
Strukturmechanik & Spannungsanalyse, Lebensdauerberechnung \\
\hline
Aerodynamik & CFD-Simulation, Drag/Lift-Koeffizienten \\
\hline
Fahrzeugbau & Crashsimulation, Akustik (NVH), Thermomanagement \\
\hline
Akustik & Modalanalyse, Schallausbreitung \\
\hline
Materialwissenschaft & Materialeigenschaften, Werkstoffdesign \\
\hline
Geophysik & Erdbebensimulation, Bodenmechanik \\
\hline
Prozesssimulation & Chemische Reaktoren, Prozessoptimierung \\
\hline
Energie & Batterie-Management, Netzstabilität \\
\hline
\end{tabularx}
\caption{Anwendungsdomänen im Ingenieurwesen für ML-Surrogatmodelle}
\label{tab:ingenieurwesen-domains-small}
\end{table}

% Anwendungsspezifikation:
Als Beispiel-Domäne zum Vergleich der modellspezifischen und anwendungsspezifischen Unsicherheitsmetriken für Surrogatmodelle im Autonomen Fahren wird der Fahrzeugbau gewählt. 

\begin{table}[!htpb]
  \centering
  \scriptsize
  \begin{tabularx}{\textwidth}{|l|X|X|}
    \hline
    & \textbf{Modellspezifische Metriken} & \textbf{Anwendungsspezifische Metriken (Autonomes Fahren)} \\
    \hline
    \textbf{AC} & 
    RMSE: Abweichung zwischen vorhergesagten und tatsächlichen Sensordaten (z. B. Positionen von Objekten) \newline
    MAE: Mittlere absolute Abweichung bei Objekterkennung oder Trajektorien \newline
    KL(P‖Q): Abweichung zwischen Vorhersage- und Ground-Truth-Wahrscheinlichkeitsverteilungen & 
    Accuracy: Korrektheit der Objekterkennung (z. B. Fußgänger erkannt/nicht erkannt) \newline
    F1-Score: Balance zwischen Präzision und Recall bei der Objekterkennung \newline
    AUC: Trennschärfe bei der Klassifikation sicherer vs. unsicherer Szenarien \\
    \hline
    \textbf{EC} & 
    \( \mathcal{L}(\theta) \): Loss-Funktion inklusive Unsicherheitsanteile (z. B. evidentieller Loss) \newline
    BMA: Mittelung mehrerer Modellposteriors für robustere Unsicherheiten \newline
    CI: Konfidenzintervalle für kritische Größen (z. B. Zeit bis Kollision) & 
    Fehler: Abweichung von vorhergesagten zu tatsächlichen Sicherheitsabständen \newline
    H(p): Entropie der Klassifikationsausgabe als Maß epistemischer Unsicherheit \newline
    AUC-PR: Leistungsfähigkeit bei seltenen, kritischen Klassen (z. B. seltene Gefahrensituationen) \\
    \hline
  \end{tabularx}
  \caption{Vergleich modellspezifischer und anwendungsspezifischer Unsicherheitsmetriken für Surrogatmodelle im autonomen Fahren}
  \label{tab:chapter6r71}
\end{table}

\footnote{%

\begin{minipage}[t]{\textwidth}
\scriptsize
\textbf{Quellen zu Tab. \ref{tab:ingenieurwesen-domains-small}:}\\[0.5em]
Die genannten Anwendungsdomänen sind zusammengetragen aus \parencite{Gawlikowski2023} sowie \parencite{Ulmer2023}. Beide Werke behandeln typische Einsatzfelder von ML-basierten Surrogatmodellen im Ingenieurwesen. 
\end{minipage}%
\vspace{0.125em}
\begin{minipage}[t]{\textwidth}
\scriptsize
\textbf{Quellen zu Tab. \ref{tab:chapter6r71}:}\\[0.5em]
\textbf{AC (Aleatorische Unsicherheit)}\\
\quad Modellspezifische Metriken: \parencite[S.~224–226]{bishop2006pattern}; \parencite[Kap.~2]{rasmussen2006gaussian} \\
\quad Anwendungsspezifische Metriken: \parencite[S.~40–42]{bishop2006pattern} \\[0.5em]

\textbf{EC (Epistemische Unsicherheit)}\\
\quad Modellspezifische Metriken: \parencite[S.~40–42]{gal2016uncertainty}; \parencite{blundell2015weight}; \parencite{sensoy2018evidential} \\
\quad Anwendungsspezifische Metriken: \parencite[S.~233–235]{bishop2006pattern}; \parencite{ovadia2019can}
\end{minipage}%
}


\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R8
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R8 Untersuchung und Vergleich verschiedener UQ-Ansätze für ML-basierte Surrogatmodelle, insbesondere Bayes'sche neuronale Netze und konforme Vorhersagen.

% R8 Untersuchung:
\subsection*{Vergleich von BNNs und Conformal Prediction}

Zur Untersuchung von R8 wird der Vergleich zwischen \gls{Bayesianische neuronale Netze}s und \gls{Conformal Prediction} auf Grundlage identischer Modellarchitekturen und Datensätze durchgeführt. Für \gls{Bayesianische neuronale Netze}s werden die Implementierungen von Herrn Mavani in NumPyro/JAX genutzt (HMC und SVI) \parencite{nmavani2025}. Für \gls{Conformal Prediction} wird ein separates Skript erstellt, das auf denselben Netzen basiert, jedoch Vorhersageintervalle mittels Konformitäts-Quantilen auf einem Calibration-Set berechnet.

\paragraph{Vergleichskriterien}
Es werden folgende Metriken erhoben:
\begin{itemize}
  \item RMSE, MAE der Punktvorhersagen
  \item Calibration Error (ECE)
  \item Coverage-Rate der Vorhersageintervalle
  \item durchschnittliche Breite der Vorhersageintervalle
  \item Rechenzeit für Training und Vorhersage
\end{itemize}

\paragraph{Ziel der Analyse}
Ziel: Praktischen Unterschiede beider Verfahren bezüglich: 
\begin{itemize}
  \item Fähigkeit zur Trennung epistemischer und aleatorischer Unsicherheit (nur bei BNNs vorhanden)
  \item strikten Garantien für die Unsicherheitsintervalle (nur bei CP vorhanden)
  \item Ressourcenbedarf und Skalierbarkeit
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  R8 CPvsBNNMavani.py
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% 1 Mavani Repo SVI, HMC cp exec on comp metrics diff most minimal analyzing

% import numpy as np
% from sklearn.model_selection import train_test_split
% from sklearn.neural_network import MLPRegressor

% # 1. Daten laden
% X, y = load_yacht_data()  # dein Dataset-Loader

% # 2. Split: Train / Calib / Test
% X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)
% X_calib, X_test, y_calib, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

% # 3. Modell trainieren
% model = MLPRegressor(hidden_layer_sizes=(50,50), max_iter=1000, random_state=42)
% model.fit(X_train, y_train)

% # 4. Residuen auf Calibration-Set
% y_calib_pred = model.predict(X_calib)
% errors = np.abs(y_calib - y_calib_pred)

% # 5. Quantil bestimmen für 90%-Intervalle
% alpha = 0.1
% quantile = np.quantile(errors, 1 - alpha)

% # 6. Prediction Intervals auf Test-Set
% y_test_pred = model.predict(X_test)
% lower = y_test_pred - quantile
% upper = y_test_pred + quantile

% # 7. Coverage berechnen
% coverage = np.mean((y_test >= lower) & (y_test <= upper))
% print(f"Coverage: {coverage:.3f}")

% # Optional: Interval width
% interval_width = np.mean(upper - lower)
% print(f"Avg Interval Width: {interval_width:.3f}")

% R8 Vergleich

\begin{table}[!htpb]
  \centering
  \begin{tabularx}{\textwidth}{|l|l|X|}
    \hline
      & \textbf{\gls{Bayesianische neuronale Netze}} & \textbf{\gls{Conformal Prediction}} \\
    \hline
    \textbf{\gls{Aleatorische Unsicherheit}} & 
    \begin{tabular}[c]{@{}l@{}} 
      Post.-Verteilung \( p(\theta \mid \mathcal{D}) \) \\ 
      UQ ü. Modellparam. bas. auf Train. \\[1ex]
      MC Dropout \\ 
    \end{tabular} &
    \begin{tabular}[c]{@{}l@{}} 
      CI \( \hat{y} \pm z \cdot \sigma \) \\ 
      UQ durch CI \\[1ex]
      Ensemble \\ 
    \end{tabular} \\
    \hline
    \textbf{\gls{Epistemische Unsicherheit}} & 
    \begin{tabular}[c]{@{}l@{}} 
      Bayes. Uns. \( p(\theta \mid \mathcal{D}) \) \\ 
      UQ ü. Modellparam. Bayes. Inferenz \\[1ex]
      VI: Post.-Approx. 
    \end{tabular} &
    \begin{tabular}[c]{@{}l@{}} 
      Vertr.-Regionen \\ 
      Pred.-UQ durch CI \\[1ex]
      GPR: UQ-Ansatz Kernel, Train. 
    \end{tabular} \\
    \hline
  \end{tabularx}
  \caption{Vergleich der UQ-Ansätze für \gls{Bayesianische neuronale Netze} und \gls{Conformal Prediction}}\label{tab:chapter6r81}
\end{table}


\footnote{%
\begin{minipage}[t]{\textwidth}
\scriptsize
\textbf{Quellen zu Tab. \ref{tab:chapter6r81}:}\\[0.5em]
\textbf{Bayesianische neuronale Netze (BNNs)}\\
Aleatorische Unsicherheit: \parencite[Kap.~3]{blundell2015weight}; \parencite[S.~40–42]{gal2016uncertainty} \\
Epistemische Unsicherheit: \parencite[S.~40–42]{gal2016uncertainty}; \parencite{mackay1992practical} \\[0.5em]

\textbf{Conformal Prediction (CP)}\\
Aleatorische Unsicherheit: \parencite[S.~4–5]{vovk2005algorithmic}; \parencite{angelopoulos2021gentle} \\
Epistemische Unsicherheit: \parencite{angelopoulos2021gentle}; \parencite[S.~63–65]{shafer2008tutorial}; \parencite{rasmussen2006gaussian}
\end{minipage}%
}


\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R9
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R9 Untersuchung des theoretischen Einflusses verschiedener Faktoren auf die Unsicherheitsschätzungen ausgewählter Modelle.

% Untersuchung - Most Minimal Sensitivitäts-Analyse: 
% S1: Modelldefinition: 
% S2: Parameterbereich
% S3: Durchführung der Analyse

% Vergleich ausgewählter Modelle

\textit{A - Modelldefinition}, \textit{B - Parameterbereich}, \textit{C - Durchführung}

\begin{table}[!htpb]
  \centering
  \begin{tabularx}{\textwidth}{|l|X|X|}
    \hline
    & \textbf{BNN} & \textbf{CFP} \\
    \hline
    \textbf{A} & 
    \begin{tabular}[c]{@{}l@{}} 
      Post. \( p(\theta \mid \mathcal{D}) \) \\ 
      UQ ü. Modellparam. \\[1ex]
      MC Dropout 
    \end{tabular} &
    \begin{tabular}[c]{@{}l@{}} 
      CI \( \hat{y} \pm z \cdot \sigma \) \\ 
      UQ durch CI \\[1ex]
      Ensemble
    \end{tabular} \\
    \hline
    \textbf{B} & 
    \begin{tabular}[c]{@{}l@{}} 
      Modellparam.: Gew- $w_i$, Verteil. \\ 
      - Sens. der Uns. ggü. Prioren \\ 
      - Einfluss von Hyperparam.
    \end{tabular} &
    \begin{tabular}[c]{@{}l@{}} 
      Unsicherheitsb.: CI \\ 
      - Einfluss von Vertr.-regionen
    \end{tabular} \\
    \hline
    \textbf{C} & 
    \begin{tabular}[c]{@{}l@{}} 
      Bayes. Inferenz z. UQ-Approx. \\ 
      - MC Sim. mit Dropout
    \end{tabular} &
    \begin{tabular}[c]{@{}l@{}} 
      Ensemble-Methode zur UQ \\ 
      - Vertr.-regionen, CI UQ-Analyse
    \end{tabular} \\
    \hline
  \end{tabularx}
  \caption{R9 Sensitivitätsanalyse von UQ für BNN und CFP}\label{tab:chapter6r91}
\end{table}

% S4: Auswertung


\footnote{%
\begin{minipage}[t]{\textwidth}
\scriptsize
\textbf{Quellen zu Tab. \ref{tab:chapter6r91}:}\\[0.5em]
\textbf{BNN (Bayesianische neuronale Netze)}\\
A (Modelldefinition): \parencite[Kap.~3]{blundell2015weight}; \parencite[S.~40–42]{gal2016uncertainty} \\
B (Parameterbereich): \parencite[S.~448–450]{mackay1992practical}; \parencite[Kap.~5]{rasmussen2006gaussian} \\
C (Durchführung): \parencite[S.~41–42]{gal2016uncertainty}; \parencite{blundell2015weight} \\[0.5em]

\textbf{CFP (Conformal Prediction)}\\
A (Modelldefinition): \parencite{angelopoulos2021gentle}; \parencite{shafer2008tutorial} \\
B (Parameterbereich): \parencite[S.~63–65]{shafer2008tutorial}; \parencite{vovk2005algorithmic} \\
C (Durchführung): \parencite{angelopoulos2021gentle}; \parencite{shafer2008tutorial}
\end{minipage}%
}


\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R_base
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% % EDNN Grundlage 

% \parencite{oberkampf2010}
% ~\parencite{Choi2017}

% EDNN Regression 

% ~\parencite{AlexanderAmini2020}

% EDNN Ensemble 

% ~\parencite{Schreck2023}

% % Ninad

% % ~\parencite{Gopakumar2024}

% EDNN Entwicklung

% ~\parencite{Deng2023}



% benchmark
% K. GREENMAN, A. SOLEIMANY, K. YANG: Benchmarking Uncertainty Quantification For Protein Engineering. URL https://openreview.net/pdf?id=G0vuqNwxaeA. – Aktualisierungsdatum: 21.04.2022 – Überprüfungsdatum 14.04.2025 

% benchmark <-> proteindataset


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Archive.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \section{Autonome Unterwasserfahrzeuge (AUVs)}

% Der aktuelle Stand der Technik bei autonomen Unterwasserfahrzeugen (AUVs) zeigt einen zunehmenden Einsatz von \textbf{machine-learning-basierten Surrogatmodellen}, etwa zur Umgebungsmodellierung, Pfadplanung oder Systemdiagnose. 

% In komplexen maritimen Umgebungen sind AUVs typischerweise mit \emph{aleatorischer Unsicherheit} konfrontiert – beispielsweise durch verrauschte Sensordaten, Strömungseinflüsse oder schwankende Sichtverhältnisse. Surrogatmodelle wie \textit{Gaussian Processes}, \textit{Bayesian Neural Networks} oder \textit{Evidential Deep Learning} ermöglichen nicht nur schnelle Approximationen physikalischer Modelle, sondern auch die quantitative Erfassung \emph{epistemischer Unsicherheit} in bislang unkartierten Regionen.

% Moderne Entscheidungsverfahren berücksichtigen zunehmend unsicherheitsbewusste Vorhersagen, z.\,B.\ bei:

% \begin{itemize}
%   \item adaptiver Missionsplanung,
%   \item Risikoabschätzung in Echtzeit,
%   \item Bewertung vergrabener Munitionsfunde.
% \end{itemize}

% Hybride Konzepte aus lernbasierten Surrogaten und probabilistischer Modellierung gelten als vielversprechender Ansatz für robuste und erklärbare AUV-Systeme unter Unsicherheit~\parencite{cui2020, yan2021}.

% \section{Model Predictive Control (MPC) unter Unsicherheit}

% Aktuelle Arbeiten zur Model Predictive Control (MPC) zeigen, dass klassische deterministische Modelle zunehmend durch \textbf{stochastische und robuste Varianten} ergänzt werden. Moderne Verfahren wie \emph{Stochastic MPC} und \emph{Robust MPC} integrieren probabilistische Prädiktionsintervalle zur Modellierung \emph{aleatorischer Unsicherheit}.

% Zunehmend wird jedoch auch \textbf{epistemische Unsicherheit} berücksichtigt, insbesondere bei datengetriebenen Modellen wie \textit{Deep Neural Networks} oder \textit{Gaussian Processes}, deren Generalisierungsfähigkeit außerhalb des Trainingsbereichs limitiert ist.

% Ansätze wie \textit{Bayesian MPC} oder \textit{Evidential MPC} versuchen, beide Unsicherheitsarten zu modellieren und in Optimierungsstrategien einzubetten – z.\,B.\ mittels:

% \begin{itemize}
%   \item adaptiver Kostenfunktionen,
%   \item probabilistischer Constraints,
%   \item Szenariostreuung zur Absicherung.
% \end{itemize}

% Beispielhafte Open-Source-Projekte:

% \begin{itemize}
%   \item \url{https://github.com/do-mpc/do-mpc}
%   \item \url{https://github.com/lucasrm25/Gaussian-Process-based-Model-Predictive-Control}
%   \item \url{https://github.com/TinyMPC/TinyMPC}
% \end{itemize}

% \section{Surrogatmodelle und Unsicherheitsdarstellung}

% % Surrogatmodelle dienen der effizienten Approximation komplexer physikalischer Systeme. Typische Verfahren umfassen~\parencite{sudret2017, tik2025}:

% \begin{itemize}
%   \item \textbf{Kriging / Gaussian Process Regression (GPR)}
%   \item \textbf{Polynomial Chaos Expansion (PCE)}
%   \item \textbf{Gradient-Enhanced Kriging (GEK)}
%   \item \textbf{Radiale Basisfunktionen (RBF)}
%   \item \textbf{Support Vector Machines (SVM)}
% \end{itemize}

% Im Projektkontext kommen insbesondere \textbf{Bayessche Neuronale Netze (BNNs)} und \textbf{Ensemble-Methoden} zur Anwendung.

% \section{Meta-Unsicherheit und Unsicherheitsbewertung}

% % Der aktuelle Stand der Technik zur \textbf{Meta-Unsicherheit} bezieht sich auf die \emph{übergeordnete Aggregation und Bewertung} verschiedener Unsicherheitsquellen in Surrogatmodellen. Während klassische Methoden aleatorische und epistemische Unsicherheiten getrennt modellieren, zielen neuere Ansätze auf deren gemeinsame Bewertung ab~\parencite{schmitt2022}.

% Methoden wie:

% \begin{itemize}
%   \item \textit{Uncertainty Meta-Learning},
%   \item \textit{Uncertainty Calibration Layers},
%   \item \textit{Evidential Frameworks},
% \end{itemize}

% \noindent
% ermöglichen die adaptive Gewichtung von Unsicherheiten je nach Szenariokontext und Modellkonfidenz. Ziel ist eine robuste, vergleichbare und erklärbare Modellbewertung für sicherheitskritische Anwendungen.

% \section{Sensitivitätsanalyse und Kalibrierung}

% % Die Sensitivitätsanalyse quantifiziert den Einfluss einzelner Eingangsgrößen auf Modellvorhersagen oder Unsicherheiten. Sie hilft, dominante Einflussfaktoren systematisch zu identifizieren~\parencite{borgonovo2017, tunkiel2020}. Dabei unterscheidet man:

% \begin{itemize}
%   \item \textbf{Invasive Methoden:} direkt im Modell integriert,
%   \item \textbf{Nicht-invasive Methoden:} modellunabhängige Blackbox-Analyse.
% \end{itemize}

% Die \textbf{Modellkalibrierung} dient dazu, Vorhersagen an die Realität (Ground Truth) anzupassen, etwa durch Parameterabgleich oder Szenariobasierung.

% \section{Zeitreihenanalyse}

% % Für die Analyse zeitabhängiger Sensordaten – wie sie bei AUVs typischerweise auftreten – kommen moderne Zeitreihenanalyse-Tools zum Einsatz. Ein Beispiel dafür ist das \textit{TSFEL Framework}~\parencite{tsfel2025}:

% \begin{itemize}
%   \item \url{https://github.com/fraunhoferportugal/tsfel}
% \end{itemize}

% \section{Zusammenfassung}

% Der Stand der Technik zeigt, dass zwar zahlreiche Methoden zur Unsicherheitsquantifizierung existieren, ein systematischer, modellagnostischer und \textbf{integrierter Ansatz zur Szenariobewertung} unter Berücksichtigung beider Unsicherheitsarten jedoch fehlt. Diese Arbeit zielt darauf ab einen methodischen Beitrag zur transparenten Bewertung maschineller Lernverfahren in sicherheitskritischen Anwendungen zu leisten.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Datensätze
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

~\nocite{BostonHousing2013}
~\nocite{CombinedCyclePowerPlant2014}
~\nocite{ConcreteCompressiveStrength1998}
~\nocite{ConditionBasedMaintenanceOfNavalPropulsionPlants2014}
~\nocite{EnergyEfficiency2012}
~\nocite{Fisher1936}
~\nocite{Cortez2009}
~\nocite{Gains2024}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Software 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

~\nocite{DuckDBDevelopers.2024}
~\nocite{EdlPytorchDevelopers.2024}
~\nocite{LoguruDevelopers.2024}
~\nocite{MatplotlibDevelopers.2024}
~\nocite{NotebookDevelopers.2024}
~\nocite{NumpyDevelopers.2024}
~\nocite{OpenpyxlDevelopers.2024}
~\nocite{PandasDevelopers.2024}
~\nocite{ProperscoringDevelopers.2024}
~\nocite{PyroPplDevelopers.2024}
~\nocite{PytestDevelopers.2024}
~\nocite{RuffDevelopers.2024}
~\nocite{ScikitLearnDevelopers.2024}
~\nocite{ScipyDevelopers.2024}
~\nocite{SeabornDevelopers.2024}
~\nocite{SphinxDevelopers.2024}
~\nocite{TensorflowDevelopers.2024}
~\nocite{TorchDevelopers.2024}
~\nocite{TorchmetricsDevelopers.2024}
~\nocite{TorchvisionDevelopers.2024}
~\nocite{XlrdDevelopers.2024}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Repos
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#

~\nocite{amini2020deep}
%~\nocite{amini2020deepfork}
~\nocite{sensoy2018evidential}
~\nocite{nmavani2025}
~\nocite{windler2025}

\end{otherlanguage}
