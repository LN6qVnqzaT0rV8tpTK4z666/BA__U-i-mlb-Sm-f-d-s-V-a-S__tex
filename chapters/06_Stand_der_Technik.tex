% !TeX root = ../main.tex

\chapter{Stand der Technik}
\label{chapter:stand-der-technik}

\begin{otherlanguage}{american}
%
%
%
\end{otherlanguage}


\begin{otherlanguage}{ngerman}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R1 Welche auf maschinellem Lernen basierenden Surrogatmodelle sind für die Quantifizierung von Unsicherheiten geeignet?

\begin{table}[!htpb]
  \centering
  \begin{tabularx}{\textwidth}{|l|X|}
    \hline
    \textbf{\gls{surrogat}} & \textbf{Eignungsgrund} \\
    \hline
    \begin{itemize}[topsep=0em, itemsep=0.25em, left=0em, labelsep=0.25em]
      \item 1. \gls{Gaußsche Prozessregression}
    \end{itemize} &  
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item 1.1. Intrinsische probabilistische Ausgabe
      \item 1.2. Exakte Varianzschätzung für kleine Datensätze
      \item 1.3. Kernel-basierte Unsicherheitscharakterisierung
    \end{itemize} \\ 
    \hline
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item 2. Deep Ensembles
    \end{itemize} & 
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item 2.1. Redundante Modellierung reduziert Overconfidence
      \item 2.2. Einfache Integration in existierende Architekturen
      \item 2.3. Robust gegen Out-of-Distribution-Daten
    \end{itemize} \\
    \hline
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item 3. Hybrid-Methoden
    \end{itemize} & 
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item 3.1. Kombiniert Stärken von Blackbox-Modellen und GPR
      \item 3.2. Nachrüstbar auf existierende Modelle
      \item 3.3. Recheneffiziente Unsicherheitspropagation
    \end{itemize} \\
    \hline
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item 4. \gls{Bayesianische neuronale Netze}s
    \end{itemize} & 
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item 4.1. Systematische Integration von Priors
      \item 4.2. Theoretisch fundierte Parameterunsicherheit
      \item 4.3. Natürliche Regularisierung durch Bayes'sche Inferenz
    \end{itemize} \\
    \hline
  \end{tabularx}
  \caption{R1 Vgl. v. Unsicherheitsquantifizierungsmethoden in ML}
  \label{tab:chapter6r1}
\end{table}

\footnote{%
\begin{minipage}[t]{\textwidth}
\scriptsize
\textbf{Quellen zu Tab. \ref{tab:chapter6r1}:}\\
1. \parencite[Kap.~2]{rasmussen2006gaussian}, 
1.1. \parencite[S.~16–17]{rasmussen2006gaussian}, 
1.2. \parencite[Kap.~2.2]{rasmussen2006gaussian},
1.3. \parencite[Kap.~4]{rasmussen2006gaussian}\\[0.3em]
2. \parencite{lakshminarayanan2017simple},
2.1. \parencite[S.~3]{lakshminarayanan2017simple},
2.2. \parencite[S.~5]{lakshminarayanan2017simple},
2.3. \parencite{ovadia2019can}\\[0.3em]
3. \parencite{perdikaris2017nonlinear}, 
3.1. \parencite[S.~5–6]{perdikaris2017nonlinear},
3.2. \parencite[S.~6]{perdikaris2017nonlinear},
3.3. \parencite{liu2020multifidelity}\\[0.3em]
4. \parencite{gal2016uncertainty}, 
4.1. \parencite[Kap.~2.3]{gal2016uncertainty}, 
4.2. \parencite[S.~40–41]{gal2016uncertainty}, 
4.3. \parencite[S.~41–42]{gal2016uncertainty}
\end{minipage}%
}

% (Übersicht aus MC25) 

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R2 Welche allgemeinen und modellspezifischen Faktoren beeinflussen das Lernen von Unsicherheiten in ML-Modellen?

\newline
R2.1 Allgemeine Faktoren

\begin{table}[!htpb]
  \begin{tabularx}{\textwidth}{|l|X|}
    \hline
    \textbf{Unsicherheitsdimensionen} & \textbf{Mögliche Werte} \\
    \hline
    1. Lokalisierung im System & Umgebung, Modellierung, Funktionen, Ziele, Verfügbare Ressourcen \\
    \hline
    2. Natur & Epistemisch, Aleatorisch \\
    \hline
    3. Grad der Unsicherheit & Keine Unsicherheit, Mangel an Wissen, Mangel an Bewusstsein, Mangel an Fähigkeit Bewusstsein zu erlangen \\
    \hline
    4. Entstehungszeit & Anforderungsdefinition, Entwicklungszeit, Laufzeit \\
    \hline
  \end{tabularx}
  \caption{R2 Allg. Faktoren Klassifizierung Unsicherheit KI-Systeme nach A. Kreuz ~\nocite{AndreasKreutz2022} ~\nocite{AndreasKreutz2022b}}
  \label{tab:chapter6r21}
\end{table}

\newline
R2.2 Modellspezifische Faktoren

\begin{table}[!htpb]
  \centering
  \begin{tabularx}{\textwidth}{|l|X|}
    \hline
    \textbf{\gls{Bayesianische neuronale Netze}} & \textbf{Modellspezifische Faktoren} \\
    \hline
    1. Prior-Verteilungen & Wahl der Prioren beeinflusst die Unsicherheit und Vorhersagegenauigkeit. \\
    \hline
    2. Likelihood-Funktion & Bestimmt, wie Unsicherheit in den Beobachtungen modelliert wird (z.B. durch Gaussian). \\
    \hline
    3. Posterior Approximation & MCMC oder Variational Inference schätzt den Posterior und die Unsicherheit. \\
    \hline
    4. Regularisierung & Hilft, Overfitting zu vermeiden und Unsicherheit zu kontrollieren. \\
    \hline
    5. Bayesische Optimierung & Optimiert Hyperparameter unter Berücksichtigung der Unsicherheit. \\
    \hline
    6. Datenqualität & Schlechte Datenqualität erhöht Unsicherheit, gute Qualität verringert sie. \\
    \hline
    7. Maßstab & Der Maßstab des Modells beeinflusst die Unsicherheitsquantifizierung. \\
    \hline
  \end{tabularx}
  \caption{R2.2 Modellspezifische Faktoren zur Unsicherheitsklassifizierung \gls{Bayesianische neuronale Netze}}\label{tab:chapter6r22}
\end{table}

\begin{table}[!htpb]
  \centering
  \begin{tabularx}{\textwidth}{|l|X|}
    \hline
    \textbf{\gls{Evidenzbasierte neuronale Netze}} & \textbf{Modellspezifische Faktoren} \\
    \hline
    1. Prior-Funktion & Beeinflusst, wie Unsicherheit über Daten und Parameter modelliert wird. \\
    \hline
    2. Evidenzfunktion & Modelliert Unsicherheit mit Evidenzparametern wie \( \alpha \), \( \beta \), und \( v \). \\
    \hline
    3. Posterior Approximation & Näherung der Posterior-Verteilung zur Unsicherheitsbestimmung. \\
    \hline
    4. Evidenz Optimierung & Optimierung der Evidenzparameter während des Trainings. \\
    \hline
    5. Evidenzbasierte Regularisierung & Regularisiert Evidenzparameter, um Overfitting zu vermeiden. \\
    \hline
    6. Multimodalität & Modelliert mehrere konkurrierende Unsicherheitsvorhersagen gleichzeitig. \\
    \hline
    7. Dateninhärente Unsicherheit & Unsicherheit, die direkt aus den Daten selbst resultiert. \\
    \hline
    8. Datenqualität & Schlechte Datenqualität erhöht die Unsicherheit im Modell. \\
    \hline
    9. Netzwerktiefe & Die Tiefe beeinflusst die Fähigkeit, Unsicherheit zu erfassen. \\
    \hline
  \end{tabularx}
  \caption{R2.2 Modellspezifische Faktoren zur Unsicherheitsklassifizierung \gls{Evidenzbasierte neuronale Netze}}\label{tab:chapter6r23}
\end{table}

\footnote{%
\begin{minipage}[t]{\textwidth}
\scriptsize
\textbf{Quellen zu Tab. \ref{tab:chapter6r21}, Tab. \ref{tab:chapter6r22}, Tab. \ref{tab:chapter6r23}:}\\[0.125em]
\textbf{R2.1 Allgemeine Faktoren}: 
1. \parencite[S.~47–52]{AndreasKreutz2022},
2. \parencite[S.~54]{AndreasKreutz2022},
3. \parencite[S.~56–58]{AndreasKreutz2022},
4. \parencite[S.~60]{AndreasKreutz2022}\\[0.125em]

\textbf{R2.2.1 Bayesianische neuronale Netze}: 
1. \parencite[Kap.~2.3]{gal2016uncertainty},
2. \parencite[Kap.~3]{blundell2015weight},
3. \parencite[S.~40–41]{gal2016uncertainty},
4. \parencite[S.~41–42]{gal2016uncertainty},
5. \parencite[Kap.~7.4]{rasmussen2006gaussian},
6. \parencite[S.~16]{bishop2006pattern},
7. \parencite[S.~29–31]{gal2016uncertainty}\\[0.125em]

\textbf{R2.2.2 Evidenzbasierte neuronale Netze}: 
1. \parencite{sensoy2018evidential},
2. \parencite[S.~2–3]{sensoy2018evidential},
3. \parencite[S.~4]{sensoy2018evidential},
4. \parencite[S.~5]{sensoy2018evidential},
5. \parencite[S.~6]{sensoy2018evidential},
6. \parencite[S.~6–7]{sensoy2018evidential},
7. \parencite{kendall2017uncertainties},
8. \parencite{kendall2017uncertainties},
9. \parencite[S.~6]{sensoy2018evidential}
\end{minipage}%
}


\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R3
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R3 Wie können diese Einflussfaktoren abgeschwächt werden, um die Unsicherheitsabschätzung zu verbessern?

\newline
Wie Allgemeine Faktoren abschwächen?

\begin{table}[!htpb]
  \centering
  \begin{tabularx}{\textwidth}{|l|X|}
    \hline
    \textbf{Unsicherheitsdimensionen} & \textbf{Mögliche Abschwächung} \\
    \hline
    1. Lokalisierung im System & Verbesserung der Modellgenauigkeit und der Ressourcennutzung durch gezielte Datensammlung und Modellanpassung. \\
    \hline
    2. Natur & Einsatz von Hybriden Modellen, die sowohl epistemische als auch aleatorische Unsicherheit modellieren können. \\
    \hline
    3. Grad der Unsicherheit & Erhöhung des Modellspezifikationsgrades, z. B. durch Mehrfachmodellierung und Unsicherheitsquantifizierung. \\
    \hline
    4. Entstehungszeit & Frühzeitige Einbindung von Unsicherheitsmodellierung in die Anforderungsdefinition und Entwicklungszeit. \\
    \hline
  \end{tabularx}
  \caption{R3 Abschwächung allgemeiner Faktoren KI Systeme}\label{tab:chapter6r31}
\end{table}

\newline
Wie Modellspezifische Faktoren abschwächen?

\begin{table}[!htpb]
  \centering
  \begin{tabularx}{\textwidth}{|l|X|}
    \hline
    \textbf{Modellspezifische Faktoren} & \textbf{Abschwächung der Unsicherheitsabschätzung} \\
    \hline
    1. Prior-Verteilungen & Auswahl robusterer Priors und der Anpassung der Priors an die Daten zur Vermeidung von zu starker Unsicherheit. \\
    \hline
    2. Likelihood-Funktion & Optimierung der Likelihood-Modelle, z. B. durch mehrdimensionale Likelihoods für die Unsicherheit. \\
    \hline
    3. Posterior Approximation & Verwendung effizienter Approximationstechniken wie Variational Inference zur besseren Unsicherheitsabschätzung. \\
    \hline
    4. Regularisierung & Anwendung von stärkeren Regularisierungstechniken, um Overfitting zu vermeiden und die Unsicherheit gezielt zu verringern. \\
    \hline
    5. Bayesische Optimierung & Optimierung von Hyperparametern unter Unsicherheit zur gezielten Reduzierung der Unsicherheit im Modell. \\
    \hline
    6. Datenqualität & Verbesserung der Datenqualität durch Datenbereinigung und Zusammenstellung von Trainingsdatensätzen, die die Unsicherheit reduzieren. \\
    \hline
    7. Maßstab & Verwendung von Skalenmodellen zur Reduzierung von Unsicherheit durch Skalierung des Modells auf größere Datenmengen. \\
    \hline
  \end{tabularx}
  \caption{R3.1 Abschwächung Modellspezifische Faktoren zur Unsicherheitsklassifizierung \textbf{\gls{Bayesianische neuronale Netze}}}\label{tab:chapter6r32}
\end{table}

\begin{table}[!htpb]
  \centering
  \begin{tabularx}{\textwidth}{|l|X|}
    \hline
    \textbf{Modellspezifische Faktoren} & \textbf{Abschwächung der Unsicherheitsabschätzung} \\
    \hline
    1. Prior-Funktion & Verwendung von flexiblen Prior-Funktionen, die auf den spezifischen Unsicherheitsgrad der Daten abgestimmt sind. \\
    \hline
    2. Evidenzfunktion & Verbesserung der Evidenzparameter, z. B. durch den Einsatz von multimodalen Evidenzfunktionen, um Unsicherheit besser zu modellieren. \\
    \hline
    3. Posterior Approximation & Anwendung von genauen MCMC-Methoden oder besseren Näherungsverfahren zur genaueren Posterior-Bestimmung. \\
    \hline
    4. Evidenz Optimierung & Evidenzparameter optimieren, um unsichere Parameterbereiche zu vermeiden und so Unsicherheit zu reduzieren. \\
    \hline
    5. Evidenzbasierte Regularisierung & Stärkere Regularisierung der Evidenzparameter zur Vermeidung von zu großer Unsicherheit bei der Modellierung. \\
    \hline
    6. Multimodalität & Integration von multimodalen Unsicherheitsmodellen, um verschiedene Unsicherheitsquellen gleichzeitig zu verarbeiten. \\
    \hline
    7. Dateninhärente Unsicherheit & Reduktion der Datenrauschen und Verbesserung der Datenvorverarbeitung, um die Datenunsicherheit zu minimieren. \\
    \hline
    8. Datenqualität & Optimierung der Datenqualität durch Verwendung besserer Datensätze und Datenaugmentation. \\
    \hline
    9. Netzwerktiefe & Optimierung der Netzwerktiefe unter Berücksichtigung der Modellkomplexität, um unnötige Unsicherheiten zu vermeiden. \\
    \hline
  \end{tabularx}
  \caption{R3.2 Abschwächung Modellspezifische Faktoren zur Unsicherheitsklassifizierung \textbf{\gls{Evidenzbasierte neuronale Netze}}}\label{tab:chapter6r33}
\end{table}

\footnote{%
\begin{minipage}[t]{\textwidth}
\scriptsize
\textbf{Quellen zu Tab. \ref{tab:chapter6r31}, Tab. \ref{tab:chapter6r32}, Tab. \ref{tab:chapter6r33}:}\\[0.125em]
\textbf{R3 Allgemeine Faktoren}\\
1. \parencite[S.~47–52]{AndreasKreutz2022},
2. \parencite[S.~6–9]{perdikaris2017nonlinear},
3. \parencite[S.~3]{ovadia2019can},
4. \parencite[S.~60]{AndreasKreutz2022} \\[0.125em]

\textbf{R3.1 Bayesianische neuronale Netze}\\
1. \parencite[Kap.~2.3]{gal2016uncertainty},
2. \parencite[Kap.~3]{blundell2015weight},
3. \parencite[S.~40–41]{gal2016uncertainty},
4. \parencite[S.~41–42]{gal2016uncertainty},
5. \parencite[Kap.~7.4]{rasmussen2006gaussian},
6. \parencite[S.~16]{bishop2006pattern},
7. \parencite[S.~29–31]{gal2016uncertainty} \\[0.125em]

\textbf{R3.2 Evidenzbasierte neuronale Netze}\\
1. \parencite{sensoy2018evidential},
2. \parencite[S.~3–4]{sensoy2018evidential},
3. \parencite[S.~4]{sensoy2018evidential},
4. \parencite[S.~5]{sensoy2018evidential},
5. \parencite[S.~6]{sensoy2018evidential},
6. \parencite[S.~6–7]{sensoy2018evidential},
7. \parencite{kendall2017uncertainties},
8. \parencite{kendall2017uncertainties},
9. \parencite[S.~6]{sensoy2018evidential}
\end{minipage}%
}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R4
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R4 Inwieweit kann ML-basierte Unsicherheitsquantifizierung zuverlässig den in realen Anwendungsszenarien beobachteten Unsicherheiten entsprechen?
\\
\\
% Beweis aus Herleitung wie das einander entsprechen kann.
\\
\\
% UQ-Pred-UQ-Data-EQ-Ensure-Framework
Lanini et. al liefern ein Framework zur Bewertung von R4 ~\parencite{Lanini2024} zur Optimierung in einer Anwendungsdomäne. Ihre Recherche differenziert zur Beantwortung weiterhin datenbasierte und modellbasierte Unsicherheitsmetriken. 
\\
\\
Manchingal et al. distanzieren sich von der Optimierung auf Anwendungsdomänen. Als Paradigmenwechsel beschreiben Sie epistemische Künstliche Intelligenz. Im Kern soll nicht nur auf Wissen in Form von Daten, sondern auch auf Nicht-Wissen trainiert werden. \parencite{manchingal2025}

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{../figures/x3.png}
  \caption{R4.1}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{../figures/x2.png}
  \caption{R4.2}
\end{figure}

% Die spezifischen Aufgaben dieser Arbeit umfassen:

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R5
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R5 Durchführung einer umfassenden Literaturübersicht über UQ-Techniken in der ML-basierten Surrogatmodellierung.

\parencite{Ulmer2023}

~\nocite{Gawlikowski2023}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R6
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R6 Identifizierung und Analyse geeigneter Unsicherheitsmetriken für Surrogatmodelle, wobei zwischen aleatorischer und epistemischer Unsicherheit unterschieden wird.

\begin{table}[htpb]
  \centering
  \begin{tabularx}{\textwidth}{|l|l|X|}
    \hline
    & \textbf{Datenbasierte Metriken} & \textbf{Modellbasierte Metriken} \\
    \hline
    \textbf{AC} & 
    \begin{tabular}[c]{@{}l@{}} 
      \( \sigma = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2} \) \\ 
      Standardabweichung (Rauschen) \\[1ex]
      \( \text{Var} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 \) \\ 
      Varianz der Residuen
    \end{tabular}
    & 
    \begin{tabular}[c]{@{}l@{}} 
      \( p(\theta \mid \mathcal{D}) \) \\ 
      Bayesianische Unsicherheit (Posterior) \\[1ex]
      Kreuzvalidierung (Training/Testdaten)
    \end{tabular} \\
    \hline
    \textbf{EC} & 
    \begin{tabular}[c]{@{}l@{}} 
      \( \text{Fehler} = \sum_{i=1}^{n} |y_i - \hat{y}_i| \) \\ 
      Fehleranalyse auf Testdaten
    \end{tabular}
    & 
    \begin{tabular}[c]{@{}l@{}} 
      \( \hat{y} \pm z \cdot \sigma \) \\ 
      Konfidenzintervall \\[1ex]
      \( H(p) = - \sum_{i} p(x_i) \log(p(x_i)) \) \\ 
      Entropie der Posterior-Verteilung
    \end{tabular} \\
    \hline
  \end{tabularx}
  \caption{R6 Unsicherheitsmetriken für Surrogatmodelle}\label{tab:chapter6r61}
\end{table}


\footnote{%
\begin{minipage}[t]{\textwidth}
\scriptsize
\textbf{Quellen zu Tab. \ref{tab:chapter6r61}:}\\[0.125em]
\textbf{AC (Aleatorische Unsicherheit)}\\
\quad Datenbasierte Metriken: \parencite[S.~28–30]{bishop2006pattern}, 
\quad Modellbasierte Metriken: \parencite[Kap.~2]{rasmussen2006gaussian}; \parencite{blundell2015weight}\\ [0.125em]

\textbf{EC (Epistemische Unsicherheit)}\\
\quad Datenbasierte Metriken: \parencite[S.~30–32]{bishop2006pattern}, 
\quad Modellbasierte Metriken: \parencite[S.~40–42]{gal2016uncertainty}; \parencite{sensoy2018evidential}, 
\end{minipage}%
}


\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R7
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R7 Vergleich modellspezifischer und anwendungsspezifischer Bewertungsmetriken für die Quantifizierung von Unsicherheit.

% Beispiel-Anwendungsdomäne: [Beispiel-Domäne]

% Anwendungsspezifikation:

\begin{table}[!htpb]
  \centering
  \resizebox{\textwidth}{!}{
    \begin{tabularx}{\textwidth}{|l|l|X|}
      \hline
        & \textbf{Modellspezifische Metriken} & \textbf{Anwendungsspezifische Metriken} \\
      \hline
      \textbf{AC} & 
      \begin{tabular}[c]{@{}l@{}} 
        \( \text{RMSE} \) \\ 
        \( \text{MAE} \) \\ 
        \( \text{KL}(P \parallel Q) \)
      \end{tabular}
      & 
      \begin{tabular}[c]{@{}l@{}} 
        \( \text{Accuracy} \) \\ 
        \( F_1 \) \\ 
        \( \text{AUC} \)
      \end{tabular} \\
      \hline
      \textbf{EC} & 
      \begin{tabular}[c]{@{}l@{}} 
        \( \mathcal{L}(\theta) \) \\ 
        \( \text{BMA} \) \\ 
        \( \text{CI} \)
      \end{tabular}
      & 
      \begin{tabular}[c]{@{}l@{}} 
        \( \text{Fehler} \) \\ 
        \( H(p) \) \\ 
        \( \text{AUC-PR} \)
      \end{tabular} \\
      \hline
    \end{tabularx}
  }
  \caption{Vergleich der modellspezifischen und anwendungsspezifischen Unsicherheitsmetriken für Surrogatmodelle}\label{tab:chapter6r71}
\end{table}


\footnote{%
\begin{minipage}[t]{\textwidth}
\scriptsize
\textbf{Quellen zu Tab. \ref{tab:chapter6r71}:}\\[0.5em]
\textbf{AC (Aleatorische Unsicherheit)}\\
\quad Modellspezifische Metriken: \parencite[S.~224–226]{bishop2006pattern}; \parencite[Kap.~2]{rasmussen2006gaussian} \\
\quad Anwendungsspezifische Metriken: \parencite[S.~40–42]{bishop2006pattern} \\[0.5em]

\textbf{EC (Epistemische Unsicherheit)}\\
\quad Modellspezifische Metriken: \parencite[S.~40–42]{gal2016uncertainty}; \parencite{blundell2015weight}; \parencite{sensoy2018evidential} \\
\quad Anwendungsspezifische Metriken: \parencite[S.~233–235]{bishop2006pattern}; \parencite{ovadia2019can}
\end{minipage}%
}


\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R8
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R8 Untersuchung und Vergleich verschiedener UQ-Ansätze für ML-basierte Surrogatmodelle, insbesondere Bayes'sche neuronale Netze und konforme Vorhersagen.

% Untersuchung:

% Vergleich

\begin{table}[!htpb]
  \centering
  \begin{tabularx}{\textwidth}{|l|l|X|}
    \hline
      & \textbf{\gls{Bayesianische neuronale Netze}} & \textbf{\gls{Conformal Prediction}} \\
    \hline
    \textbf{\gls{Aleatorische Unsicherheit}} & 
    \begin{tabular}[c]{@{}l@{}} 
      Post.-Verteilung \( p(\theta \mid \mathcal{D}) \) \\ 
      UQ ü. Modellparam. bas. auf Train. \\[1ex]
      MC Dropout \\ 
    \end{tabular} &
    \begin{tabular}[c]{@{}l@{}} 
      CI \( \hat{y} \pm z \cdot \sigma \) \\ 
      UQ durch CI \\[1ex]
      Ensemble \\ 
    \end{tabular} \\
    \hline
    \textbf{\gls{Epistemische Unsicherheit}} & 
    \begin{tabular}[c]{@{}l@{}} 
      Bayes. Uns. \( p(\theta \mid \mathcal{D}) \) \\ 
      UQ ü. Modellparam. Bayes. Inferenz \\[1ex]
      VI: Post.-Approx. 
    \end{tabular} &
    \begin{tabular}[c]{@{}l@{}} 
      Vertr.-Regionen \\ 
      Pred.-UQ durch CI \\[1ex]
      GPR: UQ-Ansatz Kernel, Train. 
    \end{tabular} \\
    \hline
  \end{tabularx}
  \caption{Vergleich der UQ-Ansätze für \gls{Bayesianische neuronale Netze} und \gls{Conformal Prediction}}\label{tab:chapter6r81}
\end{table}


\footnote{%
\begin{minipage}[t]{\textwidth}
\scriptsize
\textbf{Quellen zu Tab. \ref{tab:chapter6r81}:}\\[0.5em]
\textbf{Bayesianische neuronale Netze (BNNs)}\\
Aleatorische Unsicherheit: \parencite[Kap.~3]{blundell2015weight}; \parencite[S.~40–42]{gal2016uncertainty} \\
Epistemische Unsicherheit: \parencite[S.~40–42]{gal2016uncertainty}; \parencite{mackay1992practical} \\[0.5em]

\textbf{Conformal Prediction (CP)}\\
Aleatorische Unsicherheit: \parencite[S.~4–5]{vovk2005algorithmic}; \parencite{angelopoulos2021gentle} \\
Epistemische Unsicherheit: \parencite{angelopoulos2021gentle}; \parencite[S.~63–65]{shafer2008tutorial}; \parencite{rasmussen2006gaussian}
\end{minipage}%
}


\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R9
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R9 Untersuchung des theoretischen Einflusses verschiedener Faktoren auf die Unsicherheitsschätzungen ausgewählter Modelle.

% Untersuchung - Most Minimal Sensitivitäts-Analyse: 
% S1: Modelldefinition: 
% S2: Parameterbereich
% S3: Durchführung der Analyse

% Vergleich ausgewählter Modelle

\textit{A - Modelldefinition}, \textit{B - Parameterbereich}, \textit{C - Durchführung}

\begin{table}[!htpb]
  \centering
  \begin{tabularx}{\textwidth}{|l|X|X|}
    \hline
    & \textbf{BNN} & \textbf{CFP} \\
    \hline
    \textbf{A} & 
    \begin{tabular}[c]{@{}l@{}} 
      Post. \( p(\theta \mid \mathcal{D}) \) \\ 
      UQ ü. Modellparam. \\[1ex]
      MC Dropout 
    \end{tabular} &
    \begin{tabular}[c]{@{}l@{}} 
      CI \( \hat{y} \pm z \cdot \sigma \) \\ 
      UQ durch CI \\[1ex]
      Ensemble
    \end{tabular} \\
    \hline
    \textbf{B} & 
    \begin{tabular}[c]{@{}l@{}} 
      Modellparam.: Gew- $w_i$, Verteil. \\ 
      - Sens. der Uns. ggü. Prioren \\ 
      - Einfluss von Hyperparam.
    \end{tabular} &
    \begin{tabular}[c]{@{}l@{}} 
      Unsicherheitsb.: CI \\ 
      - Einfluss von Vertr.-regionen
    \end{tabular} \\
    \hline
    \textbf{C} & 
    \begin{tabular}[c]{@{}l@{}} 
      Bayes. Inferenz z. UQ-Approx. \\ 
      - MC Sim. mit Dropout
    \end{tabular} &
    \begin{tabular}[c]{@{}l@{}} 
      Ensemble-Methode zur UQ \\ 
      - Vertr.-regionen, CI UQ-Analyse
    \end{tabular} \\
    \hline
  \end{tabularx}
  \caption{R9 Sensitivitätsanalyse von UQ für BNN und CFP}\label{tab:chapter6r91}
\end{table}

% S4: Auswertung


\footnote{%
\begin{minipage}[t]{\textwidth}
\scriptsize
\textbf{Quellen zu Tab. \ref{tab:chapter6r91}:}\\[0.5em]
\textbf{BNN (Bayesianische neuronale Netze)}\\
A (Modelldefinition): \parencite[Kap.~3]{blundell2015weight}; \parencite[S.~40–42]{gal2016uncertainty} \\
B (Parameterbereich): \parencite[S.~448–450]{mackay1992practical}; \parencite[Kap.~5]{rasmussen2006gaussian} \\
C (Durchführung): \parencite[S.~41–42]{gal2016uncertainty}; \parencite{blundell2015weight} \\[0.5em]

\textbf{CFP (Conformal Prediction)}\\
A (Modelldefinition): \parencite{angelopoulos2021gentle}; \parencite{shafer2008tutorial} \\
B (Parameterbereich): \parencite[S.~63–65]{shafer2008tutorial}; \parencite{vovk2005algorithmic} \\
C (Durchführung): \parencite{angelopoulos2021gentle}; \parencite{shafer2008tutorial}
\end{minipage}%
}


\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R_base
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% % EDNN Grundlage 

% \parencite{oberkampf2010}
% ~\parencite{Choi2017}

% EDNN Regression 

% ~\parencite{AlexanderAmini2020}

% EDNN Ensemble 

% ~\parencite{Schreck2023}

% % Ninad

% % ~\parencite{Gopakumar2024}

% EDNN Entwicklung

% ~\parencite{Deng2023}



% benchmark
% K. GREENMAN, A. SOLEIMANY, K. YANG: Benchmarking Uncertainty Quantification For Protein Engineering. URL https://openreview.net/pdf?id=G0vuqNwxaeA. – Aktualisierungsdatum: 21.04.2022 – Überprüfungsdatum 14.04.2025 

% benchmark <-> proteindataset


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Archive.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \section{Autonome Unterwasserfahrzeuge (AUVs)}

% Der aktuelle Stand der Technik bei autonomen Unterwasserfahrzeugen (AUVs) zeigt einen zunehmenden Einsatz von \textbf{machine-learning-basierten Surrogatmodellen}, etwa zur Umgebungsmodellierung, Pfadplanung oder Systemdiagnose. 

% In komplexen maritimen Umgebungen sind AUVs typischerweise mit \emph{aleatorischer Unsicherheit} konfrontiert – beispielsweise durch verrauschte Sensordaten, Strömungseinflüsse oder schwankende Sichtverhältnisse. Surrogatmodelle wie \textit{Gaussian Processes}, \textit{Bayesian Neural Networks} oder \textit{Evidential Deep Learning} ermöglichen nicht nur schnelle Approximationen physikalischer Modelle, sondern auch die quantitative Erfassung \emph{epistemischer Unsicherheit} in bislang unkartierten Regionen.

% Moderne Entscheidungsverfahren berücksichtigen zunehmend unsicherheitsbewusste Vorhersagen, z.\,B.\ bei:

% \begin{itemize}
%   \item adaptiver Missionsplanung,
%   \item Risikoabschätzung in Echtzeit,
%   \item Bewertung vergrabener Munitionsfunde.
% \end{itemize}

% Hybride Konzepte aus lernbasierten Surrogaten und probabilistischer Modellierung gelten als vielversprechender Ansatz für robuste und erklärbare AUV-Systeme unter Unsicherheit~\parencite{cui2020, yan2021}.

% \section{Model Predictive Control (MPC) unter Unsicherheit}

% Aktuelle Arbeiten zur Model Predictive Control (MPC) zeigen, dass klassische deterministische Modelle zunehmend durch \textbf{stochastische und robuste Varianten} ergänzt werden. Moderne Verfahren wie \emph{Stochastic MPC} und \emph{Robust MPC} integrieren probabilistische Prädiktionsintervalle zur Modellierung \emph{aleatorischer Unsicherheit}.

% Zunehmend wird jedoch auch \textbf{epistemische Unsicherheit} berücksichtigt, insbesondere bei datengetriebenen Modellen wie \textit{Deep Neural Networks} oder \textit{Gaussian Processes}, deren Generalisierungsfähigkeit außerhalb des Trainingsbereichs limitiert ist.

% Ansätze wie \textit{Bayesian MPC} oder \textit{Evidential MPC} versuchen, beide Unsicherheitsarten zu modellieren und in Optimierungsstrategien einzubetten – z.\,B.\ mittels:

% \begin{itemize}
%   \item adaptiver Kostenfunktionen,
%   \item probabilistischer Constraints,
%   \item Szenariostreuung zur Absicherung.
% \end{itemize}

% Beispielhafte Open-Source-Projekte:

% \begin{itemize}
%   \item \url{https://github.com/do-mpc/do-mpc}
%   \item \url{https://github.com/lucasrm25/Gaussian-Process-based-Model-Predictive-Control}
%   \item \url{https://github.com/TinyMPC/TinyMPC}
% \end{itemize}

% \section{Surrogatmodelle und Unsicherheitsdarstellung}

% % Surrogatmodelle dienen der effizienten Approximation komplexer physikalischer Systeme. Typische Verfahren umfassen~\parencite{sudret2017, tik2025}:

% \begin{itemize}
%   \item \textbf{Kriging / Gaussian Process Regression (GPR)}
%   \item \textbf{Polynomial Chaos Expansion (PCE)}
%   \item \textbf{Gradient-Enhanced Kriging (GEK)}
%   \item \textbf{Radiale Basisfunktionen (RBF)}
%   \item \textbf{Support Vector Machines (SVM)}
% \end{itemize}

% Im Projektkontext kommen insbesondere \textbf{Bayessche Neuronale Netze (BNNs)} und \textbf{Ensemble-Methoden} zur Anwendung.

% \section{Meta-Unsicherheit und Unsicherheitsbewertung}

% % Der aktuelle Stand der Technik zur \textbf{Meta-Unsicherheit} bezieht sich auf die \emph{übergeordnete Aggregation und Bewertung} verschiedener Unsicherheitsquellen in Surrogatmodellen. Während klassische Methoden aleatorische und epistemische Unsicherheiten getrennt modellieren, zielen neuere Ansätze auf deren gemeinsame Bewertung ab~\parencite{schmitt2022}.

% Methoden wie:

% \begin{itemize}
%   \item \textit{Uncertainty Meta-Learning},
%   \item \textit{Uncertainty Calibration Layers},
%   \item \textit{Evidential Frameworks},
% \end{itemize}

% \noindent
% ermöglichen die adaptive Gewichtung von Unsicherheiten je nach Szenariokontext und Modellkonfidenz. Ziel ist eine robuste, vergleichbare und erklärbare Modellbewertung für sicherheitskritische Anwendungen.

% \section{Sensitivitätsanalyse und Kalibrierung}

% % Die Sensitivitätsanalyse quantifiziert den Einfluss einzelner Eingangsgrößen auf Modellvorhersagen oder Unsicherheiten. Sie hilft, dominante Einflussfaktoren systematisch zu identifizieren~\parencite{borgonovo2017, tunkiel2020}. Dabei unterscheidet man:

% \begin{itemize}
%   \item \textbf{Invasive Methoden:} direkt im Modell integriert,
%   \item \textbf{Nicht-invasive Methoden:} modellunabhängige Blackbox-Analyse.
% \end{itemize}

% Die \textbf{Modellkalibrierung} dient dazu, Vorhersagen an die Realität (Ground Truth) anzupassen, etwa durch Parameterabgleich oder Szenariobasierung.

% \section{Zeitreihenanalyse}

% % Für die Analyse zeitabhängiger Sensordaten – wie sie bei AUVs typischerweise auftreten – kommen moderne Zeitreihenanalyse-Tools zum Einsatz. Ein Beispiel dafür ist das \textit{TSFEL Framework}~\parencite{tsfel2025}:

% \begin{itemize}
%   \item \url{https://github.com/fraunhoferportugal/tsfel}
% \end{itemize}

% \section{Zusammenfassung}

% Der Stand der Technik zeigt, dass zwar zahlreiche Methoden zur Unsicherheitsquantifizierung existieren, ein systematischer, modellagnostischer und \textbf{integrierter Ansatz zur Szenariobewertung} unter Berücksichtigung beider Unsicherheitsarten jedoch fehlt. Diese Arbeit zielt darauf ab einen methodischen Beitrag zur transparenten Bewertung maschineller Lernverfahren in sicherheitskritischen Anwendungen zu leisten.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Datensätze
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

~\nocite{BostonHousing2013}
~\nocite{CombinedCyclePowerPlant2014}
~\nocite{ConcreteCompressiveStrength1998}
~\nocite{ConditionBasedMaintenanceOfNavalPropulsionPlants2014}
~\nocite{EnergyEfficiency2012}
~\nocite{Fisher1936}
~\nocite{Cortez2009}
~\nocite{Gains2024}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Software 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

~\nocite{DuckDBDevelopers.2024}
~\nocite{EdlPytorchDevelopers.2024}
~\nocite{LoguruDevelopers.2024}
~\nocite{MatplotlibDevelopers.2024}
~\nocite{NotebookDevelopers.2024}
~\nocite{NumpyDevelopers.2024}
~\nocite{OpenpyxlDevelopers.2024}
~\nocite{PandasDevelopers.2024}
~\nocite{ProperscoringDevelopers.2024}
~\nocite{PyroPplDevelopers.2024}
~\nocite{PytestDevelopers.2024}
~\nocite{RuffDevelopers.2024}
~\nocite{ScikitLearnDevelopers.2024}
~\nocite{ScipyDevelopers.2024}
~\nocite{SeabornDevelopers.2024}
~\nocite{SphinxDevelopers.2024}
~\nocite{TensorflowDevelopers.2024}
~\nocite{TorchDevelopers.2024}
~\nocite{TorchmetricsDevelopers.2024}
~\nocite{TorchvisionDevelopers.2024}
~\nocite{XlrdDevelopers.2024}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Repos
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#

~\nocite{amini2020deep}
%~\nocite{amini2020deep}
~\nocite{sensoy2018evidential}
~\nocite{nmavani2025}
~\nocite{windler2025}

\end{otherlanguage}
