% !TeX root = ../main.tex

\chapter{Stand der Technik}
\label{chapter:stand-der-technik}

\begin{otherlanguage}{american}
%
%
%
\end{otherlanguage}


\begin{otherlanguage}{ngerman}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R1 Welche auf maschinellem Lernen basierenden Surrogatmodelle sind für die Quantifizierung von Unsicherheiten geeignet?

\begin{table}[!htpb]
  \centering
  \begin{tabular}{|l|p{\dimexpr\textwidth-3cm-2\tabcolsep}|}  
    \hline
    \textbf{\gls{surrogat}} & \textbf{Eignungsgrund} \\
    \hline
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item \gls{Gaußsche Prozessregression}
    \end{itemize} &  
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item Intrinsische probabilistische Ausgabe
      \item Exakte Varianzschätzung für kleine Datensätze
      \item Kernel-basierte Unsicherheitscharakterisierung
    \end{itemize} \\ 
    \hline
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item Deep Ensembles
    \end{itemize} & 
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item Redundante Modellierung reduziert Overconfidence
      \item Einfache Integration in existierende Architekturen
      \item Robust gegen Out-of-Distribution-Daten
    \end{itemize} \\
    \hline
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item Hybrid-Methoden
    \end{itemize} & 
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item Kombiniert Stärken von Blackbox-Modellen und GPR
      \item Nachrüstbar auf existierende Modelle
      \item Recheneffiziente Unsicherheitspropagation
    \end{itemize} \\
    \hline
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item \gls{Bayesianische neuronale Netze}s
    \end{itemize} & 
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item Systematische Integration von Priors
      \item Theoretisch fundierte Parameterunsicherheit
      \item Natürliche Regularisierung durch Bayes'sche Inferenz
    \end{itemize} \\
    \hline
  \end{tabular}
  \caption{R1 Vgl. v. Unsicherheitsquantifizierungsmethoden in ML}\label{tab:chapter6r1}
\end{table}


% Übersicht aus MC25 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R2 Welche allgemeinen und modellspezifischen Faktoren beeinflussen das Lernen von Unsicherheiten in ML-Modellen?

\newline
R2.1 Allgemeine Faktoren

\begin{table}[!htpb]
  \begin{tabular}{|l|p{10cm}|}
    \hline
    \textbf{Unsicherheitsdimensionen} & \textbf{Mögliche Werte} \\
    \hline
    Lokalisierung im System & Umgebung, Modellierung, Funktionen, Ziele, Verfügbare Ressourcen \\
    \hline
    Natur & Epistemisch, Aleatorisch \\
    \hline
    Grad der Unsicherheit & Keine Unsicherheit, Mangel an Wissen, Mangel an Bewusstsein, Mangel an Fähigkeit Bewusstsein zu erlangen \\
    \hline
    Entstehungszeit & Anforderungsdefinition, Entwicklungszeit, Laufzeit \\
    \hline
  \end{tabular}
  \caption{R2 Allg. Faktoren Klassifizierung Unsicherheit KI-Systeme nach A. Kreuz ~\nocite{AndreasKreutz2022} ~\nocite{AndreasKreutz2022b}}\label{tab:chapter6r21}
\end{table}

\newline
R2.2 Modellspezifische Faktoren

\begin{table}[!htpb]
  \centering
  \begin{tabular}{|l|p{\dimexpr\textwidth-5cm-2\tabcolsep}|}
    \hline
    \textbf{\gls{Bayesianische neuronale Netze}} & \textbf{Modellspezifische Faktoren} \\
    \hline
    Prior-Verteilungen & Wahl der Prioren beeinflusst die Unsicherheit und Vorhersagegenauigkeit. \\
    \hline
    Likelihood-Funktion & Bestimmt, wie Unsicherheit in den Beobachtungen modelliert wird (z.B. durch Gaussian). \\
    \hline
    Posterior Approximation & MCMC oder Variational Inference schätzt den Posterior und die Unsicherheit. \\
    \hline
    Regularisierung & Hilft, Overfitting zu vermeiden und Unsicherheit zu kontrollieren. \\
    \hline
    Bayesische Optimierung & Optimiert Hyperparameter unter Berücksichtigung der Unsicherheit. \\
    \hline
    Datenqualität & Schlechte Datenqualität erhöht Unsicherheit, gute Qualität verringert sie. \\
    \hline
    Maßstab & Der Maßstab des Modells beeinflusst die Unsicherheitsquantifizierung. \\
    \hline
  \end{tabular}
  \caption{R2.2 Modellspezifische Faktoren zur Unsicherheitsklassifizierung \gls{Bayesianische neuronale Netze}}\label{tab:chapter6r22}
\end{table}

\begin{table}[!htpb]
  \centering
  \begin{tabular}{|l|p{\dimexpr\textwidth-8cm-2\tabcolsep}|}
    \hline
    \textbf{\gls{Evidenzbasierte neuronale Netze}} & \textbf{Modellspezifische Faktoren} \\
    \hline
    Prior-Funktion & Beeinflusst, wie Unsicherheit über Daten und Parameter modelliert wird. \\
    \hline
    Evidenzfunktion & Modelliert Unsicherheit mit Evidenzparametern wie \( \alpha \), \( \beta \), und \( v \). \\
    \hline
    Posterior Approximation & Näherung der Posterior-Verteilung zur Unsicherheitsbestimmung. \\
    \hline
    Evidenz Optimierung & Optimierung der Evidenzparameter während des Trainings. \\
    \hline
    Evidenzbasierte Regularisierung & Regularisiert Evidenzparameter, um Overfitting zu vermeiden. \\
    \hline
    Multimodalität & Modelliert mehrere konkurrierende Unsicherheitsvorhersagen gleichzeitig. \\
    \hline
    Dateninhärente Unsicherheit & Unsicherheit, die direkt aus den Daten selbst resultiert. \\
    \hline
    Datenqualität & Schlechte Datenqualität erhöht die Unsicherheit im Modell. \\
    \hline
    Netzwerktiefe & Die Tiefe beeinflusst die Fähigkeit, Unsicherheit zu erfassen. \\
    \hline
  \end{tabular}
  \caption{R2.2 Modellspezifische Faktoren zur Unsicherheitsklassifizierung \gls{Evidenzbasierte neuronale Netze}}\label{tab:chapter6r23}
\end{table}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R3
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R3 Wie können diese Einflussfaktoren abgeschwächt werden, um die Unsicherheitsabschätzung zu verbessern?

\newline
Wie Allgemeine Faktoren abschwächen?

\begin{table}[!htpb]
  \centering
  \begin{tabular}{|l|l|p{\dimexpr\textwidth-8cm-2\tabcolsep}|}  % Adjusted width
    \hline
    & \textbf{X} & \textbf{Y} \\
    \hline
    A & & \\
    \hline
    B & & \\
    \hline
  \end{tabular}
  \caption{}\label{tab:chapter6r31}
\end{table}

\newline
Wie Modellspezifische Faktoren abschwächen?

\begin{table}[!htpb]
  \centering
  \begin{tabular}{|l|l|p{\dimexpr\textwidth-8cm-2\tabcolsep}|}  % Adjusted width
    \hline
    & \textbf{X} & \textbf{Y} \\
    \hline
    A & & \\
    \hline
    B & & \\
    \hline
  \end{tabular}
  \caption{}\label{tab:chapter6r32}
\end{table}

% ~\parencite{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R4
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R4 Inwieweit kann ML-basierte Unsicherheitsquantifizierung zuverlässig den in realen Anwendungsszenarien beobachteten Unsicherheiten entsprechen?

\newline
% UQ-Pred-UQ-Data-EQ-Ensure-Framework
Lanini et. al liefern ein Framework zur Bewertung von R4 ~\parencite{Lanini2024}. Ihre Recherche differenziert zur Beantwortung die Anwendungsdomäne, datenbasierte und modellbasierte Unsicherheitsmetriken.  

\newline
Manchingal et al. distanzieren sich von der Optimierung auf Anwendungsdomänen. Als Paradigmenwechsel beschreiben Sie epistemische Künstliche Intelligenz. Im Kern soll nicht nur auf Wissen in Form von Daten, sondern auch auf Nicht-Wissen trainiert werden. \parencite{manchingal2025}


% includegraphics


% Die spezifischen Aufgaben dieser Arbeit umfassen:

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R5
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% R5 Durchführung einer umfassenden Literaturübersicht über UQ-Techniken in der ML-basierten Surrogatmodellierung.


\parencite{Ulmer2023}

~\nocite{Gawlikowski2023}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R6
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R6 Identifizierung und Analyse geeigneter Unsicherheitsmetriken für Surrogatmodelle, wobei zwischen aleatorischer und epistemischer Unsicherheit unterschieden wird.

\begin{table}[htpb]
  \centering
  \begin{tabular}{|l|l|l|l|}  % Adjusted width
    \hline
    & \textbf{Datenbasierte Metriken} & \textbf{Modellbasierte Metriken} \\
    \hline
    AC & & \\
    \hline
    EC & & \\
    \hline
  \end{tabular}
  \caption{}\label{tab:chapter6r61}
\end{table}


% ~\parencite{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R7
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R7 Vergleich modellspezifischer und anwendungsspezifischer Bewertungsmetriken für die Quantifizierung von Unsicherheit.

% Beispiel-Anwendungsdomäne: Domäne. 

% Anwendungsspezifikation: 

\begin{table}[htpb]
  \centering
  \begin{tabular}{|l|l|l|l|}  % Adjusted width
    \hline
    & \textbf{Modellspezifische Metriken} & \textbf{Anwendungsspezifische Metriken} \\
    \hline
    AC & & \\
    \hline
    EC & & \\
    \hline
  \end{tabular}
  \caption{}\label{tab:chapter6r71}
\end{table}

% ~\parencite{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R8
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R8 Untersuchung und Vergleich verschiedener UQ-Ansätze für ML-basierte Surrogatmodelle, insbesondere Bayes'sche neuronale Netze und konforme Vorhersagen.

% Untersuchung:



% Vergleich

\begin{table}[htpb]
  \centering
  \begin{tabular}{|l|l|p{\dimexpr\textwidth-8cm-2\tabcolsep}|}  % Adjusted width
    \hline
    & \textbf{BNN} & \textbf{CFP} \\
    \hline
    AC & & \\
    \hline
    EC & & \\
    \hline
  \end{tabular}
  \caption{R8 Vergleich UQ-Ansätze ML-basierter \gls{surrogat}}\label{tab:chapter6r81}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R9
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R9 Untersuchung des theoretischen Einflusses verschiedener Faktoren auf die Unsicherheitsschätzungen ausgewählter Modelle.

% Untersuchung - Most Minimal Sensitivitäts-Analyse: 
% S1: Modelldefinition: 
% S2: Parameterbereich
% S3: Durchführung der Analyse

% Vergleich ausgewählter Modelle

\begin{table}[htpb]
  \centering
  \begin{tabular}{|l|l|p{\dimexpr\textwidth-8cm-2\tabcolsep}|}  % Adjusted width
    \hline
    & \textbf{BNN} & \textbf{Conformal Prediction} \\
    \hline
    A & & \\
    \hline
    B & & \\
    \hline
  \end{tabular}
  \caption{R8 Sensitivitätsanalyse UQ-Schätzungen}\label{tab:chapter6r91}
\end{table}

% S4: Auswertung

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R_base
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% % EDNN Grundlage 

% \parencite{oberkampf2010}
% ~\parencite{Choi2017}

% EDNN Regression 

% ~\parencite{AlexanderAmini2020}

% EDNN Ensemble 

% ~\parencite{Schreck2023}

% % Ninad

% % ~\parencite{Gopakumar2024}

% EDNN Entwicklung

% ~\parencite{Deng2023}



% benchmark
% K. GREENMAN, A. SOLEIMANY, K. YANG: Benchmarking Uncertainty Quantification For Protein Engineering. URL https://openreview.net/pdf?id=G0vuqNwxaeA. – Aktualisierungsdatum: 21.04.2022 – Überprüfungsdatum 14.04.2025 

% benchmark <-> proteindataset


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Archive.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \section{Autonome Unterwasserfahrzeuge (AUVs)}

% Der aktuelle Stand der Technik bei autonomen Unterwasserfahrzeugen (AUVs) zeigt einen zunehmenden Einsatz von \textbf{machine-learning-basierten Surrogatmodellen}, etwa zur Umgebungsmodellierung, Pfadplanung oder Systemdiagnose. 

% In komplexen maritimen Umgebungen sind AUVs typischerweise mit \emph{aleatorischer Unsicherheit} konfrontiert – beispielsweise durch verrauschte Sensordaten, Strömungseinflüsse oder schwankende Sichtverhältnisse. Surrogatmodelle wie \textit{Gaussian Processes}, \textit{Bayesian Neural Networks} oder \textit{Evidential Deep Learning} ermöglichen nicht nur schnelle Approximationen physikalischer Modelle, sondern auch die quantitative Erfassung \emph{epistemischer Unsicherheit} in bislang unkartierten Regionen.

% Moderne Entscheidungsverfahren berücksichtigen zunehmend unsicherheitsbewusste Vorhersagen, z.\,B.\ bei:

% \begin{itemize}
%   \item adaptiver Missionsplanung,
%   \item Risikoabschätzung in Echtzeit,
%   \item Bewertung vergrabener Munitionsfunde.
% \end{itemize}

% Hybride Konzepte aus lernbasierten Surrogaten und probabilistischer Modellierung gelten als vielversprechender Ansatz für robuste und erklärbare AUV-Systeme unter Unsicherheit~\parencite{cui2020, yan2021}.

% \section{Model Predictive Control (MPC) unter Unsicherheit}

% Aktuelle Arbeiten zur Model Predictive Control (MPC) zeigen, dass klassische deterministische Modelle zunehmend durch \textbf{stochastische und robuste Varianten} ergänzt werden. Moderne Verfahren wie \emph{Stochastic MPC} und \emph{Robust MPC} integrieren probabilistische Prädiktionsintervalle zur Modellierung \emph{aleatorischer Unsicherheit}.

% Zunehmend wird jedoch auch \textbf{epistemische Unsicherheit} berücksichtigt, insbesondere bei datengetriebenen Modellen wie \textit{Deep Neural Networks} oder \textit{Gaussian Processes}, deren Generalisierungsfähigkeit außerhalb des Trainingsbereichs limitiert ist.

% Ansätze wie \textit{Bayesian MPC} oder \textit{Evidential MPC} versuchen, beide Unsicherheitsarten zu modellieren und in Optimierungsstrategien einzubetten – z.\,B.\ mittels:

% \begin{itemize}
%   \item adaptiver Kostenfunktionen,
%   \item probabilistischer Constraints,
%   \item Szenariostreuung zur Absicherung.
% \end{itemize}

% Beispielhafte Open-Source-Projekte:

% \begin{itemize}
%   \item \url{https://github.com/do-mpc/do-mpc}
%   \item \url{https://github.com/lucasrm25/Gaussian-Process-based-Model-Predictive-Control}
%   \item \url{https://github.com/TinyMPC/TinyMPC}
% \end{itemize}

% \section{Surrogatmodelle und Unsicherheitsdarstellung}

% % Surrogatmodelle dienen der effizienten Approximation komplexer physikalischer Systeme. Typische Verfahren umfassen~\parencite{sudret2017, tik2025}:

% \begin{itemize}
%   \item \textbf{Kriging / Gaussian Process Regression (GPR)}
%   \item \textbf{Polynomial Chaos Expansion (PCE)}
%   \item \textbf{Gradient-Enhanced Kriging (GEK)}
%   \item \textbf{Radiale Basisfunktionen (RBF)}
%   \item \textbf{Support Vector Machines (SVM)}
% \end{itemize}

% Im Projektkontext kommen insbesondere \textbf{Bayessche Neuronale Netze (BNNs)} und \textbf{Ensemble-Methoden} zur Anwendung.

% \section{Meta-Unsicherheit und Unsicherheitsbewertung}

% % Der aktuelle Stand der Technik zur \textbf{Meta-Unsicherheit} bezieht sich auf die \emph{übergeordnete Aggregation und Bewertung} verschiedener Unsicherheitsquellen in Surrogatmodellen. Während klassische Methoden aleatorische und epistemische Unsicherheiten getrennt modellieren, zielen neuere Ansätze auf deren gemeinsame Bewertung ab~\parencite{schmitt2022}.

% Methoden wie:

% \begin{itemize}
%   \item \textit{Uncertainty Meta-Learning},
%   \item \textit{Uncertainty Calibration Layers},
%   \item \textit{Evidential Frameworks},
% \end{itemize}

% \noindent
% ermöglichen die adaptive Gewichtung von Unsicherheiten je nach Szenariokontext und Modellkonfidenz. Ziel ist eine robuste, vergleichbare und erklärbare Modellbewertung für sicherheitskritische Anwendungen.

% \section{Sensitivitätsanalyse und Kalibrierung}

% % Die Sensitivitätsanalyse quantifiziert den Einfluss einzelner Eingangsgrößen auf Modellvorhersagen oder Unsicherheiten. Sie hilft, dominante Einflussfaktoren systematisch zu identifizieren~\parencite{borgonovo2017, tunkiel2020}. Dabei unterscheidet man:

% \begin{itemize}
%   \item \textbf{Invasive Methoden:} direkt im Modell integriert,
%   \item \textbf{Nicht-invasive Methoden:} modellunabhängige Blackbox-Analyse.
% \end{itemize}

% Die \textbf{Modellkalibrierung} dient dazu, Vorhersagen an die Realität (Ground Truth) anzupassen, etwa durch Parameterabgleich oder Szenariobasierung.

% \section{Zeitreihenanalyse}

% % Für die Analyse zeitabhängiger Sensordaten – wie sie bei AUVs typischerweise auftreten – kommen moderne Zeitreihenanalyse-Tools zum Einsatz. Ein Beispiel dafür ist das \textit{TSFEL Framework}~\parencite{tsfel2025}:

% \begin{itemize}
%   \item \url{https://github.com/fraunhoferportugal/tsfel}
% \end{itemize}

% \section{Zusammenfassung}

% Der Stand der Technik zeigt, dass zwar zahlreiche Methoden zur Unsicherheitsquantifizierung existieren, ein systematischer, modellagnostischer und \textbf{integrierter Ansatz zur Szenariobewertung} unter Berücksichtigung beider Unsicherheitsarten jedoch fehlt. Diese Arbeit zielt darauf ab einen methodischen Beitrag zur transparenten Bewertung maschineller Lernverfahren in sicherheitskritischen Anwendungen zu leisten.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Datensätze
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

~\nocite{BostonHousing2013}
~\nocite{CombinedCyclePowerPlant2014}
~\nocite{ConcreteCompressiveStrength1998}
~\nocite{ConditionBasedMaintenanceOfNavalPropulsionPlants2014}
~\nocite{EnergyEfficiency2012}
~\nocite{Fisher1936}
~\nocite{Cortez2009}
~\nocite{Gains2024}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Software 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

~\nocite{DuckDBDevelopers.2024}
~\nocite{EdlPytorchDevelopers.2024}
~\nocite{LoguruDevelopers.2024}
~\nocite{MatplotlibDevelopers.2024}
~\nocite{NotebookDevelopers.2024}
~\nocite{NumpyDevelopers.2024}
~\nocite{OpenpyxlDevelopers.2024}
~\nocite{PandasDevelopers.2024}
~\nocite{ProperscoringDevelopers.2024}
~\nocite{PyroPplDevelopers.2024}
~\nocite{PytestDevelopers.2024}
~\nocite{RuffDevelopers.2024}
~\nocite{ScikitLearnDevelopers.2024}
~\nocite{ScipyDevelopers.2024}
~\nocite{SeabornDevelopers.2024}
~\nocite{SphinxDevelopers.2024}
~\nocite{TensorflowDevelopers.2024}
~\nocite{TorchDevelopers.2024}
~\nocite{TorchmetricsDevelopers.2024}
~\nocite{TorchvisionDevelopers.2024}
~\nocite{XlrdDevelopers.2024}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Repos
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#

~\nocite{amini2020deep}
~\nocite{sensoy2018evidential}
~\nocite{nmavani2025}
~\nocite{windler2025}

\end{otherlanguage}
