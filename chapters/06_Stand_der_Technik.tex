% !TeX root = ../main.tex

\chapter{Stand der Technik}
\label{chapter:stand-der-technik}

\begin{otherlanguage}{american}
%
%
%
\end{otherlanguage}


\begin{otherlanguage}{ngerman}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R1 Welche auf maschinellem Lernen basierenden Surrogatmodelle sind für die Quantifizierung von Unsicherheiten geeignet?

\begin{table}[!htpb]
  \centering
  \begin{tabularx}{\textwidth}{|l|X|}
    \hline
    \textbf{\gls{surrogat}} & \textbf{Eignungsgrund} \\
    \hline
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item \gls{Gaußsche Prozessregression}
    \end{itemize} &  
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item Intrinsische probabilistische Ausgabe
      \item Exakte Varianzschätzung für kleine Datensätze
      \item Kernel-basierte Unsicherheitscharakterisierung
    \end{itemize} \\ 
    \hline
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item Deep Ensembles
    \end{itemize} & 
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item Redundante Modellierung reduziert Overconfidence
      \item Einfache Integration in existierende Architekturen
      \item Robust gegen Out-of-Distribution-Daten
    \end{itemize} \\
    \hline
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item Hybrid-Methoden
    \end{itemize} & 
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item Kombiniert Stärken von Blackbox-Modellen und GPR
      \item Nachrüstbar auf existierende Modelle
      \item Recheneffiziente Unsicherheitspropagation
    \end{itemize} \\
    \hline
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item \gls{Bayesianische neuronale Netze}s
    \end{itemize} & 
    \begin{itemize}[topsep=0em, itemsep=0em, left=0em, labelsep=0.25em]
      \item Systematische Integration von Priors
      \item Theoretisch fundierte Parameterunsicherheit
      \item Natürliche Regularisierung durch Bayes'sche Inferenz
    \end{itemize} \\
    \hline
  \end{tabularx}
  \caption{R1 Vgl. v. Unsicherheitsquantifizierungsmethoden in ML}\label{tab:chapter6r1}
\end{table}


% Übersicht aus MC25 

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R2 Welche allgemeinen und modellspezifischen Faktoren beeinflussen das Lernen von Unsicherheiten in ML-Modellen?

\newline
R2.1 Allgemeine Faktoren

\begin{table}[!htpb]
  \begin{tabularx}{\textwidth}{|l|X|}
    \hline
    \textbf{Unsicherheitsdimensionen} & \textbf{Mögliche Werte} \\
    \hline
    Lokalisierung im System & Umgebung, Modellierung, Funktionen, Ziele, Verfügbare Ressourcen \\
    \hline
    Natur & Epistemisch, Aleatorisch \\
    \hline
    Grad der Unsicherheit & Keine Unsicherheit, Mangel an Wissen, Mangel an Bewusstsein, Mangel an Fähigkeit Bewusstsein zu erlangen \\
    \hline
    Entstehungszeit & Anforderungsdefinition, Entwicklungszeit, Laufzeit \\
    \hline
  \end{tabularx}
  \caption{R2 Allg. Faktoren Klassifizierung Unsicherheit KI-Systeme nach A. Kreuz ~\nocite{AndreasKreutz2022} ~\nocite{AndreasKreutz2022b}}\label{tab:chapter6r21}
\end{table}

\newline
R2.2 Modellspezifische Faktoren

\begin{table}[!htpb]
  \centering
  \begin{tabularx}{\textwidth}{|l|X|}
    \hline
    \textbf{\gls{Bayesianische neuronale Netze}} & \textbf{Modellspezifische Faktoren} \\
    \hline
    Prior-Verteilungen & Wahl der Prioren beeinflusst die Unsicherheit und Vorhersagegenauigkeit. \\
    \hline
    Likelihood-Funktion & Bestimmt, wie Unsicherheit in den Beobachtungen modelliert wird (z.B. durch Gaussian). \\
    \hline
    Posterior Approximation & MCMC oder Variational Inference schätzt den Posterior und die Unsicherheit. \\
    \hline
    Regularisierung & Hilft, Overfitting zu vermeiden und Unsicherheit zu kontrollieren. \\
    \hline
    Bayesische Optimierung & Optimiert Hyperparameter unter Berücksichtigung der Unsicherheit. \\
    \hline
    Datenqualität & Schlechte Datenqualität erhöht Unsicherheit, gute Qualität verringert sie. \\
    \hline
    Maßstab & Der Maßstab des Modells beeinflusst die Unsicherheitsquantifizierung. \\
    \hline
  \end{tabularx}
  \caption{R2.2 Modellspezifische Faktoren zur Unsicherheitsklassifizierung \gls{Bayesianische neuronale Netze}}\label{tab:chapter6r22}
\end{table}

\begin{table}[!htpb]
  \centering
  \begin{tabularx}{\textwidth}{|l|X|}
    \hline
    \textbf{\gls{Evidenzbasierte neuronale Netze}} & \textbf{Modellspezifische Faktoren} \\
    \hline
    Prior-Funktion & Beeinflusst, wie Unsicherheit über Daten und Parameter modelliert wird. \\
    \hline
    Evidenzfunktion & Modelliert Unsicherheit mit Evidenzparametern wie \( \alpha \), \( \beta \), und \( v \). \\
    \hline
    Posterior Approximation & Näherung der Posterior-Verteilung zur Unsicherheitsbestimmung. \\
    \hline
    Evidenz Optimierung & Optimierung der Evidenzparameter während des Trainings. \\
    \hline
    Evidenzbasierte Regularisierung & Regularisiert Evidenzparameter, um Overfitting zu vermeiden. \\
    \hline
    Multimodalität & Modelliert mehrere konkurrierende Unsicherheitsvorhersagen gleichzeitig. \\
    \hline
    Dateninhärente Unsicherheit & Unsicherheit, die direkt aus den Daten selbst resultiert. \\
    \hline
    Datenqualität & Schlechte Datenqualität erhöht die Unsicherheit im Modell. \\
    \hline
    Netzwerktiefe & Die Tiefe beeinflusst die Fähigkeit, Unsicherheit zu erfassen. \\
    \hline
  \end{tabularx}
  \caption{R2.2 Modellspezifische Faktoren zur Unsicherheitsklassifizierung \gls{Evidenzbasierte neuronale Netze}}\label{tab:chapter6r23}
\end{table}

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R3
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R3 Wie können diese Einflussfaktoren abgeschwächt werden, um die Unsicherheitsabschätzung zu verbessern?

\newline
Wie Allgemeine Faktoren abschwächen?

\begin{table}[!htpb]
  \centering
  \begin{tabularx}{\textwidth}{|l|X|}
    \hline
    \textbf{Unsicherheitsdimensionen} & \textbf{Mögliche Abschwächung} \\
    \hline
    Lokalisierung im System & Verbesserung der Modellgenauigkeit und der Ressourcennutzung durch gezielte Datensammlung und Modellanpassung. \\
    \hline
    Natur & Einsatz von Hybriden Modellen, die sowohl epistemische als auch aleatorische Unsicherheit modellieren können. \\
    \hline
    Grad der Unsicherheit & Erhöhung des Modellspezifikationsgrades, z. B. durch Mehrfachmodellierung und Unsicherheitsquantifizierung. \\
    \hline
    Entstehungszeit & Frühzeitige Einbindung von Unsicherheitsmodellierung in die Anforderungsdefinition und Entwicklungszeit. \\
    \hline
  \end{tabularx}
  \caption{R3 Abschwächung allgemeiner Faktoren KI Systeme}\label{tab:chapter6r31}
\end{table}

\newline
Wie Modellspezifische Faktoren abschwächen?

\begin{table}[!htpb]
  \centering
  \begin{tabularx}{\textwidth}{|l|X|}
    \hline
    \textbf{Modellspezifische Faktoren} & \textbf{Abschwächung der Unsicherheitsabschätzung} \\
    \hline
    Prior-Verteilungen & Auswahl robusterer Priors und der Anpassung der Priors an die Daten zur Vermeidung von zu starker Unsicherheit. \\
    \hline
    Likelihood-Funktion & Optimierung der Likelihood-Modelle, z. B. durch mehrdimensionale Likelihoods für die Unsicherheit. \\
    \hline
    Posterior Approximation & Verwendung effizienter Approximationstechniken wie Variational Inference zur besseren Unsicherheitsabschätzung. \\
    \hline
    Regularisierung & Anwendung von stärkeren Regularisierungstechniken, um Overfitting zu vermeiden und die Unsicherheit gezielt zu verringern. \\
    \hline
    Bayesische Optimierung & Optimierung von Hyperparametern unter Unsicherheit zur gezielten Reduzierung der Unsicherheit im Modell. \\
    \hline
    Datenqualität & Verbesserung der Datenqualität durch Datenbereinigung und Zusammenstellung von Trainingsdatensätzen, die die Unsicherheit reduzieren. \\
    \hline
    Maßstab & Verwendung von Skalenmodellen zur Reduzierung von Unsicherheit durch Skalierung des Modells auf größere Datenmengen. \\
    \hline
  \end{tabularx}
  \caption{R3.1 Abschwächung Modellspezifische Faktoren zur Unsicherheitsklassifizierung \gls{Bayesianische neuronale Netze}}\label{tab:chapter6r32}
\end{table}

\begin{table}[!htpb]
  \centering
  \begin{tabularx}{\textwidth}{|l|X|}
    \hline
    \textbf{Modellspezifische Faktoren} & \textbf{Abschwächung der Unsicherheitsabschätzung} \\
    \hline
    Prior-Funktion & Verwendung von flexiblen Prior-Funktionen, die auf den spezifischen Unsicherheitsgrad der Daten abgestimmt sind. \\
    \hline
    Evidenzfunktion & Verbesserung der Evidenzparameter, z. B. durch den Einsatz von multimodalen Evidenzfunktionen, um Unsicherheit besser zu modellieren. \\
    \hline
    Posterior Approximation & Anwendung von genauen MCMC-Methoden oder besseren Näherungsverfahren zur genaueren Posterior-Bestimmung. \\
    \hline
    Evidenz Optimierung & Evidenzparameter optimieren, um unsichere Parameterbereiche zu vermeiden und so Unsicherheit zu reduzieren. \\
    \hline
    Evidenzbasierte Regularisierung & Stärkere Regularisierung der Evidenzparameter zur Vermeidung von zu großer Unsicherheit bei der Modellierung. \\
    \hline
    Multimodalität & Integration von multimodalen Unsicherheitsmodellen, um verschiedene Unsicherheitsquellen gleichzeitig zu verarbeiten. \\
    \hline
    Dateninhärente Unsicherheit & Reduktion der Datenrauschen und Verbesserung der Datenvorverarbeitung, um die Datenunsicherheit zu minimieren. \\
    \hline
    Datenqualität & Optimierung der Datenqualität durch Verwendung besserer Datensätze und Datenaugmentation. \\
    \hline
    Netzwerktiefe & Optimierung der Netzwerktiefe unter Berücksichtigung der Modellkomplexität, um unnötige Unsicherheiten zu vermeiden. \\
    \hline
  \end{tabularx}
  \caption{R3.2 Abschwächung Modellspezifische Faktoren zur Unsicherheitsklassifizierung \gls{Evidenzbasierte neuronale Netze}}\label{tab:chapter6r33}
\end{table}

% ~\parencite{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R4
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R4 Inwieweit kann ML-basierte Unsicherheitsquantifizierung zuverlässig den in realen Anwendungsszenarien beobachteten Unsicherheiten entsprechen?
\\
\\
% UQ-Pred-UQ-Data-EQ-Ensure-Framework
Lanini et. al liefern ein Framework zur Bewertung von R4 ~\parencite{Lanini2024} zur Optimierung in einer Anwendungsdomäne. Ihre Recherche differenziert zur Beantwortung weiterhin datenbasierte und modellbasierte Unsicherheitsmetriken. 
\\
\\
Manchingal et al. distanzieren sich von der Optimierung auf Anwendungsdomänen. Als Paradigmenwechsel beschreiben Sie epistemische Künstliche Intelligenz. Im Kern soll nicht nur auf Wissen in Form von Daten, sondern auch auf Nicht-Wissen trainiert werden. \parencite{manchingal2025}

\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{../figures/x3.png}
  \caption{R4.1}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{../figures/x2.png}
  \caption{R4.2}
\end{figure}

% Die spezifischen Aufgaben dieser Arbeit umfassen:

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R5
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R5 Durchführung einer umfassenden Literaturübersicht über UQ-Techniken in der ML-basierten Surrogatmodellierung.

\parencite{Ulmer2023}

~\nocite{Gawlikowski2023}

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R6
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R6 Identifizierung und Analyse geeigneter Unsicherheitsmetriken für Surrogatmodelle, wobei zwischen aleatorischer und epistemischer Unsicherheit unterschieden wird.

\begin{table}[htpb]
  \centering
  \begin{tabularx}{\textwidth}{|l|l|X|}
    \hline
    & \textbf{Datenbasierte Metriken} & \textbf{Modellbasierte Metriken} \\
    \hline
    \textbf{AC} & 
    \begin{tabular}[c]{@{}l@{}} 
      \( \sigma = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2} \) \\ 
      Standardabweichung (Rauschen) \\[1ex]
      \( \text{Var} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 \) \\ 
      Varianz der Residuen
    \end{tabular}
    & 
    \begin{tabular}[c]{@{}l@{}} 
      \( p(\theta \mid \mathcal{D}) \) \\ 
      Bayesianische Unsicherheit (Posterior) \\[1ex]
      Kreuzvalidierung (Training/Testdaten)
    \end{tabular} \\
    \hline
    \textbf{EC} & 
    \begin{tabular}[c]{@{}l@{}} 
      \( \text{Fehler} = \sum_{i=1}^{n} |y_i - \hat{y}_i| \) \\ 
      Fehleranalyse auf Testdaten
    \end{tabular}
    & 
    \begin{tabular}[c]{@{}l@{}} 
      \( \hat{y} \pm z \cdot \sigma \) \\ 
      Konfidenzintervall \\[1ex]
      \( H(p) = - \sum_{i} p(x_i) \log(p(x_i)) \) \\ 
      Entropie der Posterior-Verteilung
    \end{tabular} \\
    \hline
  \end{tabularx}
  \caption{R6 Unsicherheitsmetriken für Surrogatmodelle}\label{tab:chapter6r61}
\end{table}

% ~\parencite{}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R7
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

R7 Vergleich modellspezifischer und anwendungsspezifischer Bewertungsmetriken für die Quantifizierung von Unsicherheit.

% Beispiel-Anwendungsdomäne: [Beispiel-Domäne]

% Anwendungsspezifikation:

\begin{table}[!htpb]
  \centering
  \resizebox{\textwidth}{!}{
    \begin{tabularx}{\textwidth}{|l|l|X|}
      \hline
        & \textbf{Modellspezifische Metriken} & \textbf{Anwendungsspezifische Metriken} \\
      \hline
      \textbf{AC} & 
      \begin{tabular}[c]{@{}l@{}} 
        \( \text{RMSE} \) \\ 
        \( \text{MAE} \) \\ 
        \( \text{KL}(P \parallel Q) \)
      \end{tabular}
      & 
      \begin{tabular}[c]{@{}l@{}} 
        \( \text{Accuracy} \) \\ 
        \( F_1 \) \\ 
        \( \text{AUC} \)
      \end{tabular} \\
      \hline
      \textbf{EC} & 
      \begin{tabular}[c]{@{}l@{}} 
        \( \mathcal{L}(\theta) \) \\ 
        \( \text{BMA} \) \\ 
        \( \text{CI} \)
      \end{tabular}
      & 
      \begin{tabular}[c]{@{}l@{}} 
        \( \text{Fehler} \) \\ 
        \( H(p) \) \\ 
        \( \text{AUC-PR} \)
      \end{tabular} \\
      \hline
    \end{tabularx}
  }
  \caption{Vergleich der modellspezifischen und anwendungsspezifischen Unsicherheitsmetriken für Surrogatmodelle}\label{tab:chapter6r71}
\end{table}

\pagebreak

% ~\parencite{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R8
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R8 Untersuchung und Vergleich verschiedener UQ-Ansätze für ML-basierte Surrogatmodelle, insbesondere Bayes'sche neuronale Netze und konforme Vorhersagen.

% Untersuchung:

% Vergleich

\begin{table}[htpb]
  \centering
  \begin{tabularx}{\textwidth}{|l|l|X|}
    \hline
    & \textbf{BNN} & \textbf{CFP} \\
    \hline
    AC & & \\
    \hline
    EC & & \\
    \hline
  \end{tabularx}
  \caption{R8 Vergleich UQ-Ansätze ML-basierter \gls{surrogat}}\label{tab:chapter6r81}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R9
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

R9 Untersuchung des theoretischen Einflusses verschiedener Faktoren auf die Unsicherheitsschätzungen ausgewählter Modelle.

% Untersuchung - Most Minimal Sensitivitäts-Analyse: 
% S1: Modelldefinition: 
% S2: Parameterbereich
% S3: Durchführung der Analyse

% Vergleich ausgewählter Modelle

\begin{table}[htpb]
  \centering
  \begin{tabularx}{\textwidth}{|l|l|X|}
    \hline
    & \textbf{BNN} & \textbf{Conformal Prediction} \\
    \hline
    A & & \\
    \hline
    B & & \\
    \hline
  \end{tabularx}
  \caption{R8 Sensitivitätsanalyse UQ-Schätzungen}\label{tab:chapter6r91}
\end{table}

% S4: Auswertung

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R_base
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% % EDNN Grundlage 

% \parencite{oberkampf2010}
% ~\parencite{Choi2017}

% EDNN Regression 

% ~\parencite{AlexanderAmini2020}

% EDNN Ensemble 

% ~\parencite{Schreck2023}

% % Ninad

% % ~\parencite{Gopakumar2024}

% EDNN Entwicklung

% ~\parencite{Deng2023}



% benchmark
% K. GREENMAN, A. SOLEIMANY, K. YANG: Benchmarking Uncertainty Quantification For Protein Engineering. URL https://openreview.net/pdf?id=G0vuqNwxaeA. – Aktualisierungsdatum: 21.04.2022 – Überprüfungsdatum 14.04.2025 

% benchmark <-> proteindataset


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Archive.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \section{Autonome Unterwasserfahrzeuge (AUVs)}

% Der aktuelle Stand der Technik bei autonomen Unterwasserfahrzeugen (AUVs) zeigt einen zunehmenden Einsatz von \textbf{machine-learning-basierten Surrogatmodellen}, etwa zur Umgebungsmodellierung, Pfadplanung oder Systemdiagnose. 

% In komplexen maritimen Umgebungen sind AUVs typischerweise mit \emph{aleatorischer Unsicherheit} konfrontiert – beispielsweise durch verrauschte Sensordaten, Strömungseinflüsse oder schwankende Sichtverhältnisse. Surrogatmodelle wie \textit{Gaussian Processes}, \textit{Bayesian Neural Networks} oder \textit{Evidential Deep Learning} ermöglichen nicht nur schnelle Approximationen physikalischer Modelle, sondern auch die quantitative Erfassung \emph{epistemischer Unsicherheit} in bislang unkartierten Regionen.

% Moderne Entscheidungsverfahren berücksichtigen zunehmend unsicherheitsbewusste Vorhersagen, z.\,B.\ bei:

% \begin{itemize}
%   \item adaptiver Missionsplanung,
%   \item Risikoabschätzung in Echtzeit,
%   \item Bewertung vergrabener Munitionsfunde.
% \end{itemize}

% Hybride Konzepte aus lernbasierten Surrogaten und probabilistischer Modellierung gelten als vielversprechender Ansatz für robuste und erklärbare AUV-Systeme unter Unsicherheit~\parencite{cui2020, yan2021}.

% \section{Model Predictive Control (MPC) unter Unsicherheit}

% Aktuelle Arbeiten zur Model Predictive Control (MPC) zeigen, dass klassische deterministische Modelle zunehmend durch \textbf{stochastische und robuste Varianten} ergänzt werden. Moderne Verfahren wie \emph{Stochastic MPC} und \emph{Robust MPC} integrieren probabilistische Prädiktionsintervalle zur Modellierung \emph{aleatorischer Unsicherheit}.

% Zunehmend wird jedoch auch \textbf{epistemische Unsicherheit} berücksichtigt, insbesondere bei datengetriebenen Modellen wie \textit{Deep Neural Networks} oder \textit{Gaussian Processes}, deren Generalisierungsfähigkeit außerhalb des Trainingsbereichs limitiert ist.

% Ansätze wie \textit{Bayesian MPC} oder \textit{Evidential MPC} versuchen, beide Unsicherheitsarten zu modellieren und in Optimierungsstrategien einzubetten – z.\,B.\ mittels:

% \begin{itemize}
%   \item adaptiver Kostenfunktionen,
%   \item probabilistischer Constraints,
%   \item Szenariostreuung zur Absicherung.
% \end{itemize}

% Beispielhafte Open-Source-Projekte:

% \begin{itemize}
%   \item \url{https://github.com/do-mpc/do-mpc}
%   \item \url{https://github.com/lucasrm25/Gaussian-Process-based-Model-Predictive-Control}
%   \item \url{https://github.com/TinyMPC/TinyMPC}
% \end{itemize}

% \section{Surrogatmodelle und Unsicherheitsdarstellung}

% % Surrogatmodelle dienen der effizienten Approximation komplexer physikalischer Systeme. Typische Verfahren umfassen~\parencite{sudret2017, tik2025}:

% \begin{itemize}
%   \item \textbf{Kriging / Gaussian Process Regression (GPR)}
%   \item \textbf{Polynomial Chaos Expansion (PCE)}
%   \item \textbf{Gradient-Enhanced Kriging (GEK)}
%   \item \textbf{Radiale Basisfunktionen (RBF)}
%   \item \textbf{Support Vector Machines (SVM)}
% \end{itemize}

% Im Projektkontext kommen insbesondere \textbf{Bayessche Neuronale Netze (BNNs)} und \textbf{Ensemble-Methoden} zur Anwendung.

% \section{Meta-Unsicherheit und Unsicherheitsbewertung}

% % Der aktuelle Stand der Technik zur \textbf{Meta-Unsicherheit} bezieht sich auf die \emph{übergeordnete Aggregation und Bewertung} verschiedener Unsicherheitsquellen in Surrogatmodellen. Während klassische Methoden aleatorische und epistemische Unsicherheiten getrennt modellieren, zielen neuere Ansätze auf deren gemeinsame Bewertung ab~\parencite{schmitt2022}.

% Methoden wie:

% \begin{itemize}
%   \item \textit{Uncertainty Meta-Learning},
%   \item \textit{Uncertainty Calibration Layers},
%   \item \textit{Evidential Frameworks},
% \end{itemize}

% \noindent
% ermöglichen die adaptive Gewichtung von Unsicherheiten je nach Szenariokontext und Modellkonfidenz. Ziel ist eine robuste, vergleichbare und erklärbare Modellbewertung für sicherheitskritische Anwendungen.

% \section{Sensitivitätsanalyse und Kalibrierung}

% % Die Sensitivitätsanalyse quantifiziert den Einfluss einzelner Eingangsgrößen auf Modellvorhersagen oder Unsicherheiten. Sie hilft, dominante Einflussfaktoren systematisch zu identifizieren~\parencite{borgonovo2017, tunkiel2020}. Dabei unterscheidet man:

% \begin{itemize}
%   \item \textbf{Invasive Methoden:} direkt im Modell integriert,
%   \item \textbf{Nicht-invasive Methoden:} modellunabhängige Blackbox-Analyse.
% \end{itemize}

% Die \textbf{Modellkalibrierung} dient dazu, Vorhersagen an die Realität (Ground Truth) anzupassen, etwa durch Parameterabgleich oder Szenariobasierung.

% \section{Zeitreihenanalyse}

% % Für die Analyse zeitabhängiger Sensordaten – wie sie bei AUVs typischerweise auftreten – kommen moderne Zeitreihenanalyse-Tools zum Einsatz. Ein Beispiel dafür ist das \textit{TSFEL Framework}~\parencite{tsfel2025}:

% \begin{itemize}
%   \item \url{https://github.com/fraunhoferportugal/tsfel}
% \end{itemize}

% \section{Zusammenfassung}

% Der Stand der Technik zeigt, dass zwar zahlreiche Methoden zur Unsicherheitsquantifizierung existieren, ein systematischer, modellagnostischer und \textbf{integrierter Ansatz zur Szenariobewertung} unter Berücksichtigung beider Unsicherheitsarten jedoch fehlt. Diese Arbeit zielt darauf ab einen methodischen Beitrag zur transparenten Bewertung maschineller Lernverfahren in sicherheitskritischen Anwendungen zu leisten.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Datensätze
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

~\nocite{BostonHousing2013}
~\nocite{CombinedCyclePowerPlant2014}
~\nocite{ConcreteCompressiveStrength1998}
~\nocite{ConditionBasedMaintenanceOfNavalPropulsionPlants2014}
~\nocite{EnergyEfficiency2012}
~\nocite{Fisher1936}
~\nocite{Cortez2009}
~\nocite{Gains2024}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Software 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

~\nocite{DuckDBDevelopers.2024}
~\nocite{EdlPytorchDevelopers.2024}
~\nocite{LoguruDevelopers.2024}
~\nocite{MatplotlibDevelopers.2024}
~\nocite{NotebookDevelopers.2024}
~\nocite{NumpyDevelopers.2024}
~\nocite{OpenpyxlDevelopers.2024}
~\nocite{PandasDevelopers.2024}
~\nocite{ProperscoringDevelopers.2024}
~\nocite{PyroPplDevelopers.2024}
~\nocite{PytestDevelopers.2024}
~\nocite{RuffDevelopers.2024}
~\nocite{ScikitLearnDevelopers.2024}
~\nocite{ScipyDevelopers.2024}
~\nocite{SeabornDevelopers.2024}
~\nocite{SphinxDevelopers.2024}
~\nocite{TensorflowDevelopers.2024}
~\nocite{TorchDevelopers.2024}
~\nocite{TorchmetricsDevelopers.2024}
~\nocite{TorchvisionDevelopers.2024}
~\nocite{XlrdDevelopers.2024}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Repos
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#

~\nocite{amini2020deep}
~\nocite{sensoy2018evidential}
~\nocite{nmavani2025}
~\nocite{windler2025}

\end{otherlanguage}
