@article{cui2020,
  author = {Weicheng Cui and Shixiao Fu and Zhiqiang Hu},
  title = {Autonomous Underwater Vehicles with Uncertainty-Aware ML},
  journal = {Ocean Engineering},
  year = {2020}
}

@article{yan2021,
  author = {Jing Yan and Xian Yang and Haiyan Zhao and Xiaoyuan Luo and Xinping Guan},
  title = {Deep Learning for Underwater Robotics},
  journal = {IEEE Trans. on Robotics},
  year = {2021}
}

@article{schmitt2022,
  author = {Schmitt, Radev, Bürkner},
  title = {Meta-Unsicherheit im Bayes'schen Modellvergleich},
  year = {2022},
  note = {Vortrag, 13. Oktober 2022}
}

% This file was created with Citavi 7.0.7.1

@article{.,
 author = {{Martin Ester, Hans-Peter Kriegel, J{\"o}rg Sander, Xiaowei Xu}},
 year = {1996},
 title = {A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise},
 url = {https://www.dbs.ifi.lmu.de/Publikationen/Papers/KDD-96.final.frame.pdf},
 urldate = {04.09.2025},
 pages = {226--331},
 volume = {Proceedings of 2nd International Conference on Knowledge Discovery and Data Mining},
 file = {KDD-96.final.frame:Attachments/KDD-96.final.frame.pdf:application/pdf}
}


@misc{.09.04.2025,
 abstract = {DIN 1319-1 - 1995-01 Grundlagen der Me{\ss}technik{\&}nbsp;- Teil{\&}nbsp;1: Grundbegriffe. Jetzt informieren!},
 author = {{DIN Media}},
 year = {1995},
 title = {DIN 1319-1: - 1995-01},
 url = {https://www.dinmedia.de/de/norm/din-1319-1/2440447},
 urldate = {09.04.2025}
}


@misc{.09.04.2025b,
 abstract = {ISO/IEC 22989:2022 | Information technology - Artificial intelligence - Artificial intelligence concepts and terminology},
 author = {{VDE VERLAG}},
 year = {2022},
 title = {ISO/IEC 22989:2022: IEC-Normen},
 url = {https://www.vde-verlag.de/iec-normen/251051/iso-iec-22989-2022.html},
 address = {Berlin, Offenbach},
 urldate = {09.04.2025}
}


@misc{.12.04.2025,
 abstract = {Die Datenqualit{\"a}t misst, wie gut ein Datensatz die Kriterien f{\"u}r Genauigkeit, Vollst{\"a}ndigkeit, G{\"u}ltigkeit, Konsistenz, Eindeutigkeit, Aktualit{\"a}t und Eignung f{\"u}r den Zweck erf{\"u}llt.},
 author = {IBM},
 year = {2025},
 title = {Datenqualit{\"a}t: Was ist Datenqualit{\"a}t?},
 url = {https://www.ibm.com/de-de/topics/data-quality},
 urldate = {12.04.2025}
}


@misc{.12.04.2025b,
 abstract = {Reliable and accurate machinery fault diagnosis is crucial for ensuring operational safety and reducing downtime in industrial settings. Traditional i$\ldots$},
 author = {{H. Li, J. Jiao, Z. Liu, J. Lin, T. Zhang, H. Liiu}},
 year = {2025},
 title = {Trustworthy Bayesian deep learning framework for uncertainty quantification and confidence calibration: Application in machinery fault diagnosis},
 url = {https://www.sciencedirect.com/science/article/pii/S0951832024007282},
 address = {School of Reliability and Systems Engineering, Beihang University, Beijing, 100191, China},
 urldate = {12.04.2025},
 edition = {255},
 number = {110657},
 series = {Reliability Engineering {\&} System Safety},
 doi = {10.1016/j.ress.2024.110657}
}


@misc{.21.04.2022,
 author = {{K. Greenman, A. Soleimany, K. Yang}},
 year = {2022},
 title = {Benchmarking Uncertainty Quantification For Protein Engineering},
 url = {https://openreview.net/pdf?id=G0vuqNwxaeA},
 urldate = {14.04.2025},
 series = {ICLR International Conference on Learning Representations}
}


@misc{.31.12.2024,
 author = {{J. Wachelsen} and {A. Lenzi} and {M. Kuusela}},
 year = {31.12.2024},
 title = {Neural Likelihood Surfaces for Spatial Processes with Computationally Intensive or Intractable Likelihoods},
 url = {https://arxiv.org/pdf/2305.04634},
 urldate = {18.04.2025}
}


@proceedings{.31920173242017,
 year = {2017​},
 title = {Surrogate models for uncertainty quantification: An overview},
 url = {https://ieeexplore.ieee.org/document/7928679},
 urldate = {10.04.2025},
 publisher = {IEEE},
 isbn = {978-8-8907-0187-0},
 editor = {{Bruno Sudret}},
 doi = {10.23919/EuCAP.2017.7928679}
}


@misc{dam2024,
  author       = {{Deutsche Allianz Meeresforschung}},
  title        = {{Munition im Meer: Sachstand und Perspektiven}},
  year         = {2024},
  howpublished = {Factsheet, Deutsche Allianz für Meeresforschung},
  url          = {https://www.allianz-meeresforschung.de/app/uploads/2024/10/241021-dam-factsheet-munition.pdf},
  urldate      = {2025-09-04},
  note         = {Zugriff am 04.09.2025}
}


@article{.c,
 author = {{J. Gao, M. Chen, L. Xiang, C. Xu}},
 year = {2015},
 title = {A Comprehensive Study On Evidential Deep Learning And Its Applications},
 url = {https://arxiv.org/pdf/2409.04720},
 urldate = {13.04.2025},
 file = {2409:Attachments/2409.pdf:application/pdf}
}


@book{.d,
 title = {Computer Safety, Reliability, and Security. SAFECOMP 2024},
 file = {Computer Safety:Attachments/Computer Safety.pdf:application/pdf}
}


@article{A.Kendall.,
 author = {{A. Kendall}, Y. Gal},
 title = {What uncertainties do we need in Bayesian deep learning for computer vision?},
 url = {https://dl.acm.org/doi/10.5555/3295222.3295309},
 urldate = {14.04.2025},
 pages = {5580--5590},
 journal = {NIPS'17: Proceedings of the 31st International Conference on Neural Information Processing Systems}
}


@article{AbinayaJayaprakash.,
 author = {{Abinaya Jayaprakash}},
 title = {A comparison of deep learning methods for time series forecasting with limited data},
 url = {https://www.wias-berlin.de/people/john/BETREUUNG/master_jayaprakash.pdf},
 urldate = {08.04.2025},
 file = {master{\_}jayaprakash:Attachments/master{\_}jayaprakash.pdf:application/pdf}
}


@misc{AdamPaszkeetal.2024,
 author = {{Adam Paszke et al} and {PyTorch Foundation}},
 year = {2024},
 title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
 url = {https://github.com/pytorch/pytorch},
 urldate = {10.04.2025},
 howpublished = {Software}
}


@misc{AerospaceSciencesMeetings.08.04.2025,
 author = {{Aerospace Sciences Meetings}},
 year = {08.04.2025},
 title = {A Complete Framework for Verification, Validation, and Uncertainty Quantification in Scientific Computing (Invited) | Aerospace Sciences Meetings},
 url = {https://arc.aiaa.org/doi/10.2514/6.2010-124},
 urldate = {08.04.2025}
}


@article{AlexanderAmini.2020,
 author = {{Alexander Amini} and {Wilko Schwarting} and {Ava Soleimany} and {Daniela Rus}},
 year = {2020},
 title = {Deep Evidential Regression},
 url = {https://openreview.net/forum?id=PaiLcGoa0gW&utm_source=chatgpt.com},
 urldate = {10.04.2025},
 file = {Alexander Amini, Wilko Schwarting et al. 2020 - Deep Evidential Regression:Attachments/Alexander Amini, Wilko Schwarting et al. 2020 - Deep Evidential Regression.pdf:application/pdf}
}


@misc{AndreasKreutz.2022,
 author = {{Andreas Kreutz}},
 year = {2022},
 title = {Unsicherheit in autonomen Systemen: Nicht nur eine Frage der Perzeption: Teil 1},
 url = {https://safe-intelligence.fraunhofer.de/artikel/unsicherheit-in-autonomen-systemen-teil-1},
 urldate = {12.04.2025}
}


@misc{AndreasKreutz.2022b,
 author = {{Andreas Kreutz}},
 year = {2022},
 title = {Unsicherheit in autonomen Systemen: Wo sich Fehler einschleichen k{\"o}nnen: Teil 2},
 url = {https://safe-intelligence.fraunhofer.de/artikel/unsicherheit-in-autonomen-systemen-teil-2},
 urldate = {12.04.2025}
}


@misc{ArthurHoarau2025,
  author       = {Arthur Hoarau and Benjamin Quost and Sébastien Destercke and Willem Waegeman},
  title        = {Reducing Aleatoric and Epistemic Uncertainty through Multi-modal Data Acquisition},
  year         = {2025},
  howpublished = {arXiv preprint},
  note         = {arXiv:2501.18268v1},
  url          = {https://arxiv.org/abs/2501.18268v1},
  urldate      = {2025-04-10}
}


@misc{AtlasElektronikGmbH.2025,
 author = {{Atlas Elektronik GmbH}},
 year = {2025},
 title = {Unmanned Naval Systems: Seacat},
 url = {https://www.atlas-elektronik.com/solutions/unmanned-naval-systems/seacat},
 urldate = {10.04.2025}
}


@article{BalajiLakshminarayananAlexanderPritzelandCharlesBlundell.2017,
 author = {{Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell}},
 year = {2017},
 title = {Simple and scalable predictive uncertainty estimation using deep ensembles},
 url = {https://proceedings.neurips.cc/paper/2017/file/},
 urldate = {14.04.2025},
 number = {30},
 journal = {Advances in Neural Information Processing Systems}
}


@article{BenjaminKompaJasperSnoekandAndrewL.Beam.2021,
 author = {{Benjamin Kompa, Jasper Snoek, and Andrew L. Beam}},
 year = {2021},
 title = {Empirical frequentist coverage of deep learning uncertainty quantification procedures},
 url = {https://www.mdpi.com/1099-4300/23/12/1608},
 urldate = {14.04.2025},
 journal = {Entropy},
 doi = {10.3390/e23121608}
}


@misc{bmbf2025,
  author       = {{Bundesministerium für Bildung und Forschung (BMBF)}},
  title        = {{Förderschwerpunkt Künstliche Intelligenz: Maschinelles Lernen / Data Analytics}},
  year         = {2025},
  howpublished = {Online-Dokument, Deutsches Zentrum für Luft- und Raumfahrt (DLR)},
  url          = {https://www.softwaresysteme.dlr-pt.de/de/maschinelles-lernen.php},
  urldate      = {2025-04-10},
  note         = {Zugriff am 10.04.2025}
}

@misc{BrendenM.LakeRuslanSalakhutdinovandJoshuaB.Tenenbaum.08.04.2025,
 author = {{Brenden M. Lake , Ruslan Salakhutdinov, and Joshua B. Tenenbaum}},
 year = {08.04.2025},
 title = {Human-level concept learning through probabilistic program induction},
 url = {https://www.science.org/doi/epdf/10.1126/science.aab3050?src=getftr&utm_source=sciencedirect_contenthosting&getft_integrator=sciencedirect_contenthosting},
 urldate = {08.04.2025},
 doi = {10.1126/science.aab3050}
}


@article{ChangbinLi.2023,
 abstract = {Deep neural networks (DNNs) have been shown to perform well on exclusive, multi-class classification tasks. However, when different classes have similar visual features, it becomes challenging for human annotators to differentiate them. When an image is ambiguous, such as a blurry one where an annotator can't distinguish between a husky and a wolf, it may be labeled with both classes: {husky, wolf}. This scenario necessitates the use of composite set labels. In this paper, we propose a novel framework called Hyper-Evidential Neural Network (HENN) that explicitly models predictive uncertainty caused by composite set labels in training data in the context of the belief theory called Subjective Logic (SL).By placing a Grouped Dirichlet distribution on the class probabilities, we treat predictions of a neural network as parameters of hyper-subjective opinions and learn the network that collects both single and composite evidence leading to these hyper-opinions by a deterministic DNN from data.We introduce a new uncertainty type called vagueness originally designed for hyper-opinions in SL to quantify composite classification uncertainty for DNNs.Our experiments prove that HENN outperforms its state-of-the-art counterparts based on four image datasets.The code and datasets are available at: https://shorturl.at/dhoqx.},
 author = {{C. Li} and {K. Li} and {Y. Ou} and {L. M. Kaplan} and {A. J{\o}sang} and {J.-H. Cho} and {D. H. Jeong} and {F. Chen}},
 year = {2023},
 title = {Hyper Evidential Deep Learning to Quantify Composite Classification Uncertainty},
 url = {https://openreview.net/forum?id=A7t7z6g6tMeId=2wn4oQSnr3},
 journal = {The Twelfth International Conference on Learning Representations},
 file = {Changbin Li, Kangshuo Li et al. 2023 - Hyper Evidential Deep Learning:Attachments/Changbin Li, Kangshuo Li et al. 2023 - Hyper Evidential Deep Learning.pdf:application/pdf}
}


@article{ChaoShenYangShiBradBuckham.2015,
 author = {{Chao Shen, Yang Shi, Brad Buckham}},
 year = {2015},
 title = {Model predictive control for an AUV with dynamic path planning},
 url = {https://ieeexplore.ieee.org/document/7285374},
 urldate = {10.04.2025},
 journal = {IEEE Underwater Technology (UT)},
 doi = {10.1109/SICE.2015.7285374}
}


@article{D.Pandey.,
 author = {{D. Pandey}, Q. Yu},
 title = {Learn to Accumulate Evidence from All Training Samples: Theory and Practice}
}


@misc{Dawood.30.01.2023,
 abstract = {In terms of accuracy, deep learning (DL) models have had considerable success in classification problems for medical imaging applications. However, it is well-known that the outputs of such models, which typically utilise the SoftMax function in the final classification layer can be over-confident, i.e. they are poorly calibrated. Two competing solutions to this problem have been proposed: uncertainty-aware training and evidential neural networks (ENNs). In this paper, we perform an investigation into the improvements to model calibration that can be achieved by each of these approaches individually, and their combination. We perform experiments on two classification tasks: a simpler MNIST digit classification task and a more complex and realistic medical imaging artefact detection task using Phase Contrast Cardiac Magnetic Resonance images. The experimental results demonstrate that model calibration can suffer when the task becomes challenging enough to require a higher-capacity model. However, in our complex artefact detection task, we saw an improvement in calibration for both a low and higher-capacity model when implementing both the ENN and uncertainty-aware training together, indicating that this approach can offer a promising way to improve calibration in such settings. The findings highlight the potential use of these approaches to improve model calibration in a complex application, which would in turn improve clinician trust in DL models.},
 author = {Dawood, Tareen and Chan, Emily and Razavi, Reza and King, Andrew P. and Puyol-Anton, Esther},
 date = {30.01.2023},
 title = {Addressing Deep Learning Model Calibration Using Evidential Neural  Networks and Uncertainty-Aware Training},
 url = {http://arxiv.org/pdf/2301.13296},
 file = {Dawood, Chan et al. 30.01.2023 - Addressing Deep Learning Model Calibration:Attachments/Dawood, Chan et al. 30.01.2023 - Addressing Deep Learning Model Calibration.pdf:application/pdf}
}


@misc{DiLorenzo.26.12.2017,
 abstract = {The aim of this chapter is to give an overview of the recent advances related to sampling and recovery of signals defined over graphs. First, we illustrate the conditions for perfect recovery of bandlimited graph signals from samples collected over a selected set of vertexes. Then, we describe some sampling design criteria proposed in the literature to mitigate the effect of noise and model mismatching when performing graph signal recovery. Finally, we illustrate algorithms and optimal sampling strategies for adaptive recovery and tracking of dynamic graph signals, where both sampling set and signal values are allowed to vary with time. Numerical simulations carried out over both synthetic and real data illustrate the potential advantages of graph signal processing methods for sampling, interpolation, and tracking of signals observed over irregular domains such as, e.g., technological or biological networks.},
 author = {{Di Lorenzo}, P. and Barbarossa, S. and Banelli, P.},
 date = {26.12.2017},
 title = {Sampling and Recovery of Graph Signals},
 url = {http://arxiv.org/pdf/1712.09310},
 file = {Di Lorenzo, Barbarossa et al. 26.12.2017 - Sampling and Recovery of Graph:Attachments/Di Lorenzo, Barbarossa et al. 26.12.2017 - Sampling and Recovery of Graph.pdf:application/pdf}
}


@misc{DINMediaGmbH.07.04.2025,
 abstract = {DIN SPEC 92005 - 2024-03 K{\"u}nstliche Intelligenz{\&}nbsp;- Quantifizierung von Unsicherheiten im Maschinellen Lernen; Text Englisch. Jetzt informieren!},
 author = {{DIN -- Deutsches Institut f{\"u}r Normung e. V.}},
 year = {2024},
 title = {DIN SPEC 92005 - K{\"u}nstliche Intelligenz - Quantifizierung von Unsicherheiten im Maschinellen Lernen​},
 url = {https://www.dinmedia.de/de/technische-regel/din-spec-92005/376619718},
 address = {Berlin},
 urldate = {07.04.2025},
 doi = {10.31030/3521675}
}


@book{EmanueleBorgonovo.2017,
 author = {{Emanuele Borgonovo}},
 year = {2017},
 title = {Sensitivity Analysis},
 url = {https://link.springer.com/book/10.1007/978-3-319-52259-3?page=2#toc},
 urldate = {10.04.2025},
 publisher = {{Springer Cham}},
 series = {International Series in Operations Research {\&} Management Science},
 institution = {Sprinter},
 doi = {10.1007/978-3-319-52259-3}
}


@article{Gopakumar.2024,
 author = {Gopakumar, Vignesh and Gray, Ander and Oskarsson, Joel and Zanisi, Lorenzo and Pamela, Stanislas and Giles, Daniel and Kusner, Matt and Deisenroth, Marc Peter},
 year = {2024},
 title = {Uncertainty Quantification of Surrogate Models using Conformal Prediction},
 url = {https://arxiv.org/abs/2408.09881}
}


@book{H.BruggemannP.BremerS.Zischka.2024,
 author = {{H. Br{\"u}ggemann, P. Bremer, S. Zischka}},
 year = {2024},
 title = {Grundlagen Qualit{\"a}tsmangagement: Von den Werkzeugen {\"u}ber Methoden zum TQM},
 url = {https://link.springer.com/book/10.1007/978-3-658-43563-9},
 address = {Wiesbaden},
 urldate = {13.04.2024},
 edition = {4},
 publisher = {{Springer Vieweg}},
 doi = {10.1007/978-3-658-43563-9{\textunderscore }13}
}


@article{henrio01.,
 author = {henrio01},
 title = {Microsoft PowerPoint - GUM-Konzept},
 url = {https://www.ptb.de/cms/fileadmin/internet/fachabteilungen/abteilung_3/3.1/mu/mu_rienitz_gum-messunsicherheit.pdf},
 urldate = {04.08.2025},
 file = {Microsoft PowerPoint - GUM-Konzept:Attachments/Microsoft PowerPoint - GUM-Konzept.pdf:application/pdf}
}


@inproceedings{Herd.04082024,
 author = {Herd, Benjamin and Burton, Simon},
 title = {Can you trust your ML metrics? Using Subjective Logic to determine the true contribution of ML metrics for safety},
 pages = {1579--1586},
 publisher = {ACM},
 isbn = {9798400702433},
 editor = {Hong, Jiman and Park, Juw Won and Przyby{\l}ek, Adam},
 booktitle = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
 year = {04082024},
 address = {New York, NY, USA},
 doi = {10.1145/3605098.3635966},
 file = {Herd, Burton 04082024 - Can you trust your ML:Attachments/Herd, Burton 04082024 - Can you trust your ML.pdf:application/pdf}
}


@proceedings{Hong.04082024,
 year = {04082024},
 title = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
 address = {New York, NY, USA},
 publisher = {ACM},
 isbn = {9798400702433},
 editor = {Hong, Jiman and Park, Juw Won and Przyby{\l}ek, Adam},
 doi = {10.1145/3605098}
}


@misc{Hullermeier2021,
 abstract = {The notion of uncertainty is of major importance in machine learning and constitutes a key element of machine learning methodology. In line with the statistical tradition, uncertainty has long been perceived as almost synonymous with standard probability and probabilistic predictions. Yet, due to the steadily increasing relevance of machine learning for practical applications and related issues such as safety requirements, new problems and challenges have recently been identified by machine learning scholars, and these problems may call for new methodological developments. In particular, this includes the importance of distinguishing between (at least) two different types of uncertainty, often referred to as aleatoric and epistemic. In this paper, we provide an introduction to the topic of uncertainty in machine learning as well as an overview of attempts so far at handling uncertainty in general and formalizing this distinction in particular.},
 author = {H{\"u}llermeier, Eyke and Waegeman, Willem},
 year = {2021},
 title = {Aleatoric and epistemic uncertainty in machine learning: an introduction to concepts and methods},
 url = {https://link.springer.com/article/10.1007/s10994-021-05946-3},
 pages = {457--506},
 volume = {110},
 number = {3},
 issn = {1573-0565},
 journal = {Machine Learning},
 doi = {10.1007/s10994-021-05946-3},
 file = {H{\"u}llermeier, Waegeman 2021 - Aleatoric and epistemic uncertainty:Attachments/H{\"u}llermeier, Waegeman 2021 - Aleatoric and epistemic uncertainty.pdf:application/pdf}
}


@misc{IHK.07.04.2025,
 abstract = {Hier finden Sie das Muster einer Geheimhaltungsvereinbarung. PDF zum Download. Kostenfrei.},
 author = {{IHK M{\"u}nchen}},
 year = {2025},
 title = {Muster Geheimhaltungsvereinbarung},
 url = {https://www.ihk-muenchen.de/de/Service/Recht-und-Steuern/Vertragsrecht/mustervertraege/geheimhaltungsvereinbarung.html},
 urldate = {07.04.2025}
}


@misc{Informatik.13.04.2025,
 author = {Informatik, Gesellschaft f{\"u}r},
 year = {13.04.2025},
 title = {Detail - Digital GreenTech},
 url = {https://digitalgreentech.de/projekte/detail/i-sewer},
 urldate = {13.04.2025}
}


@misc{Informatik.13.04.2025b,
 author = {Informatik, Gesellschaft f{\"u}r},
 year = {13.04.2025},
 title = {Detail - Digital GreenTech},
 url = {https://digitalgreentech.de/projekte/detail/i-sewer},
 urldate = {13.04.2025}
}


@misc{JingYanXianYangHaiyanZhaoXiaoyuanLuoXinpingGuan.2021,
 abstract = {This book presents cutting-edge results regarding localization, tracking, and formation for AUVs and discusses future research directions},
 author = {{Jing Yan, Xian Yang, Haiyan Zhao, Xiaoyuan Luo, Xinping Guan}},
 year = {2021},
 title = {Autonomous Underwater Vehicles: Localization, Tracking, and Formation},
 url = {https://link.springer.com/book/10.1007/978-981-16-6096-2},
 address = {Singapore},
 urldate = {07.04.2025},
 edition = {1},
 number = {1},
 series = {Cognitive Intelligence and Robotics},
 doi = {10.1007/978-981-16-6096-2}
}


@article{JoaquinQuinoneroCandela.2005,
 author = {{Joaquin Qui{\~n}onero-Candela} and {Carl Edward Rasmussen}},
 year = {2005},
 title = {A Unifying View of Sparse Approximate Gaussian Process Regression},
 url = {https://www.jmlr.org/papers/v6/quinonero-candela05a.html},
 pages = {1939--1959},
 volume = {6},
 number = {65},
 issn = {1533-7928},
 journal = {Journal of Machine Learning Research},
 file = {Joaquin Qui{\~n}onero-Candela, Carl Edward Rasmussen 2005 - A Unifying View of Sparse:Attachments/Joaquin Qui{\~n}onero-Candela, Carl Edward Rasmussen 2005 - A Unifying View of Sparse.pdf:application/pdf}
}


@article{JointCommitteeforGuidesinMetrology.2008,
 abstract = {Propagation of distributions using a Monte Carlo method},
 author = {{Joint Committee for Guides in Metrology}},
 year = {2008},
 title = {Evaluation of measurement data: Supplement 1 to the ``Guide to the expression of uncertainty in measurement'': Propagation of distributions using a Monte Carlo method​},
 url = {https://www.bipm.org/documents/20126/2071204/JCGM_101_2008_E.pdf},
 urldate = {04.08.2025},
 doi = {10.59161/JCGM101-2008},
 file = {Evaluation of measurement data - Supplement 1 to the GUM:Attachments/Evaluation of measurement data - Supplement 1 to the GUM.pdf:application/pdf}
}


@article{JointCommitteeforGuidesinMetrology.2008b,
 author = {{Joint Committee for Guides in Metrology}},
 year = {2008},
 title = {Evaluation of measurement data -- Guide to the expression of uncertainty in measurement: GUM 1995 with minor corrections},
 url = {https://www.bipm.org/documents/20126/2071204/JCGM_100_2008_E.pdf},
 urldate = {04.08.2025},
 doi = {10.59161/JCGM100-2008E},
 file = {2008 (GUM 1995 with minor corrections - Evaluation of measurement data:Attachments/2008 (GUM 1995 with minor corrections - Evaluation of measurement data.pdf:application/pdf}
}


@article{Jurgens.,
 abstract = {Trustworthy ML systems should not only return accurate predictions, but also a reliable representation of their uncertainty. Bayesian methods are commonly used to quantify both aleatoric and epistemic uncertainty, but alternative approaches, such as evidential deep learning methods, have become popular in recent years. The latter group of methods in essence extends empirical risk minimization (ERM) for predicting second-order probability distributions over outcomes, from which measures of epistemic (and aleatoric) uncertainty can be extracted. This paper presents novel theoretical insights of evidential deep learning, highlighting the difficulties in optimizing second-order loss functions and interpreting the resulting epistemic uncertainty measures. With a systematic setup that covers a wide range of approaches for classification, regression and counts, it provides novel insights into issues of identifiability and convergence in second-order loss minimization, and the relative (rather than absolute) nature of epistemic uncertainty measures.},
 author = {J{\"u}rgens, Mira and Meinert, Nis and Bengs, Viktor and H{\"u}llermeier, Eyke and Waegeman, Willem},
 year = {2024},
 title = {Is Epistemic Uncertainty Faithfully Represented by Evidential Deep  Learning Methods?},
 url = {http://arxiv.org/pdf/2402.09056},
 journal = {Proceedings of the 41st International Conference on Machine Learning (ICML)},
 file = {J{\"u}rgens, Meinert et al. - Is Epistemic Uncertainty Faithfully Represented:Attachments/J{\"u}rgens, Meinert et al. - Is Epistemic Uncertainty Faithfully Represented.pdf:application/pdf}
}


@incollection{K.PfeffersT.TuuananenM.A.RothenbegerS.Chatterjee.,
 author = {{K. Pfeffers, T. Tuuananen, M. A. Rothenbeger, S. Chatterjee}},
 title = {A Design Science Research Methodology for Information Systems Research},
 pages = {45--57},
 doi = {10.2753/MIS0742-1222240302}
}


@article{Kabir.,
 author = {Kabir, H. DipuM. and Yu, Wenwu and Tang, Yanyan and He, Xiangjian and Lu, Huimin},
 title = {Neural network-based uncertainty quantification: A survey of methodologies and applications},
 pages = {36218--36234},
 number = {6},
 journal = {IEEE Access},
 doi = {10.1109/ACCESS.2018.2853721}
}


@book{Keely.2025,
 author = {Keely, William and Mauceri, Steffen and Nelson, Robert and Laughner, Joshua and O'Dell, Christopher and Massie, Steven Thomas and Baker, David F. and Kiel, Matth{\"a}us and Lamminp{\"a}{\"a}, Otto and Hobbs, Jonathan M. and Chatterjee, Abhishek and Taylor, Tommy and Wennberg, Paul O. and Crowell, Sean and Stephens, Britton B. and Payne, Vivienne H.},
 year = {2025},
 title = {Uncertainty-aware Machine Learning Bias Correction and Filtering for OCO-2: Part 2},
 url = {https://d197for5662m48.cloudfront.net/documents/publicationstatus/249039/preprint_pdf/67a8bfe1096bc8bea03e9522b475844e.pdf},
 urldate = {13.04.2025},
 doi = {10.22541/essoar.174164203.37422284/v1},
 file = {67a8bfe1096bc8bea03e9522b475844e:Attachments/67a8bfe1096bc8bea03e9522b475844e.pdf:application/pdf}
}


@misc{KooroshAslansefat.,
 author = {{Koorosh Aslansefat}},
 title = {Evidential Deep Learning and Reliability},
 url = {https://www.kaggle.com/code/kooaslansefat/evidential-deep-learning-and-reliability}
}


@inproceedings{Liang.07202025,
 author = {Liang, Daojun},
 title = {DistPred: A Distribution-Free Probabilistic Inference Method for Regression and Forecasting},
 pages = {753--764},
 publisher = {ACM},
 isbn = {9798400712456},
 editor = {Sun, Yizhou and Chierichetti, Flavio and Lauw, Hady W. and Perlich, Claudia and Tok, WeeHyong and Tomkins, Andrew},
 booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1},
 year = {07202025},
 address = {New York, NY, USA},
 doi = {10.1145/3690624.3709286},
 file = {Liang 07202025 - DistPred A Distribution-Free Probabilistic Inference:Attachments/Liang 07202025 - DistPred A Distribution-Free Probabilistic Inference.pdf:application/pdf}
}


@misc{MatplotlibDevelopmentTeam.2024,
 author = {{John D. Hunter} and {Matplotlib Contributors}},
 year = {2024},
 title = {Matplotlib},
 url = {https://matplotlib.org/},
 urldate = {10.04.2025},
 howpublished = {Software}
}


@book{nof2023,
  editor    = {Shimon Y. Nof},
  title     = {Springer Handbook of Automation},
  edition   = {2},
  publisher = {Springer},
  year      = {2023},
  address   = {Cham},
  isbn      = {978-3-030-83120-9},
  doi       = {10.1007/978-3-030-83120-9}
}


@misc{NumPyDevelopers.2024,
 author = {{Travis Oliphant} and {Numpy Contributors}},
 year = {2024},
 title = {NumPy: Array programming},
 url = {https://github.com/numpy/numpy},
 address = {London, UK},
 urldate = {10.04.2025},
 howpublished = {Software},
 doi = {10.1038/s41586-020-2649-2}
}


@book{Oberkampf.2010,
 abstract = {{\textquotedbl}Advances in scientific computing have made modelling and simulation an important part of the decision-making process in engineering, science, and public policy. This book provides a comprehensive and systematic development of the basic concepts, principles, and procedures for verification and validation of models and simulations. The emphasis is placed on models that are described by partial differential and integral equations and the simulations that result from their numerical solution. The methods described can be applied to a wide range of technical fields, from the physical sciences, engineering and technology and industry, through to environmental regulations and safety, product and plant safety, financial investing, and governmental regulations. This book will be genuinely welcomed by researchers, practitioners, and decision makers in a broad range of fields, who seek to improve the credibility and reliability of simulation results. It will also be appropriate either for university courses or for independent study{\textquotedbl}--},
 author = {Oberkampf, William L. and Roy, Christopher J.},
 year = {2010},
 title = {Verification and validation in scientific computing},
 url = {https://www.cambridge.org/core/books/verification-and-validation-in-scientific-computing/05CA1F8F3CCB5AE5445FDF55239A0183},
 address = {New York},
 publisher = {{Cambridge University Press}},
 isbn = {9780511760396},
 doi = {10.1017/CBO9780511760396}
}


@article{Olivier.2021,
 author = {Olivier, Shields {\&}. Graham-Brady},
 year = {2021},
 title = {Bayesian neural networks for uncertainty quantification in data-driven materials modeling},
 number = {386},
 journal = {Computer Methods in Applied Mechanics and Engineerin},
 doi = {10.1016/j.cma.2021.114079}
}


@misc{Pandey.30.11.2022,
 abstract = {The Conditional Neural Process (CNP) family of models offer a promising direction to tackle few-shot problems by achieving better scalability and competitive predictive performance. However, the current CNP models only capture the overall uncertainty for the prediction made on a target data point. They lack a systematic fine-grained quantification on the distinct sources of uncertainty that are essential for model training and decision-making under the few-shot setting. We propose Evidential Conditional Neural Processes (ECNP), which replace the standard Gaussian distribution used by CNP with a much richer hierarchical Bayesian structure through evidential learning to achieve epistemic-aleatoric uncertainty decomposition. The evidential hierarchical structure also leads to a theoretically justified robustness over noisy training tasks. Theoretical analysis on the proposed ECNP establishes the relationship with CNP while offering deeper insights on the roles of the evidential parameters. Extensive experiments conducted on both synthetic and real-world data demonstrate the effectiveness of our proposed model in various few-shot settings.},
 author = {Pandey, Deep Shankar and Yu, Qi},
 date = {30.11.2022},
 title = {Evidential Conditional Neural Processes},
 url = {http://arxiv.org/pdf/2212.00131},
 file = {Pandey, Yu 30.11.2022 - Evidential Conditional Neural Processes:Attachments/Pandey, Yu 30.11.2022 - Evidential Conditional Neural Processes.pdf:application/pdf}
}


@misc{PhilippGrimm.2024,
 author = {{Philipp Grimm} and {Digital Green Tech}},
 year = {2024},
 title = {i-SEWER-Projekt: Die n{\"a}chste Generation der Kanalnetzsteuerung},
 url = {https://digitalgreentech.de/projekte/detail/i-sewer},
 urldate = {13.04.2025}
}


@misc{PythonProgrammingLanguage.2024,
 author = {{Python Programming Language}},
 year = {2024},
 title = {Python},
 url = {https://www.python.org/},
 urldate = {10.04.2025},
 publisher = {{Guido van Rossum} and {Python Software Foundation}},
 howpublished = {Software}
}


@proceedings{Rasmussen.2004,
 year = {2004},
 title = {Gaussian Processes in Machine Learning},
 url = {https://link.springer.com/chapter/10.1007/978-3-540-28650-9_4},
 address = {Berlin, Heidelberg},
 urldate = {07.04.2025},
 volume = {3176},
 publisher = {Springer},
 isbn = {978-3-540-28650-9},
 series = {Advanced Lectures on Machine Learning},
 editor = {{Bousquet, O., von Luxburg, U., R{\"a}tsch, G.}},
 doi = {10.1007/978-3-540-28650-9{\textunderscore }4}
}


@inproceedings{Rasmussen.2004b,
 abstract = {We give a basic introduction to Gaussian Process regression models. We focus on understanding the role of the stochastic process and how it is used to define a distribution over functions. We present the simple equations for incorporating training data and examine...},
 author = {Rasmussen, Carl Edward},
 title = {Gaussian Processes in Machine Learning},
 url = {https://link.springer.com/chapter/10.1007/978-3-540-28650-9_4},
 pages = {63--71},
 publisher = {Springer},
 isbn = {978-3-540-28650-9},
 series = {Advanced Lectures on Machine Learning},
 editor = {{Bousquet, O., von Luxburg, U., R{\"a}tsch, G.}},
 booktitle = {Gaussian Processes in Machine Learning},
 year = {2004},
 address = {Berlin, Heidelberg},
 doi = {10.1007/978-3-540-28650-9{\textunderscore }4},
 file = {Rasmussen 2004 - Gaussian Processes in Machine Learning:Attachments/Rasmussen 2004 - Gaussian Processes in Machine Learning.pdf:application/pdf}
}


@phdthesis{Riedmaier.,
 abstract = {This dissertation presents a methodology for validation of simulation models to ensure virtual safeguarding of automated vehicles. The methodology quantifies model uncertainties compared to real experiments and predicts them by a data-driven approach to the virtual safeguarding scenarios. This provides statistical guarantees for reliable decision making. The methodology is first introduced generically and then configured, implemented, and evaluated specifically for safeguarding.},
 author = {Riedmaier, Stefan},
 year = {2022},
 title = {Model Validation and Uncertainty Aggregation for Safety Assessment of Automated Vehicles},
 url = {https://mediatum.ub.tum.de/doc/1615375/1615375.pdf},
 address = {M{\"u}nchen},
 urldate = {07.04.2025},
 school = {{Technische Universit{\"a}t M{\"u}nchen}},
 type = {Phd-Thesis},
 file = {Riedmaier - Model Validation and Uncertainty Aggregation:Attachments/Riedmaier - Model Validation and Uncertainty Aggregation.pdf:application/pdf}
}


@article{Riedmaier.2021,
 abstract = {Simulation is becoming increasingly important in the development, testing and approval process in many areas of engineering, ranging from finite element models to highly complex cyber-physical systems such as autonomous cars. Simulation must be accompanied by model verification, validation and uncertainty quantification (VV{\&}UQ) activities to assess the inherent errors and uncertainties of each simulation model. However, the VV{\&}UQ methods differ greatly between the application areas. In general, a major challenge is the aggregation of uncertainties from calibration and validation experiments to the actual model predictions under new, untested conditions. This is especially relevant due to high extrapolation uncertainties, if the experimental conditions differ strongly from the prediction conditions, or if the output quantities required for prediction cannot be measured during the experiments. In this paper, both the heterogeneous VV{\&}UQ landscape and the challenge of aggregation will be addressed with a novel modular and unified framework to enable credible decision making based on simulation models. This paper contains a comprehensive survey of over 200 literature sources from many application areas and embeds them into the unified framework. In addition, this paper analyzes and compares the VV{\&}UQ methods and the application areas in order to identify strengths and weaknesses and to derive further research directions. The framework thus combines a variety of VV{\&}UQ methods, so that different engineering areas can benefit from new methods and combinations. Finally, this paper presents a procedure to select a suitable method from the framework for the desired application.},
 author = {Riedmaier, Stefan and Danquah, Benedikt and Schick, Bernhard and Diermeyer, Frank},
 year = {2021},
 title = {Unified Framework and Survey for Model Verification, Validation and Uncertainty Quantification},
 url = {https://link.springer.com/article/10.1007/s11831-020-09473-7},
 pages = {2655--2688},
 volume = {28},
 number = {4},
 issn = {1886-1784},
 journal = {Archives of Computational Methods in Engineering},
 doi = {10.1007/s11831-020-09473-7},
 file = {Riedmaier, Danquah et al. 2021 - Unified Framework and Survey:Attachments/Riedmaier, Danquah et al. 2021 - Unified Framework and Survey.pdf:application/pdf}
}


@incollection{S.BurtonB.HerdJ.V.Zacchi.,
 author = {{S. Burton, B. Herd, J.-V. Zacchi}},
 title = {Uncertainty-Aware Evaluation of Quantitative ML Safety Requirements},
 url = {https://dl.acm.org/doi/10.1007/978-3-031-68738-9_31},
 urldate = {13.04.2025},
 pages = {391--404},
 booktitle = {Computer Safety, Reliability, and Security. SAFECOMP 2024},
 doi = {10.1007/978-3-031-68738-9{\textunderscore }31}
}


@misc{Schmitt.13.10.2022,
 abstract = {Bayesian model comparison (BMC) offers a principled probabilistic approach to study and rank competing models. In standard BMC, we construct a discrete probability distribution over the set of possible models, conditional on the observed data of interest. These posterior model probabilities (PMPs) are measures of uncertainty, but -- when derived from a finite number of observations -- are also uncertain themselves. In this paper, we conceptualize distinct levels of uncertainty which arise in BMC. We explore a fully probabilistic framework for quantifying meta-uncertainty, resulting in an applied method to enhance any BMC workflow. Drawing on both Bayesian and frequentist techniques, we represent the uncertainty over the uncertain PMPs via meta-models which combine simulated and observed data into a predictive distribution for PMPs on new data. We demonstrate the utility of the proposed method in the context of conjugate Bayesian regression, likelihood-based inference with Markov chain Monte Carlo, and simulation-based inference with neural networks.},
 author = {Schmitt, Marvin and Radev, Stefan T. and B{\"u}rkner, Paul-Christian},
 date = {13.10.2022},
 title = {Meta-Uncertainty in Bayesian Model Comparison},
 url = {http://arxiv.org/pdf/2210.07278},
 file = {Schmitt, Radev et al. 13.10.2022 - Meta-Uncertainty in Bayesian Model Comparison:Attachments/Schmitt, Radev et al. 13.10.2022 - Meta-Uncertainty in Bayesian Model Comparison.pdf:application/pdf}
}


@book{Schmitt.2020,
 author = {Schmitt, Robert H.},
 year = {2020},
 title = {Potenziale K{\"u}nstlicher Intelligenz f{\"u}r die Qualit{\"a}tswissenschaft},
 address = {Berlin, Heidelberg},
 publisher = {{Springer Berlin Heidelberg}},
 isbn = {978-3-662-60691-9},
 doi = {10.1007/978-3-662-60692-6},
 file = {Schmitt 2020 - Potenziale K{\"u}nstlicher Intelligenz:Attachments/Schmitt 2020 - Potenziale K{\"u}nstlicher Intelligenz.pdf:application/pdf}
}


@misc{Schreck.2023,
 abstract = {Robust quantification of predictive uncertainty is critical for understanding factors that drive weather and climate outcomes. Ensembles provide predictive uncertainty estimates and can be decomposed physically, but both physics and machine learning ensembles are computationally expensive. Parametric deep learning can estimate uncertainty with one model by predicting the parameters of a probability distribution but do not account for epistemic uncertainty.. Evidential deep learning, a technique that extends parametric deep learning to higher-order distributions, can account for both aleatoric and epistemic uncertainty with one model. This study compares the uncertainty derived from evidential neural networks to those obtained from ensembles. Through applications of classification of winter precipitation type and regression of surface layer fluxes, we show evidential deep learning models attaining predictive accuracy rivaling standard methods, while robustly quantifying both sources of uncertainty. We evaluate the uncertainty in terms of how well the predictions are calibrated and how well the uncertainty correlates with prediction error. Analyses of uncertainty in the context of the inputs reveal sensitivities to underlying meteorological processes, facilitating interpretation of the models. The conceptual simplicity, interpretability, and computational efficiency of evidential neural networks make them highly extensible, offering a promising approach for reliable and practical uncertainty quantification in Earth system science modeling. In order to encourage broader adoption of evidential deep learning in Earth System Science, we have developed a new Python package, MILES-GUESS (this https URL), that enables users to train and evaluate both evidential and ensemble deep learning.},
 author = {Schreck, John S. and Gagne, David John and Becker, Charlie and Chapman, William E. and Elmore, Kim and {Da Fan} and Gantos, Gabrielle and Kim, Eliot and Kimpara, Dhamma and Martin, Thomas and Molina, Maria J. and Przybylo, Vanessa M. and Radford, Jacob and Saavedra, Belen and Willson, Justin and Wirz, Christopher},
 date = {2024},
 title = {Evidential Deep Learning: Enhancing Predictive Uncertainty Estimation for Earth System Science Applications},
 url = {http://arxiv.org/pdf/2309.13207},
 number = {4},
 doi = {10.1175/AIES-D-23-0093.1},
 file = {Schreck, Gagne et al. 2023 - Evidential Deep Learning:Attachments/Schreck, Gagne et al. 2023 - Evidential Deep Learning.pdf:application/pdf}
}


@misc{ScikitlearnDevelopers.2024,
 author = {{Scikit-learn Developers}},
 year = {2024},
 title = {Scikit-learn},
 url = {https://scikit-learn.org/},
 urldate = {10.04.2025},
 howpublished = {Software}
}


@misc{SciPyDevelopers.2024,
 author = {{Travis Oliphant, Pearu Peterson, Eric Jones} and {SciPy Contributors}},
 year = {2024},
 title = {SciPy: Scientific Computing Tools for Python},
 url = {https://github.com/scipy/scipy},
 urldate = {10.04.2025}
}


@book{SpringerLink.12.04.2025,
 abstract = {Thoroughly updated new edition provides the most advanced, comprehensive, and balanced coverage of the technical and engineering aspects of automation},
 year = {2023},
 title = {Springer Handbook of Automation},
 url = {https://link.springer.com/book/10.1007/978-3-030-96729-1},
 address = {Cham},
 urldate = {12.04.2025},
 edition = {2.},
 publisher = {{Springer Nature Switzerland AG}},
 isbn = {978-3-030-96728-4},
 series = {Springer Handbooks},
 editor = {{Shimon Y. Nof​}},
 doi = {10.1007/978-3-030-96729-1}
}


@article{Stankiewicz.2021,
 author = {Stankiewicz, P. and Tan, Y. T. and Kobilarov, M.},
 year = {2021},
 title = {Adaptive sampling with an autonomous underwater vehicle in static marine environments},
 pages = {572--597},
 number = {38},
 journal = {Journal of Field Robotics},
 doi = {10.1002/rob.22005}
}


@book{StevenL.BruntonJ.NathanKutz.2022,
 author = {{Steven L. Brunton, J. Nathan Kutz}},
 year = {2022},
 title = {Data-Driven Science and Engineering: Machine Learning, Dynamical Systems, and Control},
 url = {https://www.cambridge.org/highereducation/books/data-driven-science-and-engineering/6F9A730B7A9A9F43F68CF21A24BEC339#overview},
 address = {Cambridge, United Kingdom},
 urldate = {10.04.2025},
 edition = {2},
 publisher = {{Cambridge University Press}},
 isbn = {9781009098489},
 institution = {{Cambridge University Press}},
 doi = {10.1017/9781009089517}
}


@inproceedings{Sudret.31920173242017,
 author = {Sudret, Bruno and Marelli, Stefano and Wiart, Joe},
 title = {Surrogate models for uncertainty quantification: An overview},
 url = {https://ieeexplore.ieee.org/document/7928679/},
 urldate = {10.04.2025},
 pages = {793--797},
 publisher = {IEEE},
 isbn = {978-8-8907-0187-0},
 editor = {{Bruno Sudret}},
 booktitle = {Surrogate models for uncertainty quantification},
 year = {2017​},
 doi = {10.23919/EuCAP.2017.7928679}
}


@proceedings{Sun.07202025,
 year = {07202025},
 title = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1},
 address = {New York, NY, USA},
 publisher = {ACM},
 isbn = {9798400712456},
 editor = {Sun, Yizhou and Chierichetti, Flavio and Lauw, Hady W. and Perlich, Claudia and Tok, WeeHyong and Tomkins, Andrew},
 doi = {10.1145/3690624}
}


@misc{TensorFlowDevelopers.2024,
 author = {{TensorFlow Developers}},
 year = {2024},
 title = {TensorFlow: End-to-End Open Source Machine Learning Platform},
 url = {https://www.tensorflow.org/},
 urldate = {10.04.2025},
 howpublished = {Software}
}


@misc{Tik.12.04.2025,
 abstract = {Physik-informierte {\&} Datenbasierte Surrogatsmodellierung},
 author = {Tik},
 year = {12.04.2025},
 title = {Surrogatsmodellierung | Institut f{\"u}r Technische und Numerische Mechanik | Universit{\"a}t Stuttgart},
 url = {https://www.itm.uni-stuttgart.de/forschung/surrogatsmodellierung/},
 urldate = {13.04.2025}
}


@book{TiloPfeiffer.2021,
 author = {{Tilo Pfeiffer}, Robert Schmitt},
 year = {2021},
 title = {Masing Handbuch Qualit{\"a}tsmanagement},
 url = {https://www.springerprofessional.de/masing-handbuch-qualitaets-management/26172540?tocPage=1},
 urldate = {10.04.2025},
 publisher = {{Carl Hanser Verlag GmbH {\&} Co. KG}},
 isbn = {978-3-446-46621-0},
 doi = {10.1007/978-3-446-46621-0}
}


@misc{Torvalds.2024,
 author = {Torvalds, L. and {Git Contributors}},
 year = {2024},
 title = {Git},
 url = {https://git-scm.com/},
 urldate = {10.04.2025},
 howpublished = {Software}
}


@misc{Tripathy.27.02.2019,
 abstract = {A problem of considerable importance within the field of uncertainty quantification (UQ) is the development of efficient methods for the construction of accurate surrogate models. Such efforts are particularly important to applications constrained by high-dimensional uncertain parameter spaces. The difficulty of accurate surrogate modeling in such systems, is further compounded by data scarcity brought about by the large cost of forward model evaluations. Traditional response surface techniques, such as Gaussian process regression (or Kriging) and polynomial chaos are difficult to scale to high dimensions. To make surrogate modeling tractable in expensive high-dimensional systems, one must resort to dimensionality reduction of the stochastic parameter space. A recent dimensionality reduction technique that has shown great promise is the method of `active subspaces'. The classical formulation of active subspaces, unfortunately, requires gradient information from the forward model - often impossible to obtain. In this work, we present a simple, scalable method for recovering active subspaces in high-dimensional stochastic systems, without gradient-information that relies on a reparameterization of the orthogonal active subspace projection matrix, and couple this formulation with deep neural networks. We demonstrate our approach on synthetic and real world datasets and show favorable predictive comparison to classical active subspaces.},
 author = {Tripathy, Rohit and Bilionis, Ilias},
 date = {27.02.2019},
 title = {Deep active subspaces: a scalable method for high-dimensional  uncertainty propagation},
 url = {http://arxiv.org/pdf/1902.10527},
 urldate = {10.04.2025},
 file = {Tripathy, Bilionis 27.02.2019 - Deep active subspaces:Attachments/Tripathy, Bilionis 27.02.2019 - Deep active subspaces.pdf:application/pdf}
}


@article{Tunkiel.2020,
 author = {Tunkiel, Andrzej T. and Sui, Dan and Wiktorski, Tomasz},
 year = {2020},
 title = {Data-driven sensitivity analysis of complex machine learning models: A case study of directional drilling},
 pages = {107630},
 volume = {195},
 issn = {09204105},
 journal = {Journal of Petroleum Science and Engineering},
 doi = {10.1016/j.petrol.2020.107630},
 file = {Tunkiel, Sui et al. 2020 - Data-driven sensitivity analysis of complex:Attachments/Tunkiel, Sui et al. 2020 - Data-driven sensitivity analysis of complex.pdf:application/pdf}
}


@misc{UQpyProjectTeam.2024,
 author = {{Olivier, A., Giovanis, D.G., Aakash, B.S., Chauhan, M., Vandanapu, L., Shields, M.D.}},
 year = {2024},
 title = {UQpy: A general purpose Python package and development environment for uncertainty quantification},
 url = {https://github.com/SURGroup/UQpy},
 urldate = {10.04.2025},
 howpublished = {Software},
 doi = {10.1016/j.jocs.2020.101204}
}


@misc{WeichengCuiShixiaoFuZhiqiangHu.07.04.2025,
 author = {{Weicheng Cui, Shixiao Fu, Zhiqiang Hu}},
 year = {2020},
 title = {Encyclopedia of Ocean Engineering},
 url = {https://link.springer.com/referencework/10.1007/978-981-10-6963-5},
 address = {Singapore},
 urldate = {07.04.2025},
 doi = {10.1007/978-981-10-6963-5}
}


@article{Y.LiD.RugamerB.BischlM.Rezaei.2025,
 author = {{Y. Li, D. R{\"u}gamer, B. Bischl, M. Rezaei}},
 year = {2025},
 title = {Calibrating LLMs With Information-Theoretic Evidential Deep Learning},
 url = {https://openreview.net/forum?id=YcML3rJl0N},
 urldate = {14.04.2025},
 journal = {The Tirtheenth International Conference On Learning Representations}
}


@article{YajieBaoJavadMohammadpourVelni.2024,
 author = {{Yajie Bao, Javad Mohammadpour Velni}},
 year = {2024},
 title = {Adaptive Uncertainty Quantification For Scenario Based Control Using Meta-Learning Of Bayesian Nerual Networks},
 url = {https://www.sciencedirect.com/science/article/pii/S240589632500093X},
 urldate = {10.04.2025},
 pages = {486--491},
 number = {58},
 journal = {IFAC-PapersOnLine},
 doi = {10.1016/j.ifacol.2025.01.093}
}


@article{YarinGalandZoubinGhahramani.2016,
 author = {{Yarin Gal and Zoubin Ghahramani}},
 year = {2016},
 title = {Dropout as a bayesian approximation: Representing model uncertainty in deep learning},
 url = {https://proceedings.mlr.press/v48/gal16.html},
 urldate = {14.04.2025},
 pages = {1050--1059},
 journal = {Proceedings of The 33rd International Conference On Machine Learning}
}


@article{YehorYudinM.Sc..2024,
 author = {{Yehor Yudin, M. Sc.}},
 year = {2024},
 title = {Uncertainty Quantification and Machine Learning Surrogate Models for Multi-Scale High-Performance-Computing Plasma Physics Turbulent Transport Simulations},
 url = {https://nbn-resolving.org/urn:nbn:de:bvb:91-diss-20240812-1739952-1-7},
 urldate = {08.04.2025},
 pages = {138},
 file = {1739952:Attachments/1739952.pdf:application/pdf}
}


