@article{cui2020,
  author = {Weicheng Cui and Shixiao Fu and Zhiqiang Hu},
  title = {Autonomous Underwater Vehicles with Uncertainty-Aware ML},
  journal = {Ocean Engineering},
  year = {2020},
  keywords = {zeitschriftenaufsatz}
}

@article{yan2021,
  author = {Jing Yan and Xian Yang and Haiyan Zhao and Xiaoyuan Luo and Xinping Guan},
  title = {Deep Learning for Underwater Robotics},
  journal = {IEEE Trans. on Robotics},
  year = {2021},
  keywords = {zeitschriftenaufsatz}
}


@article{schmitt2022,
  author = {Schmitt, Radev, Bürkner},
  title = {Meta-Unsicherheit im Bayes'schen Modellvergleich},
  year = {2022},
  note = {Vortrag, 13. Oktober 2022},
  keywords = {beitrag}
}


% This file was created with Citavi 7.0.7.1


@article{ester1996,
  author = {{Martin Ester, Hans-Peter Kriegel, J{\"o}rg Sander, Xiaowei Xu}},
  title = {A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise},
  year = {1996},
  volume = {Proceedings of 2nd International Conference on Knowledge Discovery and Data Mining},
  pages = {226--331},
  url = {https://www.dbs.ifi.lmu.de/Publikationen/Papers/KDD-96.final.frame.pdf},
  urldate = {04.09.2025},
  keywords = {zeitschriftenaufsatz}
}


@misc{din1319,
  author    = {{DIN Media}},
  title     = {DIN 1319-1: - 1995-01},
  year      = {1995},
  abstract  = {DIN 1319-1 - 1995-01 Grundlagen der Messtechnik – Teil 1: Grundbegriffe. Jetzt informieren!},
  url       = {https://www.dinmedia.de/de/norm/din-1319-1/2440447},
  urldate   = {2025-04-09},
  keywords  = {internetdokument}
}


@misc{iso22989,
  author    = {{VDE VERLAG}},
  title     = {ISO/IEC 22989:2022: IEC-Normen},
  year      = {2022},
  address   = {Berlin, Offenbach},
  abstract  = {ISO/IEC 22989:2022 | Information technology - Artificial intelligence - Artificial intelligence concepts and terminology},
  url       = {https://www.vde-verlag.de/iec-normen/251051/iso-iec-22989-2022.html},
  urldate   = {2025-04-09},
  keywords  = {internetdokument}
}


@misc{ibm2025dataquality,
  author    = {IBM},
  title     = {Datenqualität: Was ist Datenqualität?},
  year      = {2025},
  abstract  = {Die Datenqualität misst, wie gut ein Datensatz die Kriterien für Genauigkeit, Vollständigkeit, Gültigkeit, Konsistenz, Eindeutigkeit, Aktualität und Eignung für den Zweck erfüllt.},
  url       = {https://www.ibm.com/de-de/topics/data-quality},
  urldate   = {2025-04-12},
  keywords  = {internetdokument}
}


@article{li2025bayesianuq,
  author    = {H. Li and J. Jiao and Z. Liu and J. Lin and T. Zhang and H. Liiu},
  title     = {Trustworthy Bayesian Deep Learning Framework for Uncertainty Quantification and Confidence Calibration: Application in Machinery Fault Diagnosis},
  journal   = {Reliability Engineering \& System Safety},
  year      = {2025},
  volume    = {255},
  number    = {110657},
  doi       = {10.1016/j.ress.2024.110657},
  url       = {https://www.sciencedirect.com/science/article/pii/S0951832024007282},
  urldate   = {2025-04-12},
  address   = {School of Reliability and Systems Engineering, Beihang University, Beijing, China},
  keywords  = {zeitschriftenaufsatz}
}


@inproceedings{greenman2022uq,
  author    = {K. Greenman and A. Soleimany and K. Yang},
  title     = {Benchmarking Uncertainty Quantification For Protein Engineering},
  booktitle = {Proceedings of the International Conference on Learning Representations (ICLR)},
  year      = {2022},
  url       = {https://openreview.net/pdf?id=G0vuqNwxaeA},
  urldate   = {2025-04-14},
  keywords  = {beitrag}
}


@misc{wachelsen2024nls,
  author    = {J. Wachelsen and A. Lenzi and M. Kuusela},
  title     = {Neural Likelihood Surfaces for Spatial Processes with Computationally Intensive or Intractable Likelihoods},
  year      = {2024},
  note      = {Preprint, arXiv},
  url       = {https://arxiv.org/pdf/2305.04634},
  urldate   = {2025-04-18},
  keywords  = {beitrag}
}


@inproceedings{sudret2017surrogate,
  author    = {Bruno Sudret},
  title     = {Surrogate Models for Uncertainty Quantification: An Overview},
  booktitle = {11th European Conference on Antennas and Propagation (EUCAP)},
  year      = {2017},
  publisher = {IEEE},
  isbn      = {978-8-8907-0187-0},
  url       = {https://ieeexplore.ieee.org/document/7928679},
  urldate   = {2025-04-10},
  doi       = {10.23919/EuCAP.2017.7928679},
  keywords  = {beitrag}
}


@online{dam2024,
  author       = {{Deutsche Allianz Meeresforschung}},
  title        = {Munition im Meer: Sachstand und Perspektiven},
  year         = {2024},
  howpublished = {Factsheet, Deutsche Allianz für Meeresforschung},
  url          = {https://www.allianz-meeresforschung.de/app/uploads/2024/10/241021-dam-factsheet-munition.pdf},
  urldate      = {2025-09-04},
  note         = {Zugriff am 04.09.2025},
  keywords     = {internetdokument}
}


@article{gao2015,
  author    = {J. Gao and M. Chen and L. Xiang and C. Xu},
  title     = {A Comprehensive Study On Evidential Deep Learning And Its Applications},
  year      = {2015},
  url       = {https://arxiv.org/pdf/2409.04720},
  urldate   = {2025-04-13},
  keywords  = {internetdokument},
  file      = {2409:Attachments/2409.pdf:application/pdf}
}


@book{safecomp2024,
  title     = {Computer Safety, Reliability, and Security. SAFECOMP 2024},
  year      = {2024},
  publisher = {Springer},
  keywords  = {buch},
  file      = {Computer Safety:Attachments/Computer Safety.pdf:application/pdf}
}


@article{kendall2017,
  author    = {{A. Kendall} and {Y. Gal}},
  title     = {What uncertainties do we need in Bayesian deep learning for computer vision?},
  journal   = {NIPS'17: Proceedings of the 31st International Conference on Neural Information Processing Systems},
  pages     = {5580--5590},
  year      = {2017},
  url       = {https://dl.acm.org/doi/10.5555/3295222.3295309},
  urldate   = {2025-04-14},
  keywords  = {zeitschriftenaufsatz}
}


@article{jayaprakash2025,
  author    = {{Abinaya Jayaprakash}},
  title     = {A Comparison of Deep Learning Methods for Time Series Forecasting with Limited Data},
  year      = {2025},
  url       = {https://www.wias-berlin.de/people/john/BETREUUNG/master_jayaprakash.pdf},
  urldate   = {2025-04-08},
  keywords  = {internetdokument}
}


@misc{AdamPaszkeetal.2024,
  author       = {{Adam Paszke et al} and {PyTorch Foundation}},
  year         = {2024},
  title        = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  url          = {https://github.com/pytorch/pytorch},
  urldate      = {2025-04-10},
  howpublished = {Software},
  keywords     = {internetdokument}
}


@misc{AerospaceSciencesMeetings.08.04.2025,
  author       = {{Aerospace Sciences Meetings}},
  year         = {2025},
  title        = {A Complete Framework for Verification, Validation, and Uncertainty Quantification in Scientific Computing (Invited) | Aerospace Sciences Meetings},
  url          = {https://arc.aiaa.org/doi/10.2514/6.2010-124},
  urldate      = {2025-04-08},
  keywords     = {internetdokument}
}


@article{AlexanderAmini2020,
  author    = {Alexander Amini and Wilko Schwarting and Ava Soleimany and Daniela Rus},
  year      = {2020},
  title     = {Deep Evidential Regression},
  url       = {https://openreview.net/forum?id=PaiLcGoa0gW&utm_source=chatgpt.com},
  urldate   = {2025-04-10},
  file      = {Alexander Amini, Wilko Schwarting et al. 2020 - Deep Evidential Regression:Attachments/Alexander Amini, Wilko Schwarting et al. 2020 - Deep Evidential Regression.pdf:application/pdf},
  keywords  = {internetdokument},
  note      = {Alexander Amini, Wilko Schwarting, Ava Soleimany und Daniela Rus. „Deep Evidential Regression“. 2020.}
}

@online{AndreasKreutz2022,
  author    = {{Andreas Kreutz}},
  year      = {2022},
  title     = {Unsicherheit in autonomen Systemen: Nicht nur eine Frage der Perzeption: Teil 1},
  url       = {https://safe-intelligence.fraunhofer.de/artikel/unsicherheit-in-autonomen-systemen-teil-1},
  urldate   = {2025-04-12},
  keywords  = {internetdokument}
}


@online{AndreasKreutz2022b,
  author    = {{Andreas Kreutz}},
  year      = {2022},
  title     = {Unsicherheit in autonomen Systemen: Wo sich Fehler einschleichen können: Teil 2},
  url       = {https://safe-intelligence.fraunhofer.de/artikel/unsicherheit-in-autonomen-systemen-teil-2},
  urldate   = {2025-04-12},
  keywords  = {internetdokument}
}


@misc{ArthurHoarau2025,
  author       = {Arthur Hoarau and Benjamin Quost and Sébastien Destercke and Willem Waegeman},
  title        = {Reducing Aleatoric and Epistemic Uncertainty through Multi-modal Data Acquisition},
  year         = {2025},
  howpublished = {arXiv preprint},
  note         = {arXiv:2501.18268v1},
  url          = {https://arxiv.org/abs/2501.18268v1},
  urldate      = {2025-04-10},
  keywords     = {internetdokument}
}


@misc{AtlasElektronikGmbH.2025,
  author    = {{Atlas Elektronik GmbH}},
  year      = {2025},
  title     = {Unmanned Naval Systems: Seacat},
  url       = {https://www.atlas-elektronik.com/solutions/unmanned-naval-systems/seacat},
  urldate   = {2025-04-10},
  keywords  = {internetdokument}
}


@article{BalajiLakshminarayananAlexanderPritzelandCharlesBlundell.2017,
  author    = {Balaji Lakshminarayanan and Alexander Pritzel and Charles Blundell},
  year      = {2017},
  title     = {Simple and scalable predictive uncertainty estimation using deep ensembles},
  journal   = {Advances in Neural Information Processing Systems},
  number    = {30},
  url       = {https://proceedings.neurips.cc/paper/2017/file/},
  urldate   = {2025-04-14},
  keywords  = {zeitschriftenaufsatz}
}


@article{BenjaminKompaJasperSnoekandAndrewL.Beam.2021,
  author    = {Benjamin Kompa and Jasper Snoek and Andrew L. Beam},
  year      = {2021},
  title     = {Empirical Frequentist Coverage of Deep Learning Uncertainty Quantification Procedures},
  journal   = {Entropy},
  doi       = {10.3390/e23121608},
  url       = {https://www.mdpi.com/1099-4300/23/12/1608},
  urldate   = {2025-04-14},
  keywords  = {zeitschriftenaufsatz}
}


@misc{bmbf2025,
  author       = {{Bundesministerium für Bildung und Forschung (BMBF)}},
  title        = {{Förderschwerpunkt Künstliche Intelligenz: Maschinelles Lernen / Data Analytics}},
  year         = {2025},
  howpublished = {Online-Dokument, Deutsches Zentrum für Luft- und Raumfahrt (DLR)},
  url          = {https://www.softwaresysteme.dlr-pt.de/de/maschinelles-lernen.php},
  urldate      = {2025-04-10},
  note         = {Zugriff am 10.04.2025},
  keywords     = {internetdokument}
}


@misc{BrendenM.LakeRuslanSalakhutdinovandJoshuaB.Tenenbaum.08.04.2025,
  author       = {{Brenden M. Lake}, {Ruslan Salakhutdinov}, and {Joshua B. Tenenbaum}},
  year         = {2025},
  title        = {Human-level concept learning through probabilistic program induction},
  url          = {https://www.science.org/doi/epdf/10.1126/science.aab3050?src=getftr&utm_source=sciencedirect_contenthosting&getft_integrator=sciencedirect_contenthosting},
  urldate      = {2025-04-08},
  doi          = {10.1126/science.aab3050},
  keywords     = {internetdokument}
}


@article{ChangbinLi.2023,
  author       = {{C. Li} and {K. Li} and {Y. Ou} and {L. M. Kaplan} and {A. J{\o}sang} and {J.-H. Cho} and {D. H. Jeong} and {F. Chen}},
  year         = {2023},
  title        = {Hyper Evidential Deep Learning to Quantify Composite Classification Uncertainty},
  journal      = {The Twelfth International Conference on Learning Representations},
  url          = {https://openreview.net/forum?id=A7t7z6g6tMeId=2wn4oQSnr3},
  file         = {Changbin Li, Kangshuo Li et al. 2023 - Hyper Evidential Deep Learning:Attachments/Changbin Li, Kangshuo Li et al. 2023 - Hyper Evidential Deep Learning.pdf:application/pdf},
  abstract     = {Deep neural networks (DNNs) have been shown to perform well on exclusive, multi-class classification tasks...},
  keywords     = {zeitschriftenaufsatz}
}


@article{ChaoShenYangShiBradBuckham.2015,
  author    = {{Chao Shen, Yang Shi, Brad Buckham}},
  year      = {2015},
  title     = {Model predictive control for an AUV with dynamic path planning},
  journal   = {IEEE Underwater Technology (UT)},
  url       = {https://ieeexplore.ieee.org/document/7285374},
  urldate   = {2025-04-10},
  doi       = {10.1109/SICE.2015.7285374},
  keywords  = {zeitschriftenaufsatz}
}


@misc{Dawood.2023,
  author       = {Tareen Dawood and Emily Chan and Reza Razavi and Andrew P. King and Esther Puyol-Anton},
  title        = {Addressing Deep Learning Model Calibration Using Evidential Neural Networks and Uncertainty-Aware Training},
  year         = {2023},
  month        = {jan},
  day          = {30},
  url          = {http://arxiv.org/pdf/2301.13296},
  urldate      = {2025-04-10},
  note         = {arXiv preprint arXiv:2301.13296},
  abstract     = {In terms of accuracy, deep learning (DL) models have had considerable success in classification problems for medical imaging applications. However, it is well-known that the outputs of such models, which typically utilise the SoftMax function in the final classification layer can be over-confident, i.e. they are poorly calibrated. ...},
  file         = {Dawood, Chan et al. 30.01.2023 - Addressing Deep Learning Model Calibration:Attachments/Dawood, Chan et al. 30.01.2023 - Addressing Deep Learning Model Calibration.pdf:application/pdf},
  keywords     = {zeitschriftenaufsatz, evidential learning, model calibration, uncertainty-aware training}
}


@misc{Depeweg2019,
  author       = {Stefan Depeweg},
  title        = {Modeling Epistemic and Aleatoric Uncertainty with Bayesian Neural Networks and Latent Variables},
  school       = {Technische Universität München},
  year         = {2019},
  address      = {München, Deutschland},
  url          = {https://mediatum.ub.tum.de/doc/1482483/266761.pdf},
  note         = {Dissertation, Fakultät für Informatik},
  keywords     = {thesis, Bayes'sche neuronale Netze, Unsicherheitsquantifizierung, latente Variablen, epistemische Unsicherheit, aleatorische Unsicherheit}
}


@misc{DiLorenzo.2017,
  author       = {P. Di Lorenzo and S. Barbarossa and P. Banelli},
  title        = {Sampling and Recovery of Graph Signals},
  year         = {2017},
  month        = {dec},
  day          = {26},
  abstract     = {The aim of this chapter is to give an overview of the recent advances related to sampling and recovery of signals defined over graphs. First, we illustrate the conditions for perfect recovery of bandlimited graph signals from samples collected over a selected set of vertexes. Then, we describe some sampling design criteria...},
  url          = {http://arxiv.org/pdf/1712.09310},
  urldate      = {2025-04-10},
  note         = {arXiv preprint arXiv:1712.09310},
  file         = {Di Lorenzo, Barbarossa et al. 26.12.2017 - Sampling and Recovery of Graph:Attachments/Di Lorenzo, Barbarossa et al. 26.12.2017 - Sampling and Recovery of Graph.pdf:application/pdf},
  keywords     = {zeitschriftenaufsatz, graph signal processing, sampling, recovery}
}


@misc{DINMediaGmbH.2024,
  author       = {{DIN -- Deutsches Institut für Normung e. V.}},
  title        = {DIN SPEC 92005 - Künstliche Intelligenz – Quantifizierung von Unsicherheiten im Maschinellen Lernen},
  year         = {2024},
  month        = {mar},
  abstract     = {DIN SPEC 92005 - 2024-03 Künstliche Intelligenz – Quantifizierung von Unsicherheiten im Maschinellen Lernen; Text Englisch. Jetzt informieren!},
  url          = {https://www.dinmedia.de/de/technische-regel/din-spec-92005/376619718},
  urldate      = {2025-04-07},
  address      = {Berlin},
  doi          = {10.31030/3521675},
  howpublished = {Online-Normdokument},
  note         = {Zugriff am 07.04.2025},
  keywords     = {internetdokument}
}


@book{EmanueleBorgonovo.2017,
  author       = {Emanuele Borgonovo},
  title        = {Sensitivity Analysis},
  year         = {2017},
  publisher    = {Springer Cham},
  series       = {International Series in Operations Research \& Management Science},
  url          = {https://link.springer.com/book/10.1007/978-3-319-52259-3?page=2#toc},
  urldate      = {2025-04-10},
  doi          = {10.1007/978-3-319-52259-3},
  keywords     = {buch},
  note         = {Zugriff am 10.04.2025}
}


@article{Gawlikowski2023,
  author = {Gawlikowski, Jakob and Tassi, Cedrique Rovile Njieutcheu and Ali, Mohsin and Lee, Jongseok and Humt, Matthias and Feng, Jianxiang and Kruspe, Anna and Triebel, Rudolph and Jung, Peter and Roscher, Ribana and Shahzad, Muhammad and Yang, Wen and Bamler, Richard and Zhu, Xiao Xiang},
  title = {A survey of uncertainty in deep neural networks},
  journal = {Artificial Intelligence Review},
  year = {2023},
  volume = {56},
  number = {S1},
  pages = {1513--1589},
  doi = {10.1007/s10462-023-10562-9},
  url = {https://doi.org/10.1007/s10462-023-10562-9},
  keywords = {zeitschriftenaufsatz, Bayesian deep neural networks, Calibration, Ensembles, Test-time augmentation, Uncertainty}
}


@article{Gopakumar.2024,
  author    = {Gopakumar, Vignesh and Gray, Ander and Oskarsson, Joel and Zanisi, Lorenzo and Pamela, Stanislas and Giles, Daniel and Kusner, Matt and Deisenroth, Marc Peter},
  title     = {Uncertainty Quantification of Surrogate Models using Conformal Prediction},
  year      = {2024},
  url       = {https://arxiv.org/abs/2408.09881},
  urldate   = {2025-04-10},
  keywords  = {zeitschriftenaufsatz},
  note      = {Preprint, Zugriff am 10.04.2025}
}


@book{H.BruggemannP.BremerS.Zischka.2024,
  author    = {H. Br{\"u}ggemann and P. Bremer and S. Zischka},
  year      = {2024},
  title     = {Grundlagen Qualit{\"a}tsmanagement: Von den Werkzeugen {\"u}ber Methoden zum TQM},
  edition   = {4},
  address   = {Wiesbaden},
  publisher = {Springer Vieweg},
  url       = {https://link.springer.com/book/10.1007/978-3-658-43563-9},
  urldate   = {2024-04-13},
  doi       = {10.1007/978-3-658-43563-9_13},
  keywords  = {buchmonographie}
}

@misc{henrio01,
  author    = {{Rienitz, Olaf}},
  title     = {Microsoft PowerPoint - GUM-Konzept},
  year      = {n.d.},
  howpublished = {Online-Präsentation, Physikalisch-Technische Bundesanstalt (PTB)},
  url       = {https://www.ptb.de/cms/fileadmin/internet/fachabteilungen/abteilung_3/3.1/mu/mu_rienitz_gum-messunsicherheit.pdf},
  urldate   = {2025-08-04},
  file      = {Microsoft PowerPoint - GUM-Konzept:Attachments/Microsoft PowerPoint - GUM-Konzept.pdf:application/pdf},
  keywords  = {internetdokument}
}


@inproceedings{Herd04082024,
  author    = {Herd, Benjamin and Burton, Simon},
  title     = {Can you trust your ML metrics? Using Subjective Logic to determine the true contribution of ML metrics for safety},
  booktitle = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
  editor    = {Hong, Jiman and Park, Juw Won and Przybyłek, Adam},
  pages     = {1579--1586},
  publisher = {ACM},
  address   = {New York, NY, USA},
  year      = {2024},
  isbn      = {9798400702433},
  doi       = {10.1145/3605098.3635966},
  file      = {Herd, Burton 04082024 - Can you trust your ML:Attachments/Herd, Burton 04082024 - Can you trust your ML.pdf:application/pdf},
  keywords  = {beitrag}
}


@proceedings{Hong.2024,
  year      = {2024},
  title     = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
  address   = {New York, NY, USA},
  publisher = {ACM},
  isbn      = {9798400702433},
  editor    = {Hong, Jiman and Park, Juw Won and Przybyłek, Adam},
  doi       = {10.1145/3605098},
  keywords  = {buchsammelwerk}
}


@misc{Hullermeier2021,
  abstract  = {The notion of uncertainty is of major importance in machine learning and constitutes a key element of machine learning methodology. In line with the statistical tradition, uncertainty has long been perceived as almost synonymous with standard probability and probabilistic predictions. Yet, due to the steadily increasing relevance of machine learning for practical applications and related issues such as safety requirements, new problems and challenges have recently been identified by machine learning scholars, and these problems may call for new methodological developments. In particular, this includes the importance of distinguishing between (at least) two different types of uncertainty, often referred to as aleatoric and epistemic. In this paper, we provide an introduction to the topic of uncertainty in machine learning as well as an overview of attempts so far at handling uncertainty in general and formalizing this distinction in particular.},
  author    = {H{\"u}llermeier, Eyke and Waegeman, Willem},
  year      = {2021},
  title     = {Aleatoric and epistemic uncertainty in machine learning: an introduction to concepts and methods},
  url       = {https://link.springer.com/article/10.1007/s10994-021-05946-3},
  pages     = {457--506},
  volume    = {110},
  number    = {3},
  issn      = {1573-0565},
  journal   = {Machine Learning},
  doi       = {10.1007/s10994-021-05946-3},
  file      = {H{\"u}llermeier, Waegeman 2021 - Aleatoric and epistemic uncertainty:Attachments/H{\"u}llermeier, Waegeman 2021 - Aleatoric and epistemic uncertainty.pdf:application/pdf},
  keywords  = {zeitschriftenaufsatz}
}


@misc{Informatik.13.04.2025,
  author    = {Informatik, Gesellschaft f{\"u}r},
  year      = {13.04.2025},
  title     = {Detail - Digital GreenTech},
  url       = {https://digitalgreentech.de/projekte/detail/i-sewer},
  urldate   = {13.04.2025},
  keywords  = {internetdokument}
}


@misc{JingYanXianYangHaiyanZhaoXiaoyuanLuoXinpingGuan.2021,
  abstract  = {This book presents cutting-edge results regarding localization, tracking, and formation for AUVs and discusses future research directions},
  author    = {{Jing Yan, Xian Yang, Haiyan Zhao, Xiaoyuan Luo, Xinping Guan}},
  year      = {2021},
  title     = {Autonomous Underwater Vehicles: Localization, Tracking, and Formation},
  url       = {https://link.springer.com/book/10.1007/978-981-16-6096-2},
  address   = {Singapore},
  urldate   = {07.04.2025},
  edition   = {1},
  number    = {1},
  series    = {Cognitive Intelligence and Robotics},
  doi       = {10.1007/978-981-16-6096-2},
  keywords  = {buchmonographie}
}


@article{JoaquinQuinoneroCandela.2005,
  author    = {{Joaquin Qui{\~n}onero-Candela} and {Carl Edward Rasmussen}},
  year      = {2005},
  title     = {A Unifying View of Sparse Approximate Gaussian Process Regression},
  url       = {https://www.jmlr.org/papers/v6/quinonero-candela05a.html},
  pages     = {1939--1959},
  volume    = {6},
  number    = {65},
  issn      = {1533-7928},
  journal   = {Journal of Machine Learning Research},
  file      = {Joaquin Qui{\~n}onero-Candela, Carl Edward Rasmussen 2005 - A Unifying View of Sparse:Attachments/Joaquin Qui{\~n}onero-Candela, Carl Edward Rasmussen 2005 - A Unifying View of Sparse.pdf:application/pdf},
  keywords  = {zeitschriftenaufsatz}
}


@article{JointCommitteeforGuidesinMetrology.2008,
  abstract  = {Propagation of distributions using a Monte Carlo method},
  author    = {{Joint Committee for Guides in Metrology}},
  year      = {2008},
  title     = {Evaluation of measurement data: Supplement 1 to the ``Guide to the expression of uncertainty in measurement'': Propagation of distributions using a Monte Carlo method​},
  url       = {https://www.bipm.org/documents/20126/2071204/JCGM_101_2008_E.pdf},
  urldate   = {04.08.2025},
  doi       = {10.59161/JCGM101-2008},
  file      = {Evaluation of measurement data - Supplement 1 to the GUM:Attachments/Evaluation of measurement data - Supplement 1 to the GUM.pdf:application/pdf},
  keywords  = {internetdokument}
}


@article{JointCommitteeforGuidesinMetrology.2008b,
  author    = {{Joint Committee for Guides in Metrology}},
  year      = {2008},
  title     = {Evaluation of measurement data -- Guide to the expression of uncertainty in measurement: GUM 1995 with minor corrections},
  url       = {https://www.bipm.org/documents/20126/2071204/JCGM_100_2008_E.pdf},
  urldate   = {04.08.2025},
  doi       = {10.59161/JCGM100-2008E},
  file      = {2008 (GUM 1995 with minor corrections - Evaluation of measurement data:Attachments/2008 (GUM 1995 with minor corrections - Evaluation of measurement data.pdf:application/pdf},
  keywords  = {internetdokument}
}


@article{Jurgens.,
  abstract  = {Trustworthy ML systems should not only return accurate predictions, but also a reliable representation of their uncertainty. Bayesian methods are commonly used to quantify both aleatoric and epistemic uncertainty, but alternative approaches, such as evidential deep learning methods, have become popular in recent years. The latter group of methods in essence extends empirical risk minimization (ERM) for predicting second-order probability distributions over outcomes, from which measures of epistemic (and aleatoric) uncertainty can be extracted. This paper presents novel theoretical insights of evidential deep learning, highlighting the difficulties in optimizing second-order loss functions and interpreting the resulting epistemic uncertainty measures. With a systematic setup that covers a wide range of approaches for classification, regression and counts, it provides novel insights into issues of identifiability and convergence in second-order loss minimization, and the relative (rather than absolute) nature of epistemic uncertainty measures.},
  author    = {J{\"u}rgens, Mira and Meinert, Nis and Bengs, Viktor and H{\"u}llermeier, Eyke and Waegeman, Willem},
  year      = {2024},
  title     = {Is Epistemic Uncertainty Faithfully Represented by Evidential Deep Learning Methods?},
  doi       = {https://doi.org/10.48550/arXiv.2402.09056},
  url       = {http://arxiv.org/pdf/2402.09056},
  journal   = {Proceedings of the 41st International Conference on Machine Learning (ICML)},
  file      = {J{\"u}rgens, Meinert et al. - Is Epistemic Uncertainty Faithfully Represented:Attachments/J{\"u}rgens, Meinert et al. - Is Epistemic Uncertainty Faithfully Represented.pdf:application/pdf},
  keywords  = {zeitschriftenaufsatz}
}


@article{Pfeffers2007,
  author    = {Ken Peffers and Tuure Tuunanen and Marcus A. Rothenberger and Samir Chatterjee},
  title     = {A Design Science Research Methodology for Information Systems Research},
  journal   = {Journal of Management Information Systems},
  volume    = {24},
  number    = {3},
  pages     = {45--77},
  year      = {2007},
  doi       = {10.2753/MIS0742-1222240302},
  keywords  = {zeitschriftenaufsatz}
}


@article{Kabir.,
  author    = {Kabir, H. DipuM. and Yu, Wenwu and Tang, Yanyan and He, Xiangjian and Lu, Huimin},
  title     = {Neural network-based uncertainty quantification: A survey of methodologies and applications},
  journal   = {IEEE Access},
  number    = {6},
  pages     = {36218--36234},
  doi       = {10.1109/ACCESS.2018.2853721},
  keywords  = {zeitschriftenaufsatz}
}


@book{Keely.2025,
  author    = {Keely, William and Mauceri, Steffen and Nelson, Robert and Laughner, Joshua and O'Dell, Christopher and Massie, Steven Thomas and Baker, David F. and Kiel, Matth{\"a}us and Lamminp{\"a}{\"a}, Otto and Hobbs, Jonathan M. and Chatterjee, Abhishek and Taylor, Tommy and Wennberg, Paul O. and Crowell, Sean and Stephens, Britton B. and Payne, Vivienne H.},
  year      = {2025},
  title     = {Uncertainty-aware Machine Learning Bias Correction and Filtering for OCO-2: Part 2},
  url       = {https://d197for5662m48.cloudfront.net/documents/publicationstatus/249039/preprint_pdf/67a8bfe1096bc8bea03e9522b475844e.pdf},
  urldate   = {13.04.2025},
  doi       = {10.22541/essoar.174164203.37422284/v1},
  file      = {67a8bfe1096bc8bea03e9522b475844e:Attachments/67a8bfe1096bc8bea03e9522b475844e.pdf:application/pdf},
  keywords  = {buchmonographie}
}


@misc{KooroshAslansefat.,
  author    = {{Koorosh Aslansefat}},
  title     = {Evidential Deep Learning and Reliability},
  url       = {https://www.kaggle.com/code/kooaslansefat/evidential-deep-learning-and-reliability},
  keywords  = {internetdokument}
}


@inproceedings{Liang.07202025,
  author    = {Liang, Daojun},
  title     = {DistPred: A Distribution-Free Probabilistic Inference Method for Regression and Forecasting},
  pages     = {753--764},
  publisher = {ACM},
  isbn      = {9798400712456},
  editor    = {Sun, Yizhou and Chierichetti, Flavio and Lauw, Hady W. and Perlich, Claudia and Tok, WeeHyong and Tomkins, Andrew},
  booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1},
  year      = {07202025},
  address   = {New York, NY, USA},
  doi       = {10.1145/3690624.3709286},
  file      = {Liang 07202025 - DistPred A Distribution-Free Probabilistic Inference:Attachments/Liang 07202025 - DistPred A Distribution-Free Probabilistic Inference.pdf:application/pdf},
  keywords  = {zeitschriftenaufsatz}
}


@misc{manchingal2025,
  author        = {Shireen Kudukkil Manchingal and Fabio Cuzzolin},
  title         = {Position: Epistemic Artificial Intelligence is Essential for Machine Learning Models to ‘Know When They Do Not Know’},
  year          = {2025},
  eprint        = {2505.04950v1},
  archivePrefix = {arXiv},
  primaryClass  = {cs.AI},
  url           = {https://arxiv.org/html/2505.04950v1},
  keywords      = {beitrag}
}


@misc{Nof2023,
  editor    = {Shimon Y. Nof},
  title     = {Springer Handbook of Automation},
  edition   = {2},
  publisher = {Springer},
  year      = {2023},
  address   = {Cham},
  isbn      = {978-3-030-83120-9},
  doi       = {10.1007/978-3-540-78831-7},
  keywords   = {buchsammelwerk}
}

@book{oberkampf2010,
  author    = {Oberkampf, William L. and Roy, Christopher J.},
  title     = {Verification and Validation in Scientific Computing},
  year      = {2010},
  publisher = {Cambridge University Press},
  address   = {New York},
  isbn      = {9780511760396},
  doi       = {10.1017/CBO9780511760396},
  url       = {https://www.cambridge.org/core/books/verification-and-validation-in-scientific-computing/05CA1F8F3CCB5AE5445FDF55239A0183},
  abstract  = {{\textquotedbl}Advances in scientific computing have made modelling and simulation an important part of the decision-making process in engineering, science, and public policy. This book provides a comprehensive and systematic development of the basic concepts, principles, and procedures for verification and validation of models and simulations. The emphasis is placed on models that are described by partial differential and integral equations and the simulations that result from their numerical solution. The methods described can be applied to a wide range of technical fields, from the physical sciences, engineering and technology and industry, through to environmental regulations and safety, product and plant safety, financial investing, and governmental regulations. This book will be genuinely welcomed by researchers, practitioners, and decision makers in a broad range of fields, who seek to improve the credibility and reliability of simulation results. It will also be appropriate either for university courses or for independent study{\textquotedbl}--},
  keywords   = {buchmonographie}
}


@article{Olivier.2021,
  author  = {Olivier, Shields {\&} Graham-Brady},
  title   = {Bayesian Neural Networks for Uncertainty Quantification in Data-Driven Materials Modeling},
  journal = {Computer Methods in Applied Mechanics and Engineering},
  year    = {2021},
  number  = {386},
  doi     = {10.1016/j.cma.2021.114079},
  keywords = {zeitschriftenaufsatz}
}


@inproceedings{pandey2023learn,
  author       = {Deep Shankar Pandey and Qi Yu},
  title        = {Learn to Accumulate Evidence from All Training Samples: Theory and Practice},
  booktitle    = {Proceedings of the 40th International Conference on Machine Learning (ICML)},
  series       = {Proceedings of Machine Learning Research},
  volume       = {202},
  pages        = {26963--26989},
  year         = {2023},
  publisher    = {PMLR},
  address      = {Baltimore, MD, USA},
  doi          = {10.5555/3618408.3619531},
  url          = {https://proceedings.mlr.press/v202/pandey23a/pandey23a.pdf},
  urldate      = {2025-04-10},
  keywords     = {zeitschriftenaufsatz, evidential deep learning},
}


@misc{Pandey.30.11.2022,
  author    = {Pandey, Deep Shankar and Yu, Qi},
  title     = {Evidential Conditional Neural Processes},
  url       = {http://arxiv.org/pdf/2212.00131},
  abstract  = {The Conditional Neural Process (CNP) family of models offer a promising direction to tackle few-shot problems by achieving better scalability and competitive predictive performance. However, the current CNP models only capture the overall uncertainty for the prediction made on a target data point. They lack a systematic fine-grained quantification on the distinct sources of uncertainty that are essential for model training and decision-making under the few-shot setting. We propose Evidential Conditional Neural Processes (ECNP), which replace the standard Gaussian distribution used by CNP with a much richer hierarchical Bayesian structure through evidential learning to achieve epistemic-aleatoric uncertainty decomposition. The evidential hierarchical structure also leads to a theoretically justified robustness over noisy training tasks. Theoretical analysis on the proposed ECNP establishes the relationship with CNP while offering deeper insights on the roles of the evidential parameters. Extensive experiments conducted on both synthetic and real-world data demonstrate the effectiveness of our proposed model in various few-shot settings.},
  file      = {Pandey, Yu 30.11.2022 - Evidential Conditional Neural Processes:Attachments/Pandey, Yu 30.11.2022 - Evidential Conditional Neural Processes.pdf:application/pdf},
  keywords   = {internetdokument}
}


@misc{PhilippGrimm.2024,
  author    = {{Philipp Grimm} and {Digital Green Tech}},
  title     = {i-SEWER-Projekt: Die nächste Generation der Kanalnetzsteuerung},
  year      = {2024},
  url       = {https://digitalgreentech.de/projekte/detail/i-sewer},
  urldate   = {2025-04-13},
  keywords   = {internetdokument}
}


@proceedings{Rasmussen.2004,
  title     = {Gaussian Processes in Machine Learning},
  year      = {2004},
  editor    = {{Bousquet, O., von Luxburg, U., Rätsch, G.}},
  publisher = {Springer},
  address   = {Berlin, Heidelberg},
  series    = {Advanced Lectures on Machine Learning},
  volume    = {3176},
  isbn      = {978-3-540-28650-9},
  url       = {https://link.springer.com/chapter/10.1007/978-3-540-28650-9_4},
  urldate   = {2025-04-07},
  doi       = {10.1007/978-3-540-28650-9_4},
  keywords   = {buchsammelwerk}
}


@inproceedings{Rasmussen.2004b,
  author    = {Rasmussen, Carl Edward},
  title     = {Gaussian Processes in Machine Learning},
  booktitle = {Gaussian Processes in Machine Learning},
  editor    = {{Bousquet, O., von Luxburg, U., Rätsch, G.}},
  series    = {Advanced Lectures on Machine Learning},
  publisher = {Springer},
  address   = {Berlin, Heidelberg},
  year      = {2004},
  pages     = {63--71},
  isbn      = {978-3-540-28650-9},
  url       = {https://link.springer.com/chapter/10.1007/978-3-540-28650-9_4},
  doi       = {10.1007/978-3-540-28650-9_4},
  abstract  = {We give a basic introduction to Gaussian Process regression models. We focus on understanding the role of the stochastic process and how it is used to define a distribution over functions. We present the simple equations for incorporating training data and examine...},
  file      = {Rasmussen 2004 - Gaussian Processes in Machine Learning:Attachments/Rasmussen 2004 - Gaussian Processes in Machine Learning.pdf:application/pdf},
  keywords   = {buchsammelwerk}
}


@phdthesis{Riedmaier.,
  author    = {Riedmaier, Stefan},
  title     = {Model Validation and Uncertainty Aggregation for Safety Assessment of Automated Vehicles},
  school    = {{Technische Universität München}},
  year      = {2022},
  address   = {München},
  type      = {Phd-Thesis},
  url       = {https://mediatum.ub.tum.de/doc/1615375/1615375.pdf},
  urldate   = {2025-04-07},
  abstract  = {This dissertation presents a methodology for validation of simulation models to ensure virtual safeguarding of automated vehicles. The methodology quantifies model uncertainties compared to real experiments and predicts them by a data-driven approach to the virtual safeguarding scenarios. This provides statistical guarantees for reliable decision making. The methodology is first introduced generically and then configured, implemented, and evaluated specifically for safeguarding.},
  file      = {Riedmaier - Model Validation and Uncertainty Aggregation:Attachments/Riedmaier - Model Validation and Uncertainty Aggregation.pdf:application/pdf},
  keywords   = {buch}
}


@article{Riedmaier.2021,
  author  = {Riedmaier, Stefan and Danquah, Benedikt and Schick, Bernhard and Diermeyer, Frank},
  title   = {Unified Framework and Survey for Model Verification, Validation and Uncertainty Quantification},
  journal = {Archives of Computational Methods in Engineering},
  year    = {2021},
  volume  = {28},
  number  = {4},
  pages   = {2655--2688},
  issn    = {1886-1784},
  doi     = {10.1007/s11831-020-09473-7},
  url     = {https://link.springer.com/article/10.1007/s11831-020-09473-7},
  abstract = {Simulation is becoming increasingly important in the development, testing and approval process in many areas of engineering, ranging from finite element models to highly complex cyber-physical systems such as autonomous cars. Simulation must be accompanied by model verification, validation and uncertainty quantification (VV{\&}UQ) activities to assess the inherent errors and uncertainties of each simulation model. However, the VV{\&}UQ methods differ greatly between the application areas. In general, a major challenge is the aggregation of uncertainties from calibration and validation experiments to the actual model predictions under new, untested conditions. This is especially relevant due to high extrapolation uncertainties, if the experimental conditions differ strongly from the prediction conditions, or if the output quantities required for prediction cannot be measured during the experiments. In this paper, both the heterogeneous VV{\&}UQ landscape and the challenge of aggregation will be addressed with a novel modular and unified framework to enable credible decision making based on simulation models. This paper contains a comprehensive survey of over 200 literature sources from many application areas and embeds them into the unified framework. In addition, this paper analyzes and compares the VV{\&}UQ methods and the application areas in order to identify strengths and weaknesses and to derive further research directions. The framework thus combines a variety of VV{\&}UQ methods, so that different engineering areas can benefit from new methods and combinations. Finally, this paper presents a procedure to select a suitable method from the framework for the desired application.},
  file    = {Riedmaier, Danquah et al. 2021 - Unified Framework and Survey:Attachments/Riedmaier, Danquah et al. 2021 - Unified Framework and Survey.pdf:application/pdf},
  keywords = {zeitschriftenaufsatz}
}


@incollection{S.BurtonB.HerdJ.V.Zacchi.,
  author    = {{S. Burton, B. Herd, J.-V. Zacchi}},
  title     = {Uncertainty-Aware Evaluation of Quantitative ML Safety Requirements},
  booktitle = {Computer Safety, Reliability, and Security. SAFECOMP 2024},
  pages     = {391--404},
  url       = {https://dl.acm.org/doi/10.1007/978-3-031-68738-9_31},
  urldate   = {2025-04-13},
  doi       = {10.1007/978-3-031-68738-9_31},
  keywords   = {buchsammelwerk}
}


@misc{Schmitt.13.10.2022,
  author    = {Schmitt, Marvin and Radev, Stefan T. and Bürkner, Paul-Christian},
  title     = {Meta-Uncertainty in Bayesian Model Comparison},
  date      = {13.10.2022},
  url       = {http://arxiv.org/pdf/2210.07278},
  abstract  = {Bayesian model comparison (BMC) offers a principled probabilistic approach to study and rank competing models. In standard BMC, we construct a discrete probability distribution over the set of possible models, conditional on the observed data of interest. These posterior model probabilities (PMPs) are measures of uncertainty, but -- when derived from a finite number of observations -- are also uncertain themselves. In this paper, we conceptualize distinct levels of uncertainty which arise in BMC. We explore a fully probabilistic framework for quantifying meta-uncertainty, resulting in an applied method to enhance any BMC workflow. Drawing on both Bayesian and frequentist techniques, we represent the uncertainty over the uncertain PMPs via meta-models which combine simulated and observed data into a predictive distribution for PMPs on new data. We demonstrate the utility of the proposed method in the context of conjugate Bayesian regression, likelihood-based inference with Markov chain Monte Carlo, and simulation-based inference with neural networks.},
  file      = {Schmitt, Radev et al. 13.10.2022 - Meta-Uncertainty in Bayesian Model Comparison:Attachments/Schmitt, Radev et al. 13.10.2022 - Meta-Uncertainty in Bayesian Model Comparison.pdf:application/pdf},
  keywords   = {internetdokument}
}


@book{Schmitt.2020,
  author    = {Schmitt, Robert H.},
  title     = {Potenziale Künstlicher Intelligenz für die Qualitätswissenschaft},
  year      = {2020},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-662-60691-9},
  doi       = {10.1007/978-3-662-60692-6},
  file      = {Schmitt 2020 - Potenziale Künstlicher Intelligenz:Attachments/Schmitt 2020 - Potenziale Künstlicher Intelligenz.pdf:application/pdf},
  keywords   = {buchmonographie}
}


@misc{Schreck2023,
  author    = {Schreck, John S. and Gagne, David John and Becker, Charlie and Chapman, William E. and Elmore, Kim and {Da Fan} and Gantos, Gabrielle and Kim, Eliot and Kimpara, Dhamma and Martin, Thomas and Molina, Maria J. and Przybylo, Vanessa M. and Radford, Jacob and Saavedra, Belen and Willson, Justin and Wirz, Christopher},
  title     = {Evidential Deep Learning: Enhancing Predictive Uncertainty Estimation for Earth System Science Applications},
  date      = {2024},
  number    = {4},
  url       = {http://arxiv.org/pdf/2309.13207},
  doi       = {10.1175/AIES-D-23-0093.1},
  abstract  = {Robust quantification of predictive uncertainty is critical for understanding factors that drive weather and climate outcomes. Ensembles provide predictive uncertainty estimates and can be decomposed physically, but both physics and machine learning ensembles are computationally expensive. Parametric deep learning can estimate uncertainty with one model by predicting the parameters of a probability distribution but do not account for epistemic uncertainty.. Evidential deep learning, a technique that extends parametric deep learning to higher-order distributions, can account for both aleatoric and epistemic uncertainty with one model. This study compares the uncertainty derived from evidential neural networks to those obtained from ensembles. Through applications of classification of winter precipitation type and regression of surface layer fluxes, we show evidential deep learning models attaining predictive accuracy rivaling standard methods, while robustly quantifying both sources of uncertainty. We evaluate the uncertainty in terms of how well the predictions are calibrated and how well the uncertainty correlates with prediction error. Analyses of uncertainty in the context of the inputs reveal sensitivities to underlying meteorological processes, facilitating interpretation of the models. The conceptual simplicity, interpretability, and computational efficiency of evidential neural networks make them highly extensible, offering a promising approach for reliable and practical uncertainty quantification in Earth system science modeling. In order to encourage broader adoption of evidential deep learning in Earth System Science, we have developed a new Python package, MILES-GUESS (this https URL), that enables users to train and evaluate both evidential and ensemble deep learning.},
  file      = {Schreck, Gagne et al. 2023 - Evidential Deep Learning:Attachments/Schreck, Gagne et al. 2023 - Evidential Deep Learning.pdf:application/pdf},
  keywords   = {internetdokument}
}


@book{SpringerLink.12.04.2025,
  editor    = {{Shimon Y. Nof}},
  title     = {Springer Handbook of Automation},
  edition   = {2.},
  publisher = {Springer Nature Switzerland AG},
  year      = {2023},
  address   = {Cham},
  series    = {Springer Handbooks},
  isbn      = {978-3-030-96728-4},
  doi       = {10.1007/978-3-030-96729-1},
  url       = {https://link.springer.com/book/10.1007/978-3-030-96729-1},
  urldate   = {2025-04-12},
  abstract  = {Thoroughly updated new edition provides the most advanced, comprehensive, and balanced coverage of the technical and engineering aspects of automation},
  keywords   = {buchmonographie}
}


@article{Stankiewicz.2021,
  author  = {Stankiewicz, P. and Tan, Y. T. and Kobilarov, M.},
  title   = {Adaptive Sampling with an Autonomous Underwater Vehicle in Static Marine Environments},
  journal = {Journal of Field Robotics},
  year    = {2021},
  number  = {38},
  pages   = {572--597},
  doi     = {10.1002/rob.22005},
  keywords = {zeitschriftenaufsatz}
}


@book{StevenL.BruntonJ.NathanKutz.2022,
  author     = {{Steven L. Brunton, J. Nathan Kutz}},
  title      = {Data-Driven Science and Engineering: Machine Learning, Dynamical Systems, and Control},
  year       = {2022},
  edition    = {2},
  publisher  = {Cambridge University Press},
  address    = {Cambridge, United Kingdom},
  isbn       = {9781009098489},
  doi        = {10.1017/9781009089517},
  url        = {https://www.cambridge.org/highereducation/books/data-driven-science-and-engineering/6F9A730B7A9A9F43F68CF21A24BEC339#overview},
  urldate    = {2025-04-10},
  keywords    = {buchmonographie}
}


@inproceedings{Sudret.31920173242017,
  author    = {Sudret, Bruno and Marelli, Stefano and Wiart, Joe},
  title     = {Surrogate Models for Uncertainty Quantification: An Overview},
  booktitle = {Surrogate Models for Uncertainty Quantification},
  editor    = {{Bruno Sudret}},
  publisher = {IEEE},
  year      = {2017},
  pages     = {793--797},
  isbn      = {978-8-8907-0187-0},
  url       = {https://ieeexplore.ieee.org/document/7928679/},
  urldate   = {2025-04-10},
  doi       = {10.23919/EuCAP.2017.7928679},
  keywords   = {buchsammelwerk}
}


@proceedings{Sun.07202025,
  title     = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1},
  editor    = {Sun, Yizhou and Chierichetti, Flavio and Lauw, Hady W. and Perlich, Claudia and Tok, WeeHyong and Tomkins, Andrew},
  year      = {2025},
  address   = {New York, NY, USA},
  publisher = {ACM},
  isbn      = {9798400712456},
  doi       = {10.1145/3690624},
  keywords   = {buchsammelwerk}
}


@misc{Tik.12.04.2025,
  author    = {Tik},
  title     = {Surrogatsmodellierung | Institut für Technische und Numerische Mechanik | Universität Stuttgart},
  year      = {2025},
  url       = {https://www.itm.uni-stuttgart.de/forschung/surrogatsmodellierung/},
  urldate   = {2025-04-13},
  abstract  = {Physik-informierte {\&} Datenbasierte Surrogatsmodellierung},
  keywords   = {internetdokument}
}


@book{TiloPfeiffer.2021,
  author    = {{Tilo Pfeiffer} and Robert Schmitt},
  title     = {Masing Handbuch Qualitätsmanagement},
  year      = {2021},
  publisher = {Carl Hanser Verlag GmbH \& Co. KG},
  isbn      = {978-3-446-46621-0},
  doi       = {10.1007/978-3-446-46621-0},
  url       = {https://www.springerprofessional.de/masing-handbuch-qualitaets-management/26172540?tocPage=1},
  urldate   = {2025-04-10},
  keywords   = {buchmonographie}
}


@misc{Tripathy.27.02.2019,
  author    = {Tripathy, Rohit and Bilionis, Ilias},
  title     = {Deep Active Subspaces: A Scalable Method for High-Dimensional Uncertainty Propagation},
  date      = {2019-02-27},
  url       = {http://arxiv.org/pdf/1902.10527},
  urldate   = {2025-04-10},
  abstract  = {A problem of considerable importance within the field of uncertainty quantification (UQ) is the development of efficient methods for the construction of accurate surrogate models. Such efforts are particularly important to applications constrained by high-dimensional uncertain parameter spaces. The difficulty of accurate surrogate modeling in such systems, is further compounded by data scarcity brought about by the large cost of forward model evaluations. Traditional response surface techniques, such as Gaussian process regression (or Kriging) and polynomial chaos are difficult to scale to high dimensions. To make surrogate modeling tractable in expensive high-dimensional systems, one must resort to dimensionality reduction of the stochastic parameter space. A recent dimensionality reduction technique that has shown great promise is the method of `active subspaces'. The classical formulation of active subspaces, unfortunately, requires gradient information from the forward model - often impossible to obtain. In this work, we present a simple, scalable method for recovering active subspaces in high-dimensional stochastic systems, without gradient-information that relies on a reparameterization of the orthogonal active subspace projection matrix, and couple this formulation with deep neural networks. We demonstrate our approach on synthetic and real world datasets and show favorable predictive comparison to classical active subspaces.},
  file      = {Tripathy, Bilionis 27.02.2019 - Deep active subspaces:Attachments/Tripathy, Bilionis 27.02.2019 - Deep active subspaces.pdf:application/pdf},
  keywords   = {internetdokument}
}


@article{Tunkiel.2020,
  author  = {Tunkiel, Andrzej T. and Sui, Dan and Wiktorski, Tomasz},
  title   = {Data-driven Sensitivity Analysis of Complex Machine Learning Models: A Case Study of Directional Drilling},
  journal = {Journal of Petroleum Science and Engineering},
  year    = {2020},
  volume  = {195},
  pages   = {107630},
  issn    = {09204105},
  doi     = {10.1016/j.petrol.2020.107630},
  file    = {Tunkiel, Sui et al. 2020 - Data-driven sensitivity analysis of complex:Attachments/Tunkiel, Sui et al. 2020 - Data-driven sensitivity analysis of complex.pdf:application/pdf},
  keywords = {zeitschriftenaufsatz}
}


@article{Ulmer2023,
  author = {Dennis Ulmer and Christian Hardmeier and Jes Frellsen},
  title = {Prior and Posterior Networks: A Survey on Evidential Deep Learning Methods For Uncertainty Estimation},
  journal = {Transactions on Machine Learning Research},
  year = {2023},
  volume = {4},
  number = {1},
  pages = {1--47},
  doi = {10.48550/arXiv.2110.03051},
  url = {https://www.jmlr.org/tmlr/papers/volume4/ulmer23a/ulmer23a.pdf},
  keywords = {beitrag, Evidential Deep Learning, Uncertainty Estimation, Deep Neural Networks, Prior and Posterior Networks, Classification, Regression}
}


@misc{UQpyProjectTeam.2024,
  author       = {{Olivier, A., Giovanis, D.G., Aakash, B.S., Chauhan, M., Vandanapu, L., Shields, M.D.}},
  title        = {UQpy: A General Purpose Python Package and Development Environment for Uncertainty Quantification},
  year         = {2024},
  howpublished = {Software},
  url          = {https://github.com/SURGroup/UQpy},
  urldate      = {2025-04-10},
  doi          = {10.1016/j.jocs.2020.101204},
  keywords      = {internetdokument}
}


@misc{WeichengCuiShixiaoFuZhiqiangHu.07.04.2025,
  author    = {{Weicheng Cui, Shixiao Fu, Zhiqiang Hu}},
  title     = {Encyclopedia of Ocean Engineering},
  year      = {2020},
  url       = {https://link.springer.com/referencework/10.1007/978-981-10-6963-5},
  address   = {Singapore},
  urldate   = {2025-04-07},
  doi       = {10.1007/978-981-10-6963-5},
  keywords   = {buchsammelwerk}
}


@article{Y.LiD.RugamerB.BischlM.Rezaei.2025,
  author  = {{Y. Li, D. Rügamer, B. Bischl, M. Rezaei}},
  title   = {Calibrating LLMs With Information-Theoretic Evidential Deep Learning},
  journal = {The Thirteenth International Conference On Learning Representations},
  year    = {2025},
  url     = {https://openreview.net/forum?id=YcML3rJl0N},
  urldate = {2025-04-14},
  keywords = {zeitschriftenaufsatz}
}


@article{YajieBaoJavadMohammadpourVelni.2024,
  author  = {{Yajie Bao, Javad Mohammadpour Velni}},
  title   = {Adaptive Uncertainty Quantification For Scenario Based Control Using Meta-Learning Of Bayesian Neural Networks},
  journal = {IFAC-PapersOnLine},
  year    = {2024},
  volume  = {58},
  pages   = {486--491},
  url     = {https://www.sciencedirect.com/science/article/pii/S240589632500093X},
  urldate = {2025-04-10},
  doi     = {10.1016/j.ifacol.2025.01.093},
  keywords = {zeitschriftenaufsatz}
}


@article{YarinGalandZoubinGhahramani.2016,
  author  = {{Yarin Gal and Zoubin Ghahramani}},
  title   = {Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning},
  journal = {Proceedings of The 33rd International Conference On Machine Learning},
  year    = {2016},
  pages   = {1050--1059},
  url     = {https://proceedings.mlr.press/v48/gal16.html},
  urldate = {2025-04-14},
  keywords = {zeitschriftenaufsatz}
}


@phdthesis{YehorYudinM.Sc..2024,
  author    = {{Yehor Yudin, M. Sc.}},
  title     = {Uncertainty Quantification and Machine Learning Surrogate Models for Multi-Scale High-Performance-Computing Plasma Physics Turbulent Transport Simulations},
  year      = {2024},
  url       = {https://nbn-resolving.org/urn:nbn:de:bvb:91-diss-20240812-1739952-1-7},
  urldate   = {2025-04-08},
  pages     = {138},
  file      = {1739952:Attachments/1739952.pdf:application/pdf},
  keywords   = {buch}
}


@article{Kabir2020,
  author    = {H. Dipu M. Kabir and Wenwu Yu and Yanyan Tang and Xiangjian He and Huimin Lu},
  title     = {Neural network-based uncertainty quantification: A survey of methodologies and applications},
  journal   = {IEEE Access},
  year      = {2020},
  volume    = {6},
  pages     = {36218--36234},
}


@article{Olivier2021,
  author    = {Shields Olivier and Graham-Brady},
  title     = {Bayesian neural networks for uncertainty quantification in data-driven materials modeling},
  journal   = {Computer Methods in Applied Mechanics and Engineering},
  year      = {2021},
  volume    = {386},
}


@article{Stankiewicz2021,
  author    = {P. Stankiewicz and Y. T. Tan and M. Kobilarov},
  title     = {Adaptive sampling with an autonomous underwater vehicle in static marine environments},
  journal   = {Journal of Field Robotics},
  year      = {2021},
  volume    = {38},
  pages     = {572--597},
}


@misc{Gopakumar2024,
  author    = {Vignesh Gopakumar and Ander Gray and Joel Oskarsson and Lorenzo Zanisi and Stanislas Pamela and Daniel Giles and Matt Kusner and Marc Peter Deisenroth},
  title     = {Uncertainty Quantification of Surrogate Models using Conformal Prediction},
  year      = {2024},
  howpublished = {\url{https://arxiv.org/abs/2408.09881}},
}


@article{Choi2017,
  author    = {Y. Choi and Y. Hwang},
  title     = {Predictive Uncertainty Estimation for Deep Neural Networks},
  journal   = {Journal of Machine Learning Research},
  year      = {2017},
  volume    = {18},
  pages     = {1--21},
}


@misc{Deng2023,
  author       = {Danruo Deng and Guangyong Chen and Yang Yu and Furui Liu and Pheng-Ann Heng},
  title        = {Uncertainty Estimation by Fisher Information-based Evidential Deep Learning},
  year         = {2023},
  url          = {https://arxiv.org/abs/2303.02045},
  note         = {Abgerufen: 2025-06-24},
  keywords     = {Fisher Information, Evidential Deep Learning, Unsicherheitsschätzung, PAC-Bayesian, internetdokument}
}


@misc{krause2025,
  author = {Andreas Krause and Jonas Hübotter},
  title = {Probabilistic Artificial Intelligence},
  year = {2025},
  eprint = {2502.05244},
  archivePrefix = {arXiv},
  primaryClass = {cs.AI},
  url = {https://arxiv.org/abs/2502.05244},
  keywords = {internetdokument}
}


@article{Schreck2023,
  author       = {Schreck, John S. and Gagne, David John and Becker, Charlie and Chapman, William E. and Elmore, Kim and Da Fan and Gantos, Gabrielle and Kim, Eliot and Kimpara, Dhamma and Martin, Thomas and Molina, Maria J. and Przybylo, Vanessa M. and Radford, Jacob and Saavedra, Belen and Willson, Justin and Wirz, Christopher},
  title        = {Evidential Deep Learning: Enhancing Predictive Uncertainty Estimation for Earth System Science Applications},
  journal      = {Earth System Science},
  year         = {2023},
  volume       = {4},
  number       = {4},
  keywords     = {zeitschriftenaufsatz, evidential deep learning, uncertainty estimation, earth system science, predictive modeling},
  note         = {Accessed: 2025-04-24}
}


@article{Lanini2024,
  author = {Lanini, J. and Huynh, M. T. D. and Scebba, G. and Schneider, N. and Rodríguez-Pérez, R.},
  title = {UNIQUE: A Framework for Uncertainty Quantification Benchmarking},
  journal = {J. Chem. Inf. Model.},
  year = {2024},
  volume = {64},
  number = {22},
  pages = {8379--8386},
  doi = {10.1021/acs.jcim.4c01578},
  url = {https://doi.org/10.1021/acs.jcim.4c01578},
  eprint = {2024 Nov 14},
  pmid = {39542432},
  pmcid = {PMC11600502},
  keywords = {zeitschriftenaufsatz, Unsicherheitsquantifizierung, Benchmarking, Computational Chemistry, Maschinelles Lernen, Modellierung}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Software
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@misc{DuckDBDevelopers.2024,
  author       = {{DuckDB Developers}},
  title        = {DuckDB},
  year         = {2024},
  howpublished = {Software},
  url          = {https://duckdb.org/},
  urldate      = {2025-04-10},
  keywords     = {software}
}

@misc{EdlPytorchDevelopers.2024,
  author       = {{EDL PyTorch Developers}},
  title        = {EDL PyTorch},
  year         = {2024},
  howpublished = {Software},
  url          = {https://github.com/EDL-PyTorch/EDL},
  urldate      = {2025-04-10},
  keywords     = {software}
}

@misc{LoguruDevelopers.2024,
  author       = {{Loguru Developers}},
  title        = {Loguru},
  year         = {2024},
  howpublished = {Software},
  url          = {https://github.com/Delgan/loguru},
  urldate      = {2025-04-10},
  keywords     = {software}
}

@misc{MatplotlibDevelopers.2024,
  author       = {{Matplotlib Developers}},
  title        = {Matplotlib},
  year         = {2024},
  howpublished = {Software},
  url          = {https://matplotlib.org/},
  urldate      = {2025-04-10},
  keywords     = {software}
}

@misc{NotebookDevelopers.2024,
  author       = {{Jupyter Notebook Developers}},
  title        = {Jupyter Notebook},
  year         = {2024},
  howpublished = {Software},
  url          = {https://jupyter.org/},
  urldate      = {2025-04-10},
  keywords     = {software}
}

@misc{NumpyDevelopers.2024,
  author       = {{NumPy Developers}},
  title        = {NumPy},
  year         = {2024},
  howpublished = {Software},
  url          = {https://numpy.org/},
  urldate      = {2025-04-10},
  keywords     = {software}
}

@misc{OpenpyxlDevelopers.2024,
  author       = {{Openpyxl Developers}},
  title        = {Openpyxl},
  year         = {2024},
  howpublished = {Software},
  url          = {https://openpyxl.readthedocs.io/},
  urldate      = {2025-04-10},
  keywords     = {software}
}

@misc{PandasDevelopers.2024,
  author       = {{Pandas Developers}},
  title        = {Pandas},
  year         = {2024},
  howpublished = {Software},
  url          = {https://pandas.pydata.org/},
  urldate      = {2025-04-10},
  keywords     = {software}
}

@misc{ProperscoringDevelopers.2024,
  author       = {{Properscoring Developers}},
  title        = {Properscoring},
  year         = {2024},
  howpublished = {Software},
  url          = {https://github.com/properscoring/properscoring},
  urldate      = {2025-04-10},
  keywords     = {software}
}

@misc{PyroPplDevelopers.2024,
  author       = {{Pyro PPL Developers}},
  title        = {Pyro PPL},
  year         = {2024},
  howpublished = {Software},
  url          = {https://pyro.ai/},
  urldate      = {2025-04-10},
  keywords     = {software}
}

@misc{PytestDevelopers.2024,
  author       = {{Pytest Developers}},
  title        = {Pytest},
  year         = {2024},
  howpublished = {Software},
  url          = {https://pytest.org/},
  urldate      = {2025-04-10},
  keywords     = {software}
}

@misc{RuffDevelopers.2024,
  author       = {{Ruff Developers}},
  title        = {Ruff},
  year         = {2024},
  howpublished = {Software},
  url          = {https://github.com/charliermarsh/ruff},
  urldate      = {2025-04-10},
  keywords     = {software}
}

@misc{ScikitLearnDevelopers.2024,
  author       = {{Scikit-learn Developers}},
  title        = {Scikit-learn},
  year         = {2024},
  howpublished = {Software},
  url          = {https://scikit-learn.org/},
  urldate      = {2025-04-10},
  keywords     = {software}
}

@misc{ScipyDevelopers.2024,
  author       = {{SciPy Developers}},
  title        = {SciPy},
  year         = {2024},
  howpublished = {Software},
  url          = {https://scipy.org/},
  urldate      = {2025-04-10},
  keywords     = {software}
}

@misc{SeabornDevelopers.2024,
  author       = {{Seaborn Developers}},
  title        = {Seaborn},
  year         = {2024},
  howpublished = {Software},
  url          = {https://seaborn.pydata.org/},
  urldate      = {2025-04-10},
  keywords     = {software}
}

@misc{SphinxDevelopers.2024,
  author       = {{Sphinx Developers}},
  title        = {Sphinx},
  year         = {2024},
  howpublished = {Software},
  url          = {https://www.sphinx-doc.org/},
  urldate      = {2025-04-10},
  keywords     = {software}
}

@misc{TensorflowDevelopers.2024,
  author       = {{TensorFlow Developers}},
  title        = {TensorFlow},
  year         = {2024},
  howpublished = {Software},
  url          = {https://www.tensorflow.org/},
  urldate      = {2025-04-10},
  keywords     = {software}
}

@misc{TorchDevelopers.2024,
  author       = {{PyTorch Developers}},
  title        = {PyTorch},
  year         = {2024},
  howpublished = {Software},
  url          = {https://pytorch.org/},
  urldate      = {2025-04-10},
  keywords     = {software}
}

@misc{TorchmetricsDevelopers.2024,
  author       = {{Torchmetrics Developers}},
  title        = {Torchmetrics},
  year         = {2024},
  howpublished = {Software},
  url          = {https://torchmetrics.readthedocs.io/},
  urldate      = {2025-04-10},
  keywords     = {software}
}

@misc{TorchvisionDevelopers.2024,
  author       = {{Torchvision Developers}},
  title        = {Torchvision},
  year         = {2024},
  howpublished = {Software},
  url          = {https://pytorch.org/vision/},
  urldate      = {2025-04-10},
  keywords     = {software}
}

@misc{XlrdDevelopers.2024,
  author       = {{Xlrd Developers}},
  title        = {Xlrd},
  year         = {2024},
  howpublished = {Software},
  url          = {https://xlrd.readthedocs.io/},
  urldate      = {2025-04-10},
  keywords     = {software}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Datensätze
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@misc{BostonHousing2013,
  author       = {K. Bache and M. Lichman},
  title        = {Boston Housing Data},
  year         = {2013},
  howpublished = {Dataset},
  url          = {https://archive.ics.uci.edu/ml/datasets/Housing},
  note         = {UCI Machine Learning Repository},
  doi          = {10.24432/C5K31K},
  keywords     = {dataset, housing, regression, UCI Machine Learning Repository}
}

@misc{ConditionBasedMaintenanceOfNavalPropulsionPlants2014,
  author       = {Coraddu, A. and Oneto, L. and Ghio, A. and Savio, S. and Anguita, D. and Figari, M.},
  title        = {Condition Based Maintenance of Naval Propulsion Plants},
  year         = {2014},
  howpublished = {Dataset},
  url          = {https://doi.org/10.24432/C5K31K},
  note         = {UCI Machine Learning Repository},
  doi          = {10.24432/C5K31K},
  keywords     = {dataset, UCI Machine Learning Repository}
}

@misc{CombinedCyclePowerPlant2014,
  author       = {Tfekci, Pnar and Kaya, Heysem},
  title        = {Combined Cycle Power Plant},
  year         = {2014},
  howpublished = {UCI Machine Learning Repository},
  url          = {https://doi.org/10.24432/C5002N},
  note         = {DOI: https://doi.org/10.24432/C5002N},
  keywords     = {dataset, power plant, energy, UCI Machine Learning Repository}
}

@misc{ConcreteCompressiveStrength1998,
  author       = {Yeh, I-Cheng},
  title        = {Concrete Compressive Strength},
  year         = {1998},
  howpublished = {UCI Machine Learning Repository},
  url          = {https://doi.org/10.24432/C5PK67},
  note         = {DOI: https://doi.org/10.24432/C5PK67},
  keywords     = {dataset, concrete, strength, UCI Machine Learning Repository}
}

@misc{EnergyEfficiency2012,
  author       = {Tsanas, Athanasios and Xifara, Angeliki},
  title        = {Energy Efficiency},
  year         = {2012},
  howpublished = {UCI Machine Learning Repository},
  url          = {https://doi.org/10.24432/C51307},
  note         = {DOI: https://doi.org/10.24432/C51307},
  keywords     = {dataset, energy efficiency, UCI Machine Learning Repository}
}

@misc{Fisher1936,
  author       = {R. A. Fisher},
  title        = {The Iris Dataset},
  year         = {1936},
  howpublished = {Dataset},
  url          = {https://archive.ics.uci.edu/ml/datasets/iris},
  note         = {UCI Machine Learning Repository},
  keywords     = {dataset, iris, classification, UCI Machine Learning Repository}
}

@misc{Cortez2009,
  author       = {P. Cortez and A. Cerdeira and F. Almeida and T. Matos and J. Reis},
  title        = {Wine Quality Dataset},
  year         = {2009},
  howpublished = {Dataset},
  url          = {https://archive.ics.uci.edu/ml/datasets/wine+quality},
  note         = {UCI Machine Learning Repository},
  keywords     = {dataset, wine, classification, UCI Machine Learning Repository}
}

@misc{Gains2024,
  author       = {Unbekannter Autor},
  title        = {Protein Data},
  year         = {2024},
  howpublished = {Dataset},
  url          = {https://archive.ics.uci.edu/dataset/154/protein%2Bdata},
  note         = {UCI Machine Learning Repository. DOI: https://doi.org/10.24432/C5N88K},
  keywords     = {dataset, protein, bioinformatics, UCI Machine Learning Repository}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Repos
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@online{amini2020deep,
  title     = {Deep evidential regression},
  author    = {Amini, Alexander and Schwarting, Wilko and Soleimany, Ava and Rus, Daniela},
  journal   = {Advances in Neural Information Processing Systems},
  url       = {https://github.com/aamini/evidential-deep-learning},
  volume    = {33},
  year      = {2020},
  note      = {Accessed: 2025-04-24},
  keywords  = {repository}
}

@online{sensoy2018evidential,
  title     = {Evidential deep learning to quantify classification uncertainty},
  author    = {Sensoy, Murat and Kaplan, Lance and Kandemir, Melih},
  journal   = {Advances in neural information processing systems},
  url       = {https://muratsensoy.github.io/uncertainty.html},
  volume    = {31},
  year      = {2018},
  note      = {Accessed: 2025-04-24},
  keywords  = {repository}
}

@online{nmavani2025,
  title     = {Uncertainty in ML based Surrogate},
  author    = {Ninad Mavani},
  url       = {https://github.com/NinadMavani/MA_Uncertainty_in_ML_based_Surrogates/},
  year      = {2025},
  note      = {Accessed: 2025-06-25},
  keywords  = {repository}
}

@online{windler2025,
  title     = {Unsicherheiten in machine-learning-basierten Surrogatmodellen für die szenariobasierte Validierung autonomer Systeme},
  author    = {Marten Windler},
  url       = {https://github.com/bBswhTdb0qEq75URS/BA__U-i-mlb-Sm-f-d-s-V-a-S/tree/main/BA__Projekt},
  year      = {2025},
  note      = {Accessed: 2025-06-26},
  keywords  = {repository}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@book{rasmussen2006gaussian,
  title={Gaussian Processes for Machine Learning},
  author={Rasmussen, Carl Edward and Williams, Christopher K. I.},
  year={2006},
  publisher={MIT Press}
}

@inproceedings{lakshminarayanan2017simple,
  title={Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles},
  author={Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  booktitle={Advances in Neural Information Processing Systems},
  year={2017}
}

@phdthesis{gal2016uncertainty,
  title={Uncertainty in Deep Learning},
  author={Gal, Yarin},
  school={University of Cambridge},
  year={2016}
}

@article{perdikaris2017nonlinear,
  title={Nonlinear information fusion algorithms for data-efficient multi-fidelity modelling},
  author={Perdikaris, Paris and Raissi, Maziar and Damianou, Andreas and Lawrence, Neil D and Karniadakis, George Em},
  journal={Proceedings of the Royal Society A},
  volume={473},
  number={2198},
  year={2017}
}

@article{liu2020multifidelity,
  title={Multi-fidelity Deep Neural Networks: Algorithms and Applications},
  author={Liu, Zhen and Zhang, Yu and Karniadakis, George Em},
  journal={Journal of Computational Physics},
  volume={424},
  pages={109716},
  year={2020}
}

@inproceedings{ovadia2019can,
  title={Can You Trust Your Model's Uncertainty? Evaluating Predictive Uncertainty Under Dataset Shift},
  author={Ovadia, Yaniv and et al.},
  booktitle={Advances in Neural Information Processing Systems},
  year={2019}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@phdthesis{gal2016uncertainty,
  title={Uncertainty in Deep Learning},
  author={Gal, Yarin},
  school={University of Cambridge},
  year={2016}
}

@inproceedings{blundell2015weight,
  title={Weight Uncertainty in Neural Networks},
  author={Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2015}
}

@book{rasmussen2006gaussian,
  title={Gaussian Processes for Machine Learning},
  author={Rasmussen, Carl Edward and Williams, Christopher K. I.},
  year={2006},
  publisher={MIT Press}
}

@book{bishop2006pattern,
  title={Pattern Recognition and Machine Learning},
  author={Bishop, Christopher M.},
  year={2006},
  publisher={Springer}
}

@article{sensoy2018evidential,
  title={Evidential Deep Learning to Quantify Classification Uncertainty},
  author={Sensoy, Murat and Kaplan, Lance and Kandemir, Melih},
  journal={NeurIPS},
  year={2018}
}

@article{kendall2017uncertainties,
  title={What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?},
  author={Kendall, Alex and Gal, Yarin},
  journal={NeurIPS},
  year={2017}
}

@misc{AndreasKreutz2022,
  author = {Andreas Kreutz},
  title = {Unsicherheitsklassifizierung in KI-Systemen},
  year = {2022},
  howpublished = {Whitepaper/Manuskript},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R3
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@misc{AndreasKreutz2022,
  author = {Andreas Kreutz},
  title = {Unsicherheitsklassifizierung in KI-Systemen},
  year = {2022},
  howpublished = {Whitepaper/Manuskript},
}

@phdthesis{gal2016uncertainty,
  title={Uncertainty in Deep Learning},
  author={Gal, Yarin},
  school={University of Cambridge},
  year={2016}
}

@inproceedings{blundell2015weight,
  title={Weight Uncertainty in Neural Networks},
  author={Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
  booktitle={ICML},
  year={2015}
}

@book{rasmussen2006gaussian,
  title={Gaussian Processes for Machine Learning},
  author={Rasmussen, Carl Edward and Williams, Christopher K. I.},
  year={2006},
  publisher={MIT Press}
}

@book{bishop2006pattern,
  title={Pattern Recognition and Machine Learning},
  author={Bishop, Christopher M.},
  year={2006},
  publisher={Springer}
}

@article{sensoy2018evidential,
  title={Evidential Deep Learning to Quantify Classification Uncertainty},
  author={Sensoy, Murat and Kaplan, Lance and Kandemir, Melih},
  journal={NeurIPS},
  year={2018}
}

@article{kendall2017uncertainties,
  title={What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?},
  author={Kendall, Alex and Gal, Yarin},
  journal={NeurIPS},
  year={2017}
}

@article{perdikaris2017nonlinear,
  title={Nonlinear information fusion algorithms for data-efficient multi-fidelity modelling},
  author={Perdikaris, Paris and Raissi, Maziar and Damianou, Andreas and Lawrence, Neil D and Karniadakis, George Em},
  journal={Proceedings of the Royal Society A},
  volume={473},
  number={2198},
  year={2017}
}

@inproceedings{ovadia2019can,
  title={Can You Trust Your Model's Uncertainty? Evaluating Predictive Uncertainty Under Dataset Shift},
  author={Ovadia, Yaniv and et al.},
  booktitle={NeurIPS},
  year={2019}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R4
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R5
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R6
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@book{bishop2006pattern,
  title={Pattern Recognition and Machine Learning},
  author={Bishop, Christopher M.},
  year={2006},
  publisher={Springer}
}

@book{rasmussen2006gaussian,
  title={Gaussian Processes for Machine Learning},
  author={Rasmussen, Carl Edward and Williams, Christopher K. I.},
  year={2006},
  publisher={MIT Press}
}

@phdthesis{gal2016uncertainty,
  title={Uncertainty in Deep Learning},
  author={Gal, Yarin},
  school={University of Cambridge},
  year={2016}
}

@inproceedings{blundell2015weight,
  title={Weight Uncertainty in Neural Networks},
  author={Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
  booktitle={ICML},
  year={2015}
}

@article{sensoy2018evidential,
  title={Evidential Deep Learning to Quantify Classification Uncertainty},
  author={Sensoy, Murat and Kaplan, Lance and Kandemir, Melih},
  journal={NeurIPS},
  year={2018}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R7
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@book{bishop2006pattern,
  title={Pattern Recognition and Machine Learning},
  author={Bishop, Christopher M.},
  year={2006},
  publisher={Springer}
}

@book{rasmussen2006gaussian,
  title={Gaussian Processes for Machine Learning},
  author={Rasmussen, Carl Edward and Williams, Christopher K. I.},
  year={2006},
  publisher={MIT Press}
}

@phdthesis{gal2016uncertainty,
  title={Uncertainty in Deep Learning},
  author={Gal, Yarin},
  school={University of Cambridge},
  year={2016}
}

@inproceedings{blundell2015weight,
  title={Weight Uncertainty in Neural Networks},
  author={Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
  booktitle={ICML},
  year={2015}
}

@article{sensoy2018evidential,
  title={Evidential Deep Learning to Quantify Classification Uncertainty},
  author={Sensoy, Murat and Kaplan, Lance and Kandemir, Melih},
  journal={NeurIPS},
  year={2018}
}

@inproceedings{ovadia2019can,
  title={Can You Trust Your Model's Uncertainty? Evaluating Predictive Uncertainty Under Dataset Shift},
  author={Ovadia, Yaniv and et al.},
  booktitle={NeurIPS},
  year={2019}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R8
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{blundell2015weight,
  title={Weight Uncertainty in Neural Networks},
  author={Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
  booktitle={ICML},
  year={2015}
}

@phdthesis{gal2016uncertainty,
  title={Uncertainty in Deep Learning},
  author={Gal, Yarin},
  school={University of Cambridge},
  year={2016}
}

@article{mackay1992practical,
  title={A Practical Bayesian Framework for Backpropagation Networks},
  author={MacKay, David JC},
  journal={Neural Computation},
  volume={4},
  number={3},
  pages={448--472},
  year={1992}
}

@book{vovk2005algorithmic,
  title={Algorithmic Learning in a Random World},
  author={Vovk, Vladimir and Gammerman, Alexander and Shafer, Glenn},
  publisher={Springer},
  year={2005}
}

@article{angelopoulos2021gentle,
  title={A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification},
  author={Angelopoulos, Anastasios N and Bates, Stephen},
  journal={arXiv preprint arXiv:2107.07511},
  year={2021}
}

@article{shafer2008tutorial,
  title={A Tutorial on Conformal Prediction},
  author={Shafer, Glenn and Vovk, Vladimir},
  journal={Journal of Machine Learning Research},
  volume={9},
  pages={371--421},
  year={2008}
}

@book{rasmussen2006gaussian,
  title={Gaussian Processes for Machine Learning},
  author={Rasmussen, Carl Edward and Williams, Christopher K. I.},
  year={2006},
  publisher={MIT Press}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R9
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{blundell2015weight,
  title={Weight Uncertainty in Neural Networks},
  author={Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
  booktitle={ICML},
  year={2015}
}

@phdthesis{gal2016uncertainty,
  title={Uncertainty in Deep Learning},
  author={Gal, Yarin},
  school={University of Cambridge},
  year={2016}
}

@article{mackay1992practical,
  title={A Practical Bayesian Framework for Backpropagation Networks},
  author={MacKay, David JC},
  journal={Neural Computation},
  volume={4},
  number={3},
  pages={448--472},
  year={1992}
}

@book{rasmussen2006gaussian,
  title={Gaussian Processes for Machine Learning},
  author={Rasmussen, Carl Edward and Williams, Christopher K. I.},
  year={2006},
  publisher={MIT Press}
}

@article{angelopoulos2021gentle,
  title={A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification},
  author={Angelopoulos, Anastasios N and Bates, Stephen},
  journal={arXiv preprint arXiv:2107.07511},
  year={2021}
}

@article{shafer2008tutorial,
  title={A Tutorial on Conformal Prediction},
  author={Shafer, Glenn and Vovk, Vladimir},
  journal={Journal of Machine Learning Research},
  volume={9},
  pages={371--421},
  year={2008}
}

@book{vovk2005algorithmic,
  title={Algorithmic Learning in a Random World},
  author={Vovk, Vladimir and Gammerman, Alexander and Shafer, Glenn},
  publisher={Springer},
  year={2005}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R10
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% R11
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
